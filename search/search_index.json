{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ja: JSONL Algebra","text":"<p>Relational algebra meets JSON streaming. Transform your data with the power of mathematical principles and the simplicity of Unix pipes.</p>"},{"location":"#what-is-ja","title":"What is ja?","text":"<p><code>ja</code> (JSONL Algebra) is a command-line tool that brings the elegance of relational algebra to JSON data processing. It treats JSONL files as relations (tables) and provides operations that can be composed into powerful data pipelines.</p> <pre><code># A taste of ja\ncat orders.jsonl \\\n  | ja select 'status == \"shipped\"' \\\n  | ja join customers.jsonl --on customer_id=id \\\n  | ja groupby region \\\n  | ja agg revenue=sum(amount),orders=count\n</code></pre>"},{"location":"#why-ja","title":"Why ja?","text":"<ul> <li>\ud83e\uddee Algebraic Foundation: Based on mathematical principles that guarantee composability</li> <li>\ud83d\udd17 Unix Philosophy: Small, focused tools that do one thing well</li> <li>\ud83d\udcca Streaming Architecture: Process gigabytes without loading into memory</li> <li>\ud83c\udfaf Nested Data Support: First-class support for real-world JSON structures</li> <li>\u26a1 Zero Dependencies: Pure Python implementation (with optional enhancements)</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Quickstart \u2192 Get running in 5 minutes</li> <li>Concepts \u2192 Understand the theory</li> <li>Operations \u2192 Learn each operation</li> <li>Cookbook \u2192 Real-world examples</li> </ul>"},{"location":"#at-a-glance","title":"At a Glance","text":""},{"location":"#the-operations","title":"The Operations","text":"Operation Symbol Purpose Example select \u03c3 Filter rows <code>ja select 'age &gt; 30'</code> project \u03c0 Select columns <code>ja project name,email</code> join \u22c8 Combine relations <code>ja join users.jsonl orders.jsonl --on id=user_id</code> groupby \u03b3 Group rows <code>ja groupby department</code> union \u222a Combine all rows <code>ja union file1.jsonl file2.jsonl</code> distinct \u03b4 Remove duplicates <code>ja distinct</code>"},{"location":"#the-philosophy","title":"The Philosophy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data   \u2502 --&gt; \u2502 Filter  \u2502 --&gt; \u2502  Join   \u2502 --&gt; \u2502 Result \u2502\n\u2502 (JSONL) \u2502     \u2502(select) \u2502     \u2502 (join)  \u2502     \u2502(JSONL) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2193               \u2193               \u2193               \u2193\n  Relation  --&gt;  Relation  --&gt;  Relation  --&gt;  Relation\n</code></pre> <p>Every operation takes relations and produces relations. This closure property enables infinite composability.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install jsonl-algebra\n</code></pre> <p>That's it! You now have the <code>ja</code> command available.</p>"},{"location":"#your-first-pipeline","title":"Your First Pipeline","text":"<p>Let's analyze some order data. Create <code>orders.jsonl</code>:</p> <pre><code>{\"order_id\": 1, \"customer\": \"Alice\", \"amount\": 99.99, \"status\": \"shipped\"}\n{\"order_id\": 2, \"customer\": \"Bob\", \"amount\": 149.99, \"status\": \"pending\"}\n{\"order_id\": 3, \"customer\": \"Alice\", \"amount\": 79.99, \"status\": \"shipped\"}\n{\"order_id\": 4, \"customer\": \"Charlie\", \"amount\": 199.99, \"status\": \"shipped\"}\n{\"order_id\": 5, \"customer\": \"Bob\", \"amount\": 59.99, \"status\": \"cancelled\"}\n</code></pre>"},{"location":"#1-filter-orders","title":"1. Filter Orders","text":"<p>Get only shipped orders:</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl\n</code></pre>"},{"location":"#2-calculate-totals","title":"2. Calculate Totals","text":"<p>Total revenue from shipped orders:</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl | ja agg total=sum(amount)\n</code></pre> <p>Output: <pre><code>{\"total\": 379.97}\n</code></pre></p>"},{"location":"#3-group-by-customer","title":"3. Group by Customer","text":"<p>Revenue per customer (shipped only):</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl \\\n  | ja groupby customer \\\n  | ja agg revenue=sum(amount),orders=count\n</code></pre> <p>Output: <pre><code>{\"customer\": \"Alice\", \"revenue\": 179.98, \"orders\": 2}\n{\"customer\": \"Charlie\", \"revenue\": 199.99, \"orders\": 1}\n</code></pre></p>"},{"location":"#4-multi-level-grouping","title":"4. Multi-Level Grouping","text":"<p>Our innovative chained groupby enables complex analytics:</p> <pre><code>cat sales.jsonl \\\n  | ja groupby region \\      # First level grouping\n  | ja groupby product \\     # Second level grouping  \n  | ja agg total=sum(amount) # Final aggregation\n</code></pre> <p>This produces results like: <pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"total\": 1250}\n{\"region\": \"North\", \"product\": \"Gadget\", \"total\": 850}\n{\"region\": \"South\", \"product\": \"Widget\", \"total\": 900}\n</code></pre></p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Relational Operations: select, project, join, union, intersection, difference, distinct, and more</li> <li>Chained Grouping: Multi-level grouping that preserves composability</li> <li>Nested Data Support: Access and manipulate nested fields using intuitive dot notation</li> <li>Streaming Architecture: Process large datasets without loading into memory</li> <li>Expression Language: Safe and expressive filtering with ExprEval</li> <li>Interactive REPL: Build data pipelines step-by-step interactively</li> <li>Format Conversion: Import/export CSV, JSON arrays, and directory structures</li> <li>Unix Philosophy: Designed for pipes and command composition</li> </ul>"},{"location":"#working-with-nested-data","title":"Working with Nested Data","text":"<p><code>ja</code> makes working with nested JSON objects effortless:</p> <pre><code># Project nested fields\nja project user.name,user.email,order.total data.jsonl\n\n# Group by nested values\nja groupby user.region orders.jsonl | ja agg revenue=sum(amount)\n\n# Filter on nested conditions\nja select 'user.age &gt; 30 and order.status == \"shipped\"' data.jsonl\n</code></pre>"},{"location":"#interactive-mode","title":"Interactive Mode","text":"<p>Want to explore? Try the REPL:</p> <pre><code>ja repl\n\nja&gt; from orders.jsonl\nja&gt; select amount &gt; 100\nja&gt; groupby customer\nja&gt; agg total=sum(amount)\nja&gt; execute\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ol> <li>Read the Quickstart - Get hands-on in 5 minutes</li> <li>Explore the Concepts - Understand the theory</li> <li>Browse the Cookbook - See real examples</li> <li>Join the Community - Contribute and get help</li> </ol>"},{"location":"#dependencies-and-setup","title":"Dependencies and Setup","text":"<p><code>ja</code> includes optional dependencies for enhanced functionality:</p> <ul> <li>jmespath: For safe and expressive filtering (replaces eval)</li> <li>jsonschema: For schema validation features</li> <li>All other features work without external dependencies</li> </ul>"},{"location":"#for-users-from-pypi","title":"For users (from PyPI)","text":"<pre><code>pip install jsonl-algebra\n</code></pre> <p>This automatically installs the required dependencies.</p>"},{"location":"#for-developers-from-local-repository","title":"For developers (from local repository)","text":"<pre><code># Standard installation\npip install .\n\n# Editable mode for development\npip install -e .\n</code></pre> <p>Ready to transform your JSON data? Start with the quickstart guide or dive into the concepts to understand the theory behind the tool.</p>"},{"location":"DOCUMENTATION_SUMMARY/","title":"Documentation Summary","text":"<p>This document summarizes the comprehensive MkDocs documentation created for the jsonl-algebra project.</p>"},{"location":"DOCUMENTATION_SUMMARY/#overview","title":"Overview","text":"<p>A complete, professional documentation site has been created using MkDocs with the Material theme. The documentation covers all aspects of jsonl-algebra from beginner tutorials to advanced API references.</p>"},{"location":"DOCUMENTATION_SUMMARY/#what-was-created","title":"What Was Created","text":""},{"location":"DOCUMENTATION_SUMMARY/#1-site-configuration","title":"1. Site Configuration","text":"<p>File: <code>/mkdocs.yml</code></p> <p>Enhanced MkDocs configuration with: - Material theme with dark/light mode toggle - Advanced navigation features (tabs, sections, expand, tracking) - Code highlighting with copy buttons - Search functionality with suggestions - Emoji support - Task lists and special markdown extensions - API documentation via mkdocstrings</p>"},{"location":"DOCUMENTATION_SUMMARY/#2-documentation-structure","title":"2. Documentation Structure","text":"<p>The documentation is organized into the following major sections:</p>"},{"location":"DOCUMENTATION_SUMMARY/#getting-started","title":"Getting Started","text":"<ul> <li><code>docs/getting-started/installation.md</code> - Comprehensive installation guide</li> <li>Multiple installation methods (pip, source, virtual env)</li> <li>Platform-specific instructions (Linux, macOS, Windows)</li> <li>Troubleshooting section</li> <li> <p>Verification steps</p> </li> <li> <p><code>docs/getting-started/quickstart.md</code> - 5-minute hands-on tutorial</p> </li> <li>Sample data creation</li> <li>Step-by-step lessons for core operations</li> <li>Real-world examples</li> <li> <p>Practice exercises with solutions</p> </li> <li> <p><code>docs/getting-started/concepts.md</code> - Core concepts explanation</p> </li> <li>JSONL format explained</li> <li>Relational algebra basics</li> <li>Dot notation for nested data</li> <li>Streaming architecture</li> <li>Expression language</li> <li>Pipeline composition</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#cli-reference","title":"CLI Reference","text":"<ul> <li><code>docs/cli/overview.md</code> - Complete CLI overview</li> <li>Command structure and syntax</li> <li>All core commands listed and categorized</li> <li>Input/output patterns</li> <li>Common usage patterns</li> <li>Performance considerations</li> <li>Error handling</li> <li>Environment variables</li> <li>Integration with Unix tools</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#ja-shell-guide","title":"ja-shell Guide","text":"<ul> <li><code>docs/shell/introduction.md</code> - Interactive JSON navigator</li> <li>What is ja-shell and why use it</li> <li>Filesystem abstraction concept</li> <li>Rich terminal UI features</li> <li>Performance optimization</li> <li>Comparison with other tools</li> <li>Architecture explanation</li> <li>Future features roadmap</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#integrations","title":"Integrations","text":"<ul> <li><code>docs/integrations/overview.md</code> - All integrations explained</li> <li>MCP server for AI assistants</li> <li>Log analyzer for real-time monitoring</li> <li>Data explorer REPL</li> <li>ML pipeline for machine learning</li> <li>Composability module</li> <li>Comparison matrix</li> <li>Common workflows</li> <li>Design philosophy</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#tutorials","title":"Tutorials","text":"<ul> <li><code>docs/tutorials/data-analysis.md</code> - Log file analysis tutorial</li> <li>Complete walkthrough of analyzing access logs</li> <li>Finding errors and anomalies</li> <li>Performance analysis</li> <li>User activity tracking</li> <li>Creating summary reports</li> <li>Time-based analysis</li> <li>Alerting on anomalies</li> <li>Multi-file analysis</li> <li>Real-world integration patterns</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#reference","title":"Reference","text":"<ul> <li><code>docs/faq.md</code> - Comprehensive FAQ</li> <li>General questions about jsonl-algebra</li> <li>Installation and setup</li> <li>Usage questions with examples</li> <li>Data format questions</li> <li>Performance optimization</li> <li>Expression syntax</li> <li>Feature questions</li> <li>Troubleshooting</li> <li>Advanced usage</li> <li> <p>Contributing information</p> </li> <li> <p><code>docs/contributing.md</code> - Contribution guide</p> </li> <li>Ways to contribute</li> <li>Development environment setup</li> <li>Development workflow</li> <li>Testing guidelines</li> <li>Documentation standards</li> <li>Pull request process</li> <li>Code review process</li> <li>Project structure</li> <li>Feature development guide</li> <li>Release process</li> <li>Community guidelines</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#3-custom-styling","title":"3. Custom Styling","text":"<p>File: <code>docs/stylesheets/extra.css</code></p> <p>Custom CSS providing: - Enhanced code block styling - Admonition styling (tips, warnings, success, info) - Better table formatting - Command syntax highlighting - Keyboard key styling - Mermaid diagram support - Improved navigation - Responsive images - Dark mode support - Task list styling</p>"},{"location":"DOCUMENTATION_SUMMARY/#documentation-features","title":"Documentation Features","text":""},{"location":"DOCUMENTATION_SUMMARY/#content-features","title":"Content Features","text":"<ol> <li>Comprehensive Coverage</li> <li>Beginner to advanced content</li> <li>Real-world examples throughout</li> <li>Runnable code snippets</li> <li> <p>Troubleshooting guides</p> </li> <li> <p>Interactive Elements</p> </li> <li>Tabbed content for alternatives</li> <li>Collapsible sections</li> <li>Code copy buttons</li> <li> <p>Search functionality</p> </li> <li> <p>Visual Enhancements</p> </li> <li>Syntax-highlighted code</li> <li>Admonitions (tips, warnings, notes)</li> <li>Tables and lists</li> <li>Emoji support</li> <li> <p>Icons</p> </li> <li> <p>Navigation</p> </li> <li>Clear hierarchy</li> <li>Breadcrumbs</li> <li>Table of contents</li> <li>Cross-linking between pages</li> <li>\"Edit on GitHub\" links</li> </ol>"},{"location":"DOCUMENTATION_SUMMARY/#material-theme-features","title":"Material Theme Features","text":"<p>Enabled features: - <code>navigation.tabs</code> - Top-level tabs - <code>navigation.sections</code> - Section grouping - <code>navigation.expand</code> - Auto-expand sections - <code>navigation.top</code> - Back to top button - <code>navigation.tracking</code> - URL tracking - <code>navigation.indexes</code> - Section index pages - <code>search.highlight</code> - Highlight search terms - <code>search.share</code> - Share search results - <code>search.suggest</code> - Search suggestions - <code>content.code.copy</code> - Copy code button - <code>content.code.annotate</code> - Code annotations - <code>content.tabs.link</code> - Linked tabs</p>"},{"location":"DOCUMENTATION_SUMMARY/#markdown-extensions","title":"Markdown Extensions","text":"<p>Enabled extensions: - Code highlighting with line numbers - Mermaid diagrams - Inline code highlighting - Tabbed content - Admonitions - Details/summary blocks - Emoji - Keyboard keys - Smart symbols - Task lists - Tables - Definition lists - Footnotes - Deep table of contents</p>"},{"location":"DOCUMENTATION_SUMMARY/#file-locations","title":"File Locations","text":"<p>All documentation files are in <code>/home/spinoza/github/released/jsonl-algebra/docs/</code>:</p> <pre><code>docs/\n\u251c\u2500\u2500 mkdocs.yml (root)          # Site configuration\n\u251c\u2500\u2500 stylesheets/\n\u2502   \u2514\u2500\u2500 extra.css              # Custom styling\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md        # Installation guide\n\u2502   \u251c\u2500\u2500 quickstart.md          # 5-minute tutorial\n\u2502   \u2514\u2500\u2500 concepts.md            # Core concepts\n\u251c\u2500\u2500 cli/\n\u2502   \u2514\u2500\u2500 overview.md            # CLI reference\n\u251c\u2500\u2500 shell/\n\u2502   \u2514\u2500\u2500 introduction.md        # ja-shell guide\n\u251c\u2500\u2500 integrations/\n\u2502   \u2514\u2500\u2500 overview.md            # Integrations overview\n\u251c\u2500\u2500 tutorials/\n\u2502   \u2514\u2500\u2500 data-analysis.md       # Log analysis tutorial\n\u251c\u2500\u2500 contributing.md            # Contribution guide\n\u251c\u2500\u2500 faq.md                     # FAQ\n\u2514\u2500\u2500 DOCUMENTATION_SUMMARY.md   # This file\n</code></pre>"},{"location":"DOCUMENTATION_SUMMARY/#building-and-viewing","title":"Building and Viewing","text":""},{"location":"DOCUMENTATION_SUMMARY/#local-development","title":"Local Development","text":"<p>Build and serve the documentation locally:</p> <pre><code># Install MkDocs and dependencies\npip install mkdocs mkdocs-material mkdocstrings[python]\n\n# Serve locally with live reload\nmkdocs serve\n\n# Open in browser: http://127.0.0.1:8000\n</code></pre>"},{"location":"DOCUMENTATION_SUMMARY/#build-static-site","title":"Build Static Site","text":"<p>Generate static HTML files:</p> <pre><code>mkdocs build\n\n# Output in site/ directory\n</code></pre>"},{"location":"DOCUMENTATION_SUMMARY/#deploy-to-github-pages","title":"Deploy to GitHub Pages","text":"<pre><code>mkdocs gh-deploy\n</code></pre>"},{"location":"DOCUMENTATION_SUMMARY/#content-statistics","title":"Content Statistics","text":""},{"location":"DOCUMENTATION_SUMMARY/#pages-created","title":"Pages Created","text":"<ul> <li>9 new comprehensive documentation pages</li> <li>1 enhanced configuration file</li> <li>1 custom CSS file</li> <li>1 summary document (this file)</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#word-count-approximate","title":"Word Count (Approximate)","text":"<ul> <li>Installation guide: 1,500 words</li> <li>Quick start tutorial: 2,500 words</li> <li>Core concepts: 2,000 words</li> <li>CLI overview: 2,500 words</li> <li>ja-shell introduction: 2,500 words</li> <li>Integrations overview: 2,500 words</li> <li>Data analysis tutorial: 3,500 words</li> <li>FAQ: 3,000 words</li> <li>Contributing guide: 3,000 words</li> </ul> <p>Total: ~23,000 words of new documentation</p>"},{"location":"DOCUMENTATION_SUMMARY/#documentation-philosophy","title":"Documentation Philosophy","text":"<p>The documentation follows these principles:</p> <ol> <li>User-Focused</li> <li>Written for data engineers, developers, DevOps</li> <li>Assumes basic command-line knowledge</li> <li> <p>Progressive complexity (beginner to advanced)</p> </li> <li> <p>Example-Driven</p> </li> <li>Every concept has runnable examples</li> <li>Real-world use cases throughout</li> <li> <p>Copy-paste friendly code</p> </li> <li> <p>Comprehensive</p> </li> <li>Covers all major features</li> <li>Includes edge cases and gotchas</li> <li> <p>Troubleshooting for common issues</p> </li> <li> <p>Accessible</p> </li> <li>Clear, simple language</li> <li>Visual aids (tables, diagrams, admonitions)</li> <li> <p>Multiple learning paths</p> </li> <li> <p>Maintainable</p> </li> <li>Structured organization</li> <li>Cross-referenced pages</li> <li>Version-controlled</li> <li>Easy to update</li> </ol>"},{"location":"DOCUMENTATION_SUMMARY/#next-steps","title":"Next Steps","text":""},{"location":"DOCUMENTATION_SUMMARY/#recommended-additions","title":"Recommended Additions","text":"<p>While the core documentation is complete, these areas could be expanded:</p> <ol> <li>CLI Command Detail Pages</li> <li>Individual pages for each command (select, project, join, etc.)</li> <li>Currently covered in overview but could be expanded</li> <li> <p>Located in <code>docs/cli/commands/</code></p> </li> <li> <p>More Tutorials</p> </li> <li>ETL pipeline tutorial (<code>docs/tutorials/etl.md</code>)</li> <li>JSON exploration tutorial (<code>docs/tutorials/json-exploration.md</code>)</li> <li>Real-time monitoring (<code>docs/tutorials/monitoring.md</code>)</li> <li> <p>Data quality checks (<code>docs/tutorials/quality.md</code>)</p> </li> <li> <p>API Reference Pages</p> </li> <li>Detailed API docs for <code>ja.core</code> (<code>docs/api/core.md</code>)</li> <li>Composability patterns (<code>docs/api/composability.md</code>)</li> <li>Virtual filesystem API (<code>docs/api/vfs.md</code>)</li> <li> <p>Schema API (<code>docs/api/schema.md</code>)</p> </li> <li> <p>ja-shell Deep Dive</p> </li> <li>Tutorial walkthrough (<code>docs/shell/tutorial.md</code>)</li> <li>Command reference (<code>docs/shell/commands.md</code>)</li> <li>Advanced features (<code>docs/shell/advanced.md</code>)</li> <li> <p>Use cases (<code>docs/shell/use-cases.md</code>)</p> </li> <li> <p>Integration Guides</p> </li> <li>Detailed MCP server guide (<code>docs/integrations/mcp.md</code>)</li> <li>Log analyzer guide (<code>docs/integrations/log-analyzer.md</code>)</li> <li>Data explorer guide (<code>docs/integrations/data-explorer.md</code>)</li> <li> <p>ML pipeline guide (<code>docs/integrations/ml-pipeline.md</code>)</p> </li> <li> <p>Core Concept Pages</p> </li> <li>Detailed relational algebra (<code>docs/concepts/relational-algebra.md</code>)</li> <li>Dot notation guide (<code>docs/concepts/dotnotation.md</code>)</li> <li>Streaming and piping (<code>docs/concepts/streaming.md</code>)</li> <li> <p>Expression language (<code>docs/concepts/expressions.md</code>)</p> </li> <li> <p>Reference Materials</p> </li> <li>Troubleshooting guide (<code>docs/troubleshooting.md</code>)</li> <li>Changelog (<code>docs/changelog.md</code>)</li> <li>Development setup (<code>docs/development.md</code>)</li> <li>Testing strategy (<code>docs/testing.md</code>)</li> </ol>"},{"location":"DOCUMENTATION_SUMMARY/#using-existing-content","title":"Using Existing Content","text":"<p>Some excellent content already exists in the repo that can be: - Adapted for the new structure - Cross-referenced - Updated to match the new style</p> <p>Existing files that can be incorporated: - <code>docs/index.md</code> (already good, could be enhanced) - <code>docs/quickstart.md</code> (existing content) - <code>docs/getting-started.md</code> (can merge with new content) - <code>docs/concepts/jsonl-algebra.md</code> (existing content) - <code>docs/guide/repl/</code> (existing REPL documentation) - <code>docs/cookbook/log-analysis.md</code> (existing tutorial)</p>"},{"location":"DOCUMENTATION_SUMMARY/#building-on-this-foundation","title":"Building on This Foundation","text":"<p>The documentation structure is designed to be:</p> <ol> <li>Expandable - Easy to add new pages</li> <li>Modular - Each section is self-contained</li> <li>Consistent - Follows the same style throughout</li> <li>Navigable - Clear hierarchy and cross-links</li> </ol> <p>To add new content:</p> <ol> <li>Create markdown file in appropriate directory</li> <li>Add to <code>nav</code> section in <code>mkdocs.yml</code></li> <li>Follow existing style (admonitions, code blocks, etc.)</li> <li>Cross-link to related pages</li> <li>Test locally with <code>mkdocs serve</code></li> </ol>"},{"location":"DOCUMENTATION_SUMMARY/#quality-checklist","title":"Quality Checklist","text":"<p>The created documentation includes:</p> <ul> <li>\u2705 Clear installation instructions</li> <li>\u2705 Hands-on quickstart tutorial</li> <li>\u2705 Conceptual explanations</li> <li>\u2705 Command reference</li> <li>\u2705 Real-world tutorials</li> <li>\u2705 Integration guides</li> <li>\u2705 Comprehensive FAQ</li> <li>\u2705 Contributing guide</li> <li>\u2705 Custom styling</li> <li>\u2705 Search functionality</li> <li>\u2705 Dark mode support</li> <li>\u2705 Responsive design</li> <li>\u2705 Code highlighting</li> <li>\u2705 Copy-paste examples</li> <li>\u2705 Cross-references</li> <li>\u2705 Professional appearance</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#feedback-and-improvements","title":"Feedback and Improvements","text":"<p>This documentation is a living resource. Consider:</p> <ul> <li>Gathering user feedback</li> <li>Tracking documentation issues</li> <li>Updating with new features</li> <li>Adding more examples</li> <li>Creating video tutorials</li> <li>Translating to other languages</li> </ul>"},{"location":"DOCUMENTATION_SUMMARY/#conclusion","title":"Conclusion","text":"<p>A comprehensive, professional documentation site has been created for jsonl-algebra. The documentation:</p> <ul> <li>Covers all major features and use cases</li> <li>Provides clear learning paths for different audiences</li> <li>Includes practical, runnable examples</li> <li>Looks professional with the Material theme</li> <li>Is ready for immediate use and future expansion</li> </ul> <p>The foundation is solid and can be easily extended as the project grows.</p> <p>Created: October 27, 2025 Total Files: 12 new/updated files Total Words: ~23,000 words Status: Ready for review and deployment</p>"},{"location":"chained-groups/","title":"Chained GroupBy Operations","text":"<p><code>ja</code> supports a powerful pattern of chaining multiple <code>groupby</code> operations, allowing you to create multi-level aggregations while maintaining the JSONL format throughout the pipeline.</p>"},{"location":"chained-groups/#how-it-works","title":"How It Works","text":"<p>When you use <code>groupby</code> without the <code>--agg</code> flag, <code>ja</code> adds special metadata fields to each row:</p> <ul> <li><code>_group</code>: The value of the grouping key for this row</li> <li><code>_group_field</code>: The field name used for grouping</li> <li><code>_group_size</code>: Total number of rows in this group</li> <li><code>_group_index</code>: This row's index within its group</li> </ul> <p>These fields allow subsequent operations to understand the grouping structure while keeping the data in JSONL format.</p>"},{"location":"chained-groups/#basic-example","title":"Basic Example","text":"<pre><code># Group sales by region, then by product within each region\ncat sales.jsonl | ja groupby region | ja groupby product | ja agg \"total=sum(amount),count\"\n</code></pre>"},{"location":"chained-groups/#representation","title":"Representation","text":""},{"location":"chained-groups/#original-data","title":"Original Data","text":"<pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 100}\n{\"region\": \"North\", \"product\": \"Gadget\", \"amount\": 150}\n{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 200}\n{\"region\": \"South\", \"product\": \"Widget\", \"amount\": 250}\n</code></pre>"},{"location":"chained-groups/#after-first-groupby","title":"After First GroupBy","text":"<pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 100, \"_group\": \"North\", \"_group_field\": \"region\", \"_group_size\": 3, \"_group_index\": 0}\n{\"region\": \"North\", \"product\": \"Gadget\", \"amount\": 150, \"_group\": \"North\", \"_group_field\": \"region\", \"_group_size\": 3, \"_group_index\": 1}\n{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 200, \"_group\": \"North\", \"_group_field\": \"region\", \"_group_size\": 3, \"_group_index\": 2}\n{\"region\": \"South\", \"product\": \"Widget\", \"amount\": 250, \"_group\": \"South\", \"_group_field\": \"region\", \"_group_size\": 1, \"_group_index\": 0}\n</code></pre>"},{"location":"chained-groups/#after-second-groupby","title":"After Second GroupBy","text":"<pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 100, \"_group\": \"North.Widget\", \"_group_field\": \"product\", \"_group_size\": 2, \"_group_index\": 0, \"_parent_group\": \"North\", \"_group_trail\": [\"region\", \"product\"]}\n{\"region\": \"North\", \"product\": \"Widget\", \"amount\": 200, \"_group\": \"North.Widget\", \"_group_field\": \"product\", \"_group_size\": 2, \"_group_index\": 1, \"_parent_group\": \"North\", \"_group_trail\": [\"region\", \"product\"]}\n{\"region\": \"North\", \"product\": \"Gadget\", \"amount\": 150, \"_group\": \"North.Gadget\", \"_group_field\": \"product\", \"_group_size\": 1, \"_group_index\": 0, \"_parent_group\": \"North\", \"_group_trail\": [\"region\", \"product\"]}\n{\"region\": \"South\", \"product\": \"Widget\", \"amount\": 250, \"_group\": \"South.Widget\", \"_group_field\": \"product\", \"_group_size\": 1, \"_group_index\": 0, \"_parent_group\": \"South\", \"_group_trail\": [\"region\", \"product\"]}\n</code></pre>"},{"location":"chained-groups/#after-aggregation","title":"After Aggregation","text":"<pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"total\": 300, \"count\": 2}\n{\"region\": \"North\", \"product\": \"Gadget\", \"total\": 150, \"count\": 1}\n{\"region\": \"South\", \"product\": \"Widget\", \"total\": 250, \"count\": 1}\n</code></pre>"},{"location":"chained-groups/#advanced-examples","title":"Advanced Examples","text":""},{"location":"chained-groups/#three-level-grouping","title":"Three-Level Grouping","text":"<pre><code># Group by year, then month, then category\ncat transactions.jsonl \\\n  | ja groupby year \\\n  | ja groupby month \\\n  | ja groupby category \\\n  | ja agg revenue=sum(amount),transactions=count,avg_transaction=avg(amount)\n</code></pre>"},{"location":"chained-groups/#filtering-between-groups","title":"Filtering Between Groups","text":"<pre><code># Group by user, filter to active users, then group by product\ncat purchases.jsonl \\\n  | ja groupby user_id \\\n  | ja select '_group_size &gt; 5' \\\n  | ja groupby product_id \\\n  | ja agg total=sum(price)\n</code></pre>"},{"location":"chained-groups/#inspecting-intermediate-results","title":"Inspecting Intermediate Results","text":"<pre><code># Use jq to examine the grouping structure\ncat data.jsonl | ja groupby category | jq '._group_field, ._group_size' | sort | uniq -c\n</code></pre>"},{"location":"chained-groups/#comparison-with-direct-aggregation","title":"Comparison with Direct Aggregation","text":"<p>You can still use the <code>--agg</code> flag for more efficient single-level aggregations:</p> <pre><code># Direct aggregation (more efficient for simple cases)\nja groupby region --agg total=sum(amount),count sales.jsonl\n\n# Equivalent chained operation\ncat sales.jsonl | ja groupby region | ja agg total=sum(amount),count\n</code></pre> <p>The chained approach is more flexible but may be slightly less efficient for simple aggregations. Use it when you need: - Multi-level grouping - Intermediate filtering or transformation - Exploratory analysis with inspection of groups - Integration with other tools in a pipeline</p>"},{"location":"contributing/","title":"Contributing to jsonl-algebra","text":"<p>Thank you for your interest in contributing to jsonl-algebra! This document will guide you through the contribution process.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<p>There are many ways to contribute to jsonl-algebra:</p> <ul> <li>Report bugs - Help us identify and fix issues</li> <li>Suggest features - Share ideas for improvements</li> <li>Improve documentation - Fix typos, clarify explanations, add examples</li> <li>Write tutorials - Share how you use jsonl-algebra</li> <li>Submit code - Fix bugs or implement features</li> <li>Create integrations - Build tools that extend jsonl-algebra</li> <li>Answer questions - Help other users in discussions</li> </ul> <p>All contributions are valuable and appreciated!</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#1-set-up-development-environment","title":"1. Set Up Development Environment","text":"<p>Fork and clone the repository:</p> <pre><code># Fork on GitHub first, then clone your fork\ngit clone https://github.com/YOUR-USERNAME/jsonl-algebra.git\ncd jsonl-algebra\n\n# Add upstream remote\ngit remote add upstream https://github.com/queelius/jsonl-algebra.git\n</code></pre> <p>Create a virtual environment and install dependencies:</p> <pre><code># Create virtual environment\npython3 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in editable mode with dev dependencies\npip install -e \".[dev]\"\n</code></pre> <p>Verify installation:</p> <pre><code># Run tests\npytest\n\n# Check code style\nblack --check .\nflake8 .\n</code></pre>"},{"location":"contributing/#2-create-a-branch","title":"2. Create a Branch","text":"<p>Create a feature branch for your work:</p> <pre><code>git checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/bug-description\n</code></pre> <p>Use descriptive branch names:</p> <ul> <li><code>feature/add-regex-support</code></li> <li><code>fix/groupby-null-handling</code></li> <li><code>docs/improve-quickstart</code></li> </ul>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#making-changes","title":"Making Changes","text":"<ol> <li>Make your changes - Edit the relevant files</li> <li>Write tests - Add tests for new features or bug fixes</li> <li>Run tests - Ensure all tests pass</li> <li>Check style - Format code with black and check with flake8</li> <li>Update docs - Document new features or behavior changes</li> <li>Commit changes - Write clear commit messages</li> </ol>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>Run the full test suite:</p> <pre><code># All tests\npytest\n\n# Specific test file\npytest tests/test_core.py\n\n# Specific test function\npytest tests/test_core.py::test_select_basic\n\n# With coverage\npytest --cov=ja tests/\n\n# Generate coverage report\npytest --cov=ja --cov-report=html tests/\n# Open htmlcov/index.html in browser\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>jsonl-algebra follows Python best practices:</p> <p>Format code with black:</p> <pre><code>black .\n</code></pre> <p>Check style with flake8:</p> <pre><code>flake8 .\n</code></pre> <p>Type hints:</p> <p>We use type hints where helpful:</p> <pre><code>from typing import List, Dict, Iterator\n\ndef select(data: List[Dict], expr: str) -&gt; List[Dict]:\n    \"\"\"Filter rows based on expression.\"\"\"\n    ...\n</code></pre> <p>Docstrings:</p> <p>Use Google-style docstrings:</p> <pre><code>def my_function(param1: str, param2: int) -&gt; bool:\n    \"\"\"Short description of function.\n\n    Longer description if needed. Explain what the function does,\n    any important behavior, and edge cases.\n\n    Args:\n        param1: Description of first parameter\n        param2: Description of second parameter\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: When invalid input is provided\n\n    Example:\n        &gt;&gt;&gt; my_function(\"test\", 42)\n        True\n    \"\"\"\n    ...\n</code></pre>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Write clear, descriptive commit messages:</p> <p>Good: <pre><code>Add support for regex in select expressions\n\n- Implement regex matching with =~ operator\n- Add tests for regex patterns\n- Update documentation with examples\n</code></pre></p> <p>Bad: <pre><code>fixed stuff\n</code></pre></p> <p>Format:</p> <pre><code>Short summary (50 chars or less)\n\nMore detailed explanation if needed. Wrap at 72 characters.\nExplain what changed and why.\n\n- Bullet points for multiple changes\n- Each change on its own line\n\nFixes #123\n</code></pre>"},{"location":"contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<p>Tests are located in the <code>tests/</code> directory, organized by module:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_core.py         # Core operations\n\u251c\u2500\u2500 test_cli.py          # CLI commands\n\u251c\u2500\u2500 test_expr.py         # Expression evaluation\n\u251c\u2500\u2500 test_groupby.py      # Grouping operations\n\u2514\u2500\u2500 ...\n</code></pre> <p>Test structure:</p> <pre><code>import pytest\nfrom ja.core import select\n\ndef test_select_basic():\n    \"\"\"Test basic select operation.\"\"\"\n    data = [\n        {\"name\": \"Alice\", \"age\": 30},\n        {\"name\": \"Bob\", \"age\": 25},\n    ]\n\n    result = list(select(data, \"age &gt; 27\"))\n\n    assert len(result) == 1\n    assert result[0][\"name\"] == \"Alice\"\n\ndef test_select_with_nulls():\n    \"\"\"Test select handles null values.\"\"\"\n    data = [\n        {\"name\": \"Alice\", \"score\": 90},\n        {\"name\": \"Bob\", \"score\": None},\n    ]\n\n    result = list(select(data, \"score != null\"))\n\n    assert len(result) == 1\n    assert result[0][\"name\"] == \"Alice\"\n\n@pytest.mark.parametrize(\"expr,expected_count\", [\n    (\"age &gt; 25\", 2),\n    (\"age &gt;= 30\", 1),\n    (\"age &lt; 30\", 1),\n])\ndef test_select_comparisons(expr, expected_count):\n    \"\"\"Test various comparison operators.\"\"\"\n    data = [\n        {\"age\": 25},\n        {\"age\": 30},\n        {\"age\": 35},\n    ]\n\n    result = list(select(data, expr))\n    assert len(result) == expected_count\n</code></pre>"},{"location":"contributing/#test-coverage","title":"Test Coverage","text":"<p>Aim for high test coverage:</p> <pre><code># Generate coverage report\npytest --cov=ja --cov-report=term-missing tests/\n\n# View in browser\npytest --cov=ja --cov-report=html tests/\nopen htmlcov/index.html\n</code></pre> <p>Coverage goals:</p> <ul> <li>Core operations: 90%+ coverage</li> <li>CLI commands: 80%+ coverage</li> <li>Edge cases: Test error conditions</li> <li>Integration tests: Test component interaction</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":""},{"location":"contributing/#updating-documentation","title":"Updating Documentation","text":"<p>Documentation is in the <code>docs/</code> directory using MkDocs:</p> <pre><code>docs/\n\u251c\u2500\u2500 index.md                    # Homepage\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u251c\u2500\u2500 quickstart.md\n\u2502   \u2514\u2500\u2500 concepts.md\n\u251c\u2500\u2500 cli/\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u2514\u2500\u2500 commands.md\n\u2514\u2500\u2500 ...\n</code></pre> <p>Building docs locally:</p> <pre><code># Install MkDocs\npip install mkdocs mkdocs-material mkdocstrings[python]\n\n# Serve locally\nmkdocs serve\n\n# Open http://127.0.0.1:8000 in browser\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"contributing/#documentation-style","title":"Documentation Style","text":"<p>Be clear and concise:</p> <ul> <li>Use simple language</li> <li>Provide examples</li> <li>Explain the \"why\", not just the \"what\"</li> </ul> <p>Use admonitions for important info:</p> <pre><code>!!! tip \"Pro Tip\"\n    Filter data early in pipelines to improve performance.\n\n!!! warning \"Important\"\n    This operation loads all data into memory.\n\n!!! info \"Note\"\n    Null values are handled specially in comparisons.\n</code></pre> <p>Include runnable examples:</p> <pre><code>Filter users over 30:\n\n ```bash\nja select 'age &gt; 30' users.jsonl\n ```\n\nOutput:\n ```json\n{\"id\": 1, \"name\": \"Alice\", \"age\": 35}\n ```\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li> <p>Sync with upstream: <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre></p> </li> <li> <p>Run tests: <pre><code>pytest\n</code></pre></p> </li> <li> <p>Check code style: <pre><code>black --check .\nflake8 .\n</code></pre></p> </li> <li> <p>Update docs if needed</p> </li> <li> <p>Squash commits if needed: <pre><code>git rebase -i HEAD~3  # Squash last 3 commits\n</code></pre></p> </li> </ol>"},{"location":"contributing/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<ol> <li> <p>Push your branch: <pre><code>git push origin feature/your-feature-name\n</code></pre></p> </li> <li> <p>Open a Pull Request on GitHub</p> </li> <li> <p>Fill out the PR template:</p> </li> <li>Description of changes</li> <li>Related issues</li> <li>Testing done</li> <li> <p>Screenshots (if UI changes)</p> </li> <li> <p>Wait for review:</p> </li> <li>Address reviewer comments</li> <li>Make requested changes</li> <li>Push updates (they'll appear in the PR)</li> </ol>"},{"location":"contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\n\nBrief description of what this PR does.\n\n## Related Issues\n\nFixes #123\nCloses #456\n\n## Changes Made\n\n- Added feature X\n- Fixed bug Y\n- Updated documentation for Z\n\n## Testing\n\n- [ ] Added tests for new functionality\n- [ ] All tests pass\n- [ ] Manually tested with sample data\n\n## Documentation\n\n- [ ] Updated relevant documentation\n- [ ] Added docstrings for new functions\n- [ ] Updated CHANGELOG.md\n\n## Screenshots (if applicable)\n\nBefore: [screenshot]\nAfter: [screenshot]\n</code></pre>"},{"location":"contributing/#code-review-process","title":"Code Review Process","text":""},{"location":"contributing/#what-to-expect","title":"What to Expect","text":"<ul> <li>Reviews usually happen within a few days</li> <li>Maintainers may request changes</li> <li>Discussion helps improve the code</li> <li>Multiple review rounds are normal</li> </ul>"},{"location":"contributing/#being-a-good-reviewer","title":"Being a Good Reviewer","text":"<p>If you're reviewing PRs:</p> <ul> <li>Be constructive and kind</li> <li>Explain the \"why\" behind suggestions</li> <li>Acknowledge good work</li> <li>Test the changes if possible</li> <li>Approve when ready</li> </ul>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<p>Understanding the codebase:</p> <pre><code>jsonl-algebra/\n\u251c\u2500\u2500 ja/                      # Main package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 core.py             # Core operations (select, project, etc.)\n\u2502   \u251c\u2500\u2500 cli.py              # CLI entry point\n\u2502   \u251c\u2500\u2500 commands.py         # CLI command handlers\n\u2502   \u251c\u2500\u2500 expr.py             # Expression evaluator\n\u2502   \u251c\u2500\u2500 group.py            # Grouping operations\n\u2502   \u251c\u2500\u2500 compose.py          # Composability/pipelines\n\u2502   \u251c\u2500\u2500 schema.py           # Schema inference/validation\n\u2502   \u251c\u2500\u2500 repl.py             # Interactive REPL\n\u2502   \u251c\u2500\u2500 shell.py            # ja-shell filesystem navigator\n\u2502   \u2514\u2500\u2500 vfs.py              # Virtual filesystem for ja-shell\n\u251c\u2500\u2500 integrations/           # Integrations\n\u2502   \u251c\u2500\u2500 mcp_server.py       # MCP server\n\u2502   \u251c\u2500\u2500 log_analyzer.py     # Log analyzer\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 tests/                  # Test suite\n\u251c\u2500\u2500 docs/                   # Documentation\n\u251c\u2500\u2500 examples/               # Example data and scripts\n\u2514\u2500\u2500 scripts/                # Utility scripts\n</code></pre>"},{"location":"contributing/#key-modules","title":"Key Modules","text":"<p>ja/core.py - Core relational operations: - <code>select()</code> - Filter rows - <code>project()</code> - Choose fields - <code>join()</code> - Combine datasets - <code>union()</code>, <code>intersection()</code>, <code>difference()</code> - <code>distinct()</code> - <code>sort_by()</code></p> <p>ja/group.py - Grouping and aggregation: - <code>groupby_with_metadata()</code> - Add grouping metadata - <code>groupby_agg()</code> - Group and aggregate - Aggregation functions (sum, avg, count, etc.)</p> <p>ja/cli.py - Command-line interface: - Argument parsing - Command routing - Error handling</p> <p>ja/expr.py - Expression evaluation: - Safe expression parser - Comparison operators - Nested field access</p>"},{"location":"contributing/#feature-development","title":"Feature Development","text":""},{"location":"contributing/#adding-a-new-operation","title":"Adding a New Operation","text":"<p>Example: Adding a <code>reverse</code> operation</p> <ol> <li>Implement in core.py:</li> </ol> <pre><code>def reverse(data: List[Dict]) -&gt; List[Dict]:\n    \"\"\"Reverse the order of rows.\n\n    Args:\n        data: List of dictionaries to reverse\n\n    Returns:\n        List in reversed order\n\n    Example:\n        &gt;&gt;&gt; data = [{\"id\": 1}, {\"id\": 2}]\n        &gt;&gt;&gt; list(reverse(data))\n        [{\"id\": 2}, {\"id\": 1}]\n    \"\"\"\n    return list(reversed(data))\n</code></pre> <ol> <li>Add CLI command in commands.py:</li> </ol> <pre><code>def handle_reverse(args, data_stream):\n    \"\"\"Handle reverse command.\"\"\"\n    data = list(data_stream)\n    reversed_data = reverse(data)\n    for row in reversed_data:\n        print(json.dumps(row))\n</code></pre> <ol> <li>Add argument parser in cli.py:</li> </ol> <pre><code># In build_parser()\nreverse_parser = subparsers.add_parser(\n    'reverse',\n    help='Reverse row order'\n)\nreverse_parser.add_argument(\n    'file',\n    nargs='?',\n    help='Input JSONL file (default: stdin)'\n)\n</code></pre> <ol> <li>Wire up in cli.py:</li> </ol> <pre><code># In main()\nelif args.command == 'reverse':\n    handle_reverse(args, data_stream)\n</code></pre> <ol> <li>Write tests in tests/test_core.py:</li> </ol> <pre><code>def test_reverse_basic():\n    \"\"\"Test basic reverse operation.\"\"\"\n    data = [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]\n    result = list(reverse(data))\n\n    assert len(result) == 3\n    assert result[0][\"id\"] == 3\n    assert result[1][\"id\"] == 2\n    assert result[2][\"id\"] == 1\n\ndef test_reverse_empty():\n    \"\"\"Test reverse with empty data.\"\"\"\n    data = []\n    result = list(reverse(data))\n    assert result == []\n</code></pre> <ol> <li>Document in docs/cli/commands.md:</li> </ol> <pre><code>### reverse\n\nReverse the order of rows.\n\n**Usage:**\n\n ```bash\nja reverse [file]\n ```\n\n**Examples:**\n\n ```bash\n# Reverse users.jsonl\nja reverse users.jsonl\n\n# Reverse from stdin\ncat users.jsonl | ja reverse\n ```\n</code></pre> <ol> <li>Add to CHANGELOG.md</li> </ol>"},{"location":"contributing/#integration-development","title":"Integration Development","text":"<p>Creating a new integration:</p> <ol> <li>Create file in <code>integrations/</code></li> <li>Follow existing patterns</li> <li>Add comprehensive docstrings</li> <li>Create tests</li> <li>Write README/documentation</li> <li>Update <code>integrations/README.md</code></li> </ol> <p>See Integrations Overview for details.</p>"},{"location":"contributing/#release-process","title":"Release Process","text":"<p>(For maintainers)</p> <ol> <li>Update version in pyproject.toml</li> <li>Update CHANGELOG.md</li> <li>Run full test suite: <pre><code>pytest\n</code></pre></li> <li>Build documentation: <pre><code>mkdocs build\n</code></pre></li> <li>Create release commit: <pre><code>git commit -am \"Release v1.2.0\"\ngit tag v1.2.0\n</code></pre></li> <li>Build package: <pre><code>python -m build\n</code></pre></li> <li>Upload to PyPI: <pre><code>twine upload dist/*\n</code></pre></li> <li>Push to GitHub: <pre><code>git push origin main --tags\n</code></pre></li> </ol>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":""},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers</li> <li>Assume good intentions</li> <li>Give constructive feedback</li> <li>Focus on the issue, not the person</li> </ul>"},{"location":"contributing/#communication","title":"Communication","text":"<ul> <li>GitHub Issues - Bug reports and feature requests</li> <li>Pull Requests - Code contributions</li> <li>Discussions - General questions and ideas</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in:</p> <ul> <li>CONTRIBUTORS.md file</li> <li>Release notes</li> <li>GitHub contributors page</li> </ul>"},{"location":"contributing/#getting-help","title":"Getting Help","text":""},{"location":"contributing/#questions-about-contributing","title":"Questions About Contributing","text":"<ul> <li>Check this guide</li> <li>Read existing PRs for examples</li> <li>Ask in GitHub Discussions</li> <li>Open an issue if stuck</li> </ul>"},{"location":"contributing/#need-ideas","title":"Need Ideas?","text":"<p>Look for issues labeled:</p> <ul> <li><code>good first issue</code> - Good for newcomers</li> <li><code>help wanted</code> - We'd love contributions</li> <li><code>documentation</code> - Improve docs</li> <li><code>enhancement</code> - New features</li> </ul>"},{"location":"contributing/#thank-you","title":"Thank You!","text":"<p>Every contribution makes jsonl-algebra better. Whether you're fixing a typo, reporting a bug, or implementing a major feature, your help is appreciated!</p>"},{"location":"contributing/#additional-resources","title":"Additional Resources","text":"<ul> <li>Testing Strategy - Detailed testing guide</li> <li>Development Setup - Advanced setup</li> <li>Architecture Overview - Design principles</li> <li>API Reference - Code documentation</li> </ul> <p>Happy contributing! \ud83d\ude80</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>Common questions about jsonl-algebra and their answers.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-jsonl-algebra","title":"What is jsonl-algebra?","text":"<p>jsonl-algebra (command: <code>ja</code>) is a command-line tool and Python library for manipulating JSONL (JSON Lines) data using relational algebra operations like select, project, join, and groupby.</p>"},{"location":"faq/#what-is-jsonl","title":"What is JSONL?","text":"<p>JSONL (JSON Lines) is a format where each line is a valid JSON object:</p> <pre><code>{\"id\": 1, \"name\": \"Alice\"}\n{\"id\": 2, \"name\": \"Bob\"}\n</code></pre> <p>Unlike JSON arrays, JSONL files can be processed line-by-line, making them ideal for streaming and large datasets.</p>"},{"location":"faq/#do-i-need-to-know-relational-algebra-to-use-ja","title":"Do I need to know relational algebra to use ja?","text":"<p>No! While ja is based on relational algebra principles, you don't need mathematical knowledge to use it. The commands are intuitive:</p> <ul> <li><code>select</code> = filter rows</li> <li><code>project</code> = choose columns</li> <li><code>join</code> = combine datasets</li> <li><code>groupby</code> = aggregate data</li> </ul>"},{"location":"faq/#whats-the-difference-between-ja-and-jq","title":"What's the difference between ja and jq?","text":"Feature ja jq Data format JSONL (one object per line) JSON (any structure) Operations Relational algebra Query language Learning curve Low (SQL-like) Medium (custom syntax) Streaming Built-in Partial Joins Native support Complex Best for Tabular data, logs, datasets Tree transformations <p>Use ja for: Filtering, joining, and aggregating structured data Use jq for: Complex JSON transformations and restructuring</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#how-do-i-install-jsonl-algebra","title":"How do I install jsonl-algebra?","text":"<pre><code>pip install jsonl-algebra\n</code></pre> <p>See the Installation Guide for detailed instructions.</p>"},{"location":"faq/#what-python-version-do-i-need","title":"What Python version do I need?","text":"<p>Python 3.8 or higher is required.</p>"},{"location":"faq/#can-i-use-ja-without-installing-python","title":"Can I use ja without installing Python?","text":"<p>No, ja is a Python-based tool and requires Python to be installed. However, once Python is installed, setup is just one command: <code>pip install jsonl-algebra</code>.</p>"},{"location":"faq/#how-do-i-upgrade-to-the-latest-version","title":"How do I upgrade to the latest version?","text":"<pre><code>pip install --upgrade jsonl-algebra\n</code></pre>"},{"location":"faq/#is-ja-available-for-windows","title":"Is ja available for Windows?","text":"<p>Yes! ja works on Windows, macOS, and Linux. On Windows, we recommend using WSL2 for the best experience, but it also works in PowerShell and Command Prompt.</p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#how-do-i-filter-rows-in-a-jsonl-file","title":"How do I filter rows in a JSONL file?","text":"<p>Use the <code>select</code> command:</p> <pre><code>ja select 'age &gt; 30' users.jsonl\n</code></pre>"},{"location":"faq/#how-do-i-choose-specific-fields","title":"How do I choose specific fields?","text":"<p>Use the <code>project</code> command:</p> <pre><code>ja project name,email users.jsonl\n</code></pre>"},{"location":"faq/#how-do-i-join-two-jsonl-files","title":"How do I join two JSONL files?","text":"<p>Use the <code>join</code> command:</p> <pre><code>ja join users.jsonl orders.jsonl --on user_id=customer_id\n</code></pre>"},{"location":"faq/#can-i-pipe-ja-commands-together","title":"Can I pipe ja commands together?","text":"<p>Yes! That's the recommended way to build complex operations:</p> <pre><code>cat data.jsonl | ja select 'active == true' | ja project id,name | ja sort name\n</code></pre>"},{"location":"faq/#how-do-i-save-output-to-a-file","title":"How do I save output to a file?","text":"<p>Use shell redirection:</p> <pre><code>ja select 'age &gt; 30' users.jsonl &gt; filtered.jsonl\n</code></pre> <p>Or use the <code>--output</code> flag:</p> <pre><code>ja select 'age &gt; 30' --output filtered.jsonl users.jsonl\n</code></pre>"},{"location":"faq/#how-do-i-work-with-nested-fields","title":"How do I work with nested fields?","text":"<p>Use dot notation:</p> <pre><code># Access nested field\nja project user.profile.email data.jsonl\n\n# Filter on nested field\nja select 'user.age &gt; 30' data.jsonl\n</code></pre>"},{"location":"faq/#can-i-use-ja-with-stdin","title":"Can I use ja with stdin?","text":"<p>Yes! ja reads from stdin when no file is specified:</p> <pre><code>cat data.jsonl | ja select 'x &gt; 0'\necho '{\"name\": \"Alice\"}' | ja project name\ncurl https://api.example.com/data | ja select 'status == \"active\"'\n</code></pre>"},{"location":"faq/#data-format-questions","title":"Data Format Questions","text":""},{"location":"faq/#whats-the-difference-between-json-and-jsonl-files","title":"What's the difference between .json and .jsonl files?","text":"<p>JSON (.json): <pre><code>[\n  {\"id\": 1, \"name\": \"Alice\"},\n  {\"id\": 2, \"name\": \"Bob\"}\n]\n</code></pre></p> <p>JSONL (.jsonl): <pre><code>{\"id\": 1, \"name\": \"Alice\"}\n{\"id\": 2, \"name\": \"Bob\"}\n</code></pre></p> <p>JSONL is better for: - Streaming (process line-by-line) - Appending (just add new lines) - Large files (constant memory usage) - Log files</p>"},{"location":"faq/#can-ja-work-with-regular-json-files","title":"Can ja work with regular JSON files?","text":"<p>ja is designed for JSONL, but you can convert:</p> <pre><code># JSON array to JSONL\ncat array.json | jq -c '.[]' &gt; data.jsonl\n\n# JSONL to JSON array\nja collect data.jsonl &gt; array.json\n</code></pre>"},{"location":"faq/#how-do-i-convert-csv-to-jsonl","title":"How do I convert CSV to JSONL?","text":"<p>Use the import command:</p> <pre><code>ja import csv data.csv &gt; data.jsonl\n</code></pre>"},{"location":"faq/#how-do-i-convert-jsonl-to-csv","title":"How do I convert JSONL to CSV?","text":"<p>Use the export command:</p> <pre><code>ja export csv data.jsonl &gt; data.csv\n</code></pre>"},{"location":"faq/#can-ja-handle-nested-json-structures","title":"Can ja handle nested JSON structures?","text":"<p>Yes! Use dot notation to access nested fields:</p> <pre><code>{\"user\": {\"profile\": {\"email\": \"alice@example.com\"}}}\n</code></pre> <pre><code>ja project user.profile.email data.jsonl\n</code></pre>"},{"location":"faq/#performance-questions","title":"Performance Questions","text":""},{"location":"faq/#can-ja-handle-large-files","title":"Can ja handle large files?","text":"<p>Yes! ja uses streaming, so it can process files larger than available RAM. Memory usage is constant per operation.</p>"},{"location":"faq/#how-do-i-make-operations-faster","title":"How do I make operations faster?","text":"<ol> <li> <p>Filter early - Reduce data size before expensive operations    <pre><code>ja select 'status == \"active\"' huge.jsonl | ja groupby category\n</code></pre></p> </li> <li> <p>Use specific commands - Don't use pipes unnecessarily    <pre><code># Good (one pass)\nja select 'a &gt; 10 and b &lt; 20' data.jsonl\n\n# Bad (two passes)\nja select 'a &gt; 10' data.jsonl | ja select 'b &lt; 20'\n</code></pre></p> </li> <li> <p>Limit output - Use <code>head</code> for sampling    <pre><code>ja sort score --desc huge.jsonl | head -100\n</code></pre></p> </li> </ol>"},{"location":"faq/#why-is-sortgroupby-slower-than-select","title":"Why is sort/groupby slower than select?","text":"<p>Some operations require seeing all data:</p> <ul> <li>Streaming (fast, constant memory): <code>select</code>, <code>project</code>, <code>rename</code></li> <li>Buffering (slower, grows with data): <code>sort</code>, <code>distinct</code>, <code>groupby</code>, <code>join</code></li> </ul>"},{"location":"faq/#can-i-process-multiple-files-in-parallel","title":"Can I process multiple files in parallel?","text":"<p>Yes, using GNU parallel or xargs:</p> <pre><code>ls *.jsonl | parallel 'ja select \"status == \\\"active\\\"\" {} &gt; {.}_active.jsonl'\n</code></pre>"},{"location":"faq/#expression-syntax-questions","title":"Expression &amp; Syntax Questions","text":""},{"location":"faq/#what-operators-can-i-use-in-expressions","title":"What operators can I use in expressions?","text":"Operator Purpose Example <code>==</code> Equal <code>status == \"active\"</code> <code>!=</code> Not equal <code>role != \"admin\"</code> <code>&gt;</code> Greater than <code>age &gt; 30</code> <code>&lt;</code> Less than <code>price &lt; 100</code> <code>&gt;=</code> Greater or equal <code>score &gt;= 90</code> <code>&lt;=</code> Less or equal <code>count &lt;= 10</code> <code>and</code> Logical AND <code>age &gt; 18 and status == \"active\"</code> <code>or</code> Logical OR <code>role == \"admin\" or role == \"owner\"</code>"},{"location":"faq/#how-do-i-check-for-null-values","title":"How do I check for null values?","text":"<pre><code>ja select 'field == null' data.jsonl    # Is null\nja select 'field != null' data.jsonl    # Is not null\n</code></pre>"},{"location":"faq/#how-do-i-use-quotes-in-expressions","title":"How do I use quotes in expressions?","text":"<p>Use different quote types:</p> <pre><code># Outer single quotes, inner double quotes\nja select 'name == \"Alice\"' data.jsonl\n\n# Or escape\nja select \"name == \\\"Alice\\\"\" data.jsonl\n</code></pre>"},{"location":"faq/#can-i-use-regular-expressions","title":"Can I use regular expressions?","text":"<p>Not directly in expressions, but you can use <code>grep</code>:</p> <pre><code>ja project message logs.jsonl | grep -E \"error|warning\"\n</code></pre>"},{"location":"faq/#how-do-i-compare-strings","title":"How do I compare strings?","text":"<p>Strings use lexicographic (dictionary) ordering:</p> <pre><code>ja select 'name &gt; \"M\"' users.jsonl  # Names starting with N-Z\n</code></pre>"},{"location":"faq/#feature-questions","title":"Feature Questions","text":""},{"location":"faq/#does-ja-support-aggregations","title":"Does ja support aggregations?","text":"<p>Yes! Use <code>groupby</code> with <code>--agg</code>:</p> <pre><code>ja groupby category --agg count,total=sum:amount data.jsonl\n</code></pre> <p>Available aggregations: - <code>count</code> - Count rows - <code>sum:field</code> - Sum values - <code>avg:field</code> - Average - <code>min:field</code> - Minimum - <code>max:field</code> - Maximum - <code>list:field</code> - Collect into array</p>"},{"location":"faq/#can-i-do-leftrightouter-joins","title":"Can I do left/right/outer joins?","text":"<p>Yes! Use the <code>--left</code>, <code>--right</code>, or <code>--outer</code> flags:</p> <pre><code>ja join users.jsonl orders.jsonl --on id=user_id --left\n</code></pre>"},{"location":"faq/#is-there-an-interactive-mode","title":"Is there an interactive mode?","text":"<p>Yes! Use the REPL:</p> <pre><code>ja repl users.jsonl\n</code></pre> <p>Or try ja-shell for filesystem-like navigation:</p> <pre><code>ja-shell\n</code></pre>"},{"location":"faq/#can-i-validate-data-schemas","title":"Can I validate data schemas?","text":"<p>Yes! Infer and validate JSON schemas:</p> <pre><code># Infer schema\nja schema infer data.jsonl &gt; schema.json\n\n# Validate data\nja schema validate schema.json new_data.jsonl\n</code></pre>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#command-not-found-ja","title":"Command not found: ja","text":"<p>The installation directory may not be in your PATH. Try:</p> <pre><code># Check if installed\npip show jsonl-algebra\n\n# Add to PATH (Linux/Mac)\nexport PATH=\"$HOME/.local/bin:$PATH\"\n\n# Or use full path\npython -m ja.cli select 'x &gt; 0' data.jsonl\n</code></pre>"},{"location":"faq/#invalid-expression-error","title":"Invalid expression error","text":"<p>Check your expression syntax:</p> <pre><code># Wrong - missing quotes around strings\nja select 'name == Alice' data.jsonl\n\n# Right - strings need quotes\nja select 'name == \"Alice\"' data.jsonl\n</code></pre>"},{"location":"faq/#memory-error-with-large-files","title":"Memory error with large files","text":"<p>Some operations buffer data. Solutions:</p> <ol> <li>Filter first to reduce size</li> <li>Use sampling with <code>head</code></li> <li>Split file into chunks</li> <li>Increase system memory</li> </ol>"},{"location":"faq/#json-decode-error","title":"JSON decode error","text":"<p>Check that your file is valid JSONL:</p> <pre><code># Validate each line\ncat data.jsonl | python -m json.tool\n\n# Find problematic lines\nawk 'NR==1 || !system(\"echo \" $0 \" | python -m json.tool &gt; /dev/null 2&gt;&amp;1\")' data.jsonl\n</code></pre>"},{"location":"faq/#output-looks-wrong","title":"Output looks wrong","text":"<p>ja outputs JSONL by default (one object per line). For pretty printing:</p> <pre><code># Pretty print with jq\nja select 'x &gt; 0' data.jsonl | jq '.'\n\n# Or convert to JSON array\nja collect data.jsonl | jq '.'\n</code></pre>"},{"location":"faq/#advanced-usage","title":"Advanced Usage","text":""},{"location":"faq/#can-i-use-ja-in-scripts","title":"Can I use ja in scripts?","text":"<p>Yes! ja is designed for scripting:</p> <pre><code>#!/bin/bash\nif ja select 'status == \"active\"' users.jsonl &gt; active.jsonl; then\n    echo \"Found $(wc -l &lt; active.jsonl) active users\"\nelse\n    echo \"Error filtering users\" &gt;&amp;2\n    exit 1\nfi\n</code></pre>"},{"location":"faq/#how-do-i-use-ja-programmatically-in-python","title":"How do I use ja programmatically in Python?","text":"<p>Import the library:</p> <pre><code>from ja.core import read_jsonl, select, project, join\n\nusers = read_jsonl(\"users.jsonl\")\nfiltered = select(users, \"age &gt; 30\")\nprojected = project(filtered, [\"name\", \"email\"])\n\nfor record in projected:\n    print(record)\n</code></pre>"},{"location":"faq/#can-i-extend-ja-with-custom-operations","title":"Can I extend ja with custom operations?","text":"<p>Yes! You can:</p> <ol> <li>Use the Python API to create custom functions</li> <li>Build integrations (see Integrations)</li> <li>Contribute to the project</li> </ol>"},{"location":"faq/#how-do-i-process-streaming-data","title":"How do I process streaming data?","text":"<p>ja works with streaming inputs:</p> <pre><code># Process logs in real-time\ntail -f /var/log/app.log | ja select 'level == \"ERROR\"'\n\n# From API stream\ncurl -N https://api.example.com/stream | ja project id,timestamp\n</code></pre>"},{"location":"faq/#integration-questions","title":"Integration Questions","text":""},{"location":"faq/#what-is-the-mcp-server","title":"What is the MCP server?","text":"<p>The Model Context Protocol server lets AI assistants use ja operations. See MCP Integration.</p>"},{"location":"faq/#can-i-use-ja-with-other-tools","title":"Can I use ja with other tools?","text":"<p>Yes! ja works great with:</p> <ul> <li>jq - For complex JSON transformations</li> <li>awk/sed - For text processing</li> <li>grep - For pattern matching</li> <li>parallel - For parallel processing</li> <li>curl - For API data</li> <li>pandas - For data analysis</li> </ul>"},{"location":"faq/#does-ja-work-with-databases","title":"Does ja work with databases?","text":"<p>Not directly, but you can:</p> <ol> <li>Export database to JSONL</li> <li>Process with ja</li> <li>Import results back</li> </ol> <p>Many databases support JSON export.</p>"},{"location":"faq/#contributing-development","title":"Contributing &amp; Development","text":""},{"location":"faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>See the Contributing Guide for details:</p> <ul> <li>Report bugs</li> <li>Suggest features</li> <li>Submit pull requests</li> <li>Improve documentation</li> <li>Share use cases</li> </ul>"},{"location":"faq/#where-is-the-source-code","title":"Where is the source code?","text":"<p>On GitHub: github.com/queelius/jsonl-algebra</p>"},{"location":"faq/#how-do-i-run-tests","title":"How do I run tests?","text":"<pre><code>pytest tests/\n</code></pre>"},{"location":"faq/#is-there-a-roadmap","title":"Is there a roadmap?","text":"<p>Check the GitHub issues and project boards for planned features.</p>"},{"location":"faq/#getting-help","title":"Getting Help","text":""},{"location":"faq/#where-can-i-get-help","title":"Where can I get help?","text":"<ol> <li>Read the documentation</li> <li>Check this FAQ</li> <li>Search GitHub issues</li> <li>Open a new issue</li> </ol>"},{"location":"faq/#how-do-i-report-a-bug","title":"How do I report a bug?","text":"<p>Open an issue on GitHub with:</p> <ul> <li>ja version (<code>ja --version</code>)</li> <li>Python version</li> <li>Operating system</li> <li>Minimal example to reproduce</li> <li>Expected vs actual behavior</li> </ul>"},{"location":"faq/#can-i-request-a-feature","title":"Can I request a feature?","text":"<p>Yes! Open a feature request on GitHub. Include:</p> <ul> <li>Use case description</li> <li>Example of desired behavior</li> <li>Why existing features don't work</li> </ul>"},{"location":"faq/#still-have-questions","title":"Still Have Questions?","text":"<ul> <li>Check the Tutorials for examples</li> <li>Read the CLI Reference for all commands</li> <li>Visit the GitHub Discussions</li> <li>Open an issue if you found a bug</li> </ul>"},{"location":"future-plans/","title":"Future Plans for ja","text":""},{"location":"future-plans/#lazy-evaluation-and-json-query-language","title":"Lazy Evaluation and JSON Query Language","text":""},{"location":"future-plans/#the-core-idea","title":"The Core Idea","text":"<p>What if we could represent JSONL algebra pipelines as JSON? Instead of executing each step immediately, we'd build a query plan that could be inspected, modified, and optimized before execution.</p>"},{"location":"future-plans/#simple-example","title":"Simple Example","text":"<pre><code># Current eager mode (executes immediately)\ncat orders.jsonl | ja select 'amount &gt; 100' | ja groupby customer | ja agg total=sum(amount)\n\n# Future lazy mode (builds query plan)\ncat orders.jsonl | ja query --build | ja select 'amount &gt; 100' | ja groupby customer | ja agg total=sum(amount)\n</code></pre> <p>This would output a JSON query plan: <pre><code>{\n  \"source\": \"stdin\",\n  \"operations\": [\n    {\"op\": \"select\", \"expr\": \"amount &gt; 100\"},\n    {\"op\": \"groupby\", \"key\": \"customer\"},\n    {\"op\": \"agg\", \"spec\": {\"total\": \"sum(amount)\"}}\n  ]\n}\n</code></pre></p>"},{"location":"future-plans/#why-this-matters","title":"Why This Matters","text":"<ol> <li>Inspection: See what will happen before it happens</li> <li>Optimization: Rearrange operations for better performance</li> <li>Reusability: Save and share query definitions</li> <li>Tooling: Other tools could generate or consume these plans</li> </ol>"},{"location":"future-plans/#multi-source-example","title":"Multi-Source Example","text":"<pre><code># A join pipeline\ncat transactions.jsonl | ja query --build | ja join users.jsonl --on user_id | ja select 'user.active == true'\n</code></pre> <p>Query plan: <pre><code>{\n  \"source\": \"stdin\",\n  \"operations\": [\n    {\n      \"op\": \"join\",\n      \"with\": \"users.jsonl\",\n      \"on\": [\"user_id\", \"id\"]\n    },\n    {\n      \"op\": \"select\",\n      \"expr\": \"user.active == true\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"future-plans/#execution-options","title":"Execution Options","text":"<pre><code># Build and save a query plan\nja query --build &lt; orders.jsonl &gt; plan.json\n\n# Execute a saved plan\nja query --execute plan.json &lt; orders.jsonl\n\n# Show what would happen (dry run)\nja query --explain plan.json\n</code></pre>"},{"location":"future-plans/#stdin-handling","title":"stdin Handling","text":"<p>For stdin sources, we keep it simple:</p> <pre><code># If stdin is too large for lazy mode\n$ cat huge_file.jsonl | ja query --build\nError: stdin too large for query building (&gt;10MB)\n\nOptions:\n1. Save to a file first: cat huge_file.jsonl &gt; data.jsonl\n2. Use eager mode: ja select ... (without --build)\n3. Use existing tools: cat huge_file.jsonl | head -10000 | ja query --build\n</code></pre>"},{"location":"future-plans/#integration-with-unix-tools","title":"Integration with Unix Tools","text":"<p>The beauty is that JSON query plans work well with existing tools:</p> <pre><code># Use jq to modify query plans\nja query --build &lt; data.jsonl | jq '.operations += [{\"op\": \"limit\", \"n\": 100}]' | ja query --execute\n\n# Version control your queries\ngit add queries/monthly_report.json\n\n# Generate queries programmatically\npython generate_query.py | ja query --execute &lt; data.jsonl\n</code></pre>"},{"location":"future-plans/#potential-benefits","title":"Potential Benefits","text":"<ol> <li> <p>Query Optimization <pre><code>{\n  \"original\": [\n    {\"op\": \"join\", \"with\": \"huge_file.jsonl\"},\n    {\"op\": \"select\", \"expr\": \"amount &gt; 1000\"}\n  ],\n  \"optimized\": [\n    {\"op\": \"select\", \"expr\": \"amount &gt; 1000\"},\n    {\"op\": \"join\", \"with\": \"huge_file.jsonl\"}\n  ]\n}\n</code></pre></p> </li> <li> <p>Debugging <pre><code>ja query --explain plan.json\n# Step 1: Load stdin (est. 10,000 rows)\n# Step 2: Filter where amount &gt; 100 (est. 2,000 rows)\n# Step 3: Group by customer (est. 500 groups)\n# Step 4: Aggregate sum(amount)\n</code></pre></p> </li> <li> <p>Alternative Execution Engines <pre><code># Future: Convert to SQL\nja query --to-sql plan.json\n# SELECT customer, SUM(amount) as total\n# FROM stdin\n# WHERE amount &gt; 100\n# GROUP BY customer\n</code></pre></p> </li> </ol>"},{"location":"future-plans/#open-questions","title":"Open Questions","text":"<ol> <li>Should this be part of <code>ja</code> or a separate tool?</li> <li>How much optimization is worth the complexity?</li> <li>What's the right balance between lazy and eager execution?</li> </ol>"},{"location":"future-plans/#next-steps","title":"Next Steps","text":"<p>Start simple: 1. Add <code>--dry-run</code> to show what an operation would do 2. Add <code>--explain</code> to show row count estimates 3. Gather feedback on whether full lazy evaluation is needed</p> <p>The goal is to enhance <code>ja</code>'s power while maintaining its simplicity. JSON query plans could be the bridge between simple command-line usage and more complex data processing needs.</p>"},{"location":"future-plans/#streaming-mode-and-window-processing","title":"Streaming Mode and Window Processing","text":""},{"location":"future-plans/#the-streaming-flag","title":"The --streaming Flag","text":"<p>Add a <code>--streaming</code> flag that enforces streaming constraints:</p> <pre><code># This would error\nja sort --streaming data.jsonl\nError: sort operation requires seeing all data and cannot be performed in streaming mode\n\n# This would work\nja select 'amount &gt; 100' --streaming data.jsonl\n</code></pre> <p>Benefits: - Explicit about memory usage expectations - Fail fast when streaming isn't possible - Good for production pipelines with memory constraints</p>"},{"location":"future-plans/#window-based-processing","title":"Window-Based Processing","text":"<p>For operations that normally require seeing all data, add <code>--window-size</code> support:</p> <pre><code># Sort within 1000-row windows\nja sort amount --window-size 1000 huge.jsonl\n\n# Collect groups within windows\nja groupby region huge.jsonl | ja collect --window-size 5000\n\n# Remove duplicates within windows\nja distinct --window-size 10000 huge.jsonl\n</code></pre> <p>This provides a middle ground: - Process arbitrarily large files - Trade completeness for memory efficiency - Useful for approximate results on huge datasets</p>"},{"location":"future-plans/#operations-by-streaming-capability","title":"Operations by Streaming Capability","text":""},{"location":"future-plans/#always-streaming","title":"Always Streaming","text":"<ul> <li><code>select</code> - Row-by-row filtering</li> <li><code>project</code> - Row-by-row transformation</li> <li><code>rename</code> - Row-by-row field renaming</li> <li><code>groupby</code> (without --agg) - Adds metadata only</li> </ul>"},{"location":"future-plans/#never-streaming-need-full-data","title":"Never Streaming (Need Full Data)","text":"<ul> <li><code>sort</code> - Must compare all rows</li> <li><code>distinct</code> - Must track all seen values</li> <li><code>groupby --agg</code> - Must see all groups</li> <li><code>collect</code> - Must gather all group members</li> <li><code>join</code> (currently) - Needs to load right side</li> </ul>"},{"location":"future-plans/#could-be-streaming","title":"Could Be Streaming","text":"<ul> <li><code>join</code> with pre-sorted data and merge join</li> <li><code>union</code> with duplicate handling disabled</li> <li><code>intersection/difference</code> with bloom filters</li> </ul>"},{"location":"future-plans/#implementation-plan","title":"Implementation Plan","text":"<ol> <li>Phase 1: Add <code>--streaming</code> flag to enforce constraints</li> <li>Phase 2: Implement <code>--window-size</code> for sort, distinct, collect</li> <li>Phase 3: Document streaming characteristics in help text</li> <li>Phase 4: Add approximate algorithms for streaming versions</li> </ol>"},{"location":"future-plans/#example-memory-conscious-pipeline","title":"Example: Memory-Conscious Pipeline","text":"<pre><code># Process 1TB log file with memory constraints\ncat huge_log.jsonl \\\n  | ja select 'level == \"ERROR\"' --streaming \\\n  | ja project timestamp,message,host \\\n  | ja groupby host \\\n  | ja collect --window-size 10000 \\\n  | ja agg errors=count --window-size 10000\n</code></pre> <p>This processes the entire file while never holding more than 10,000 rows in memory.</p>"},{"location":"future-plans/#path-like-matching","title":"Path-like Matching","text":"<p>We provide dot notation. We will extend this to support more complex matching.</p> <p>The path <code>field1.*.field2[&lt;condition-predicate&gt;].field4</code> can point to many values at <code>field4</code>. Maybe the value is a simple string or integer, or maybe it is arbititrarily complex JSON values. When we group by such a field, many values may be returned for a single JSONL line (JSON).</p> <p>When we perform a group-by operation, we group by the value at the end of that path. If two JSON lines have say the  same value associated to <code>field4</code> in the above example, then they placed in the same group. Right?</p> <p>Not so fast.</p> <p>Suppose we have a JSONL file with 3 entries:</p> <pre><code>{ \"a\": { \"key\" : \"value\" } } \n{ \"b\": { \"key\" : \"value\" } } \n{ \"c\": { \"key\" : \"other-value\" } } \n</code></pre> <p>If we group by <code>a.key</code>, we get one group with the value <code>value</code> and the other gru</p>"},{"location":"getting-started/","title":"Getting Started with ja","text":"<p>This guide walks you through jsonl-algebra's core concepts using realistic example data.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code># Basic installation\npip install jsonl-algebra\n\n# With dataset generation tools\npip install \"jsonl-algebra[dataset]\"\n</code></pre>"},{"location":"getting-started/#generate-example-data","title":"Generate Example Data","text":"<p>Let's start by creating some example data to work with:</p> <pre><code># Generate sample datasets\nja-generate-dataset --num-companies 8 --num-people 30 --output-dir examples/\n\n# This creates:\n# - examples/companies.jsonl (8 companies with nested headquarters data)\n# - examples/people.jsonl (30 people with nested personal info, jobs, and household relationships)\n</code></pre>"},{"location":"getting-started/#explore-the-data","title":"Explore the Data","text":""},{"location":"getting-started/#look-at-the-structure","title":"Look at the Structure","text":"<pre><code># See the first few records\nja examples/people.jsonl --head 2 --pretty\n\n# Check companies structure  \nja examples/companies.jsonl --head 2 --pretty\n</code></pre>"},{"location":"getting-started/#basic-filtering","title":"Basic Filtering","text":"<pre><code># Find people over 30\nja examples/people.jsonl --where 'person.age &gt; 30' --select person.name,person.age\n\n# Find tech companies\nja examples/companies.jsonl --where 'industry == \"Technology\"' --select name,size\n</code></pre>"},{"location":"getting-started/#working-with-nested-data","title":"Working with Nested Data","text":"<pre><code># Extract names and locations\nja examples/people.jsonl --select person.name,person.location.state,person.location.city\n\n# Group by location\nja examples/people.jsonl --group-by person.location.state --count\n</code></pre>"},{"location":"getting-started/#core-operations","title":"Core Operations","text":""},{"location":"getting-started/#selection-and-projection","title":"Selection and Projection","text":"<pre><code># Select high earners in California\nja examples/people.jsonl \\\\\n  --where 'person.job.salary &gt;= 80000 and person.location.state == \"CA\"' \\\\\n  --select person.name,person.job.title,person.job.salary\n\n# Project just essential job info\nja examples/people.jsonl \\\\\n  --select person.name.first,person.name.last,person.job.title,person.job.company_name\n</code></pre>"},{"location":"getting-started/#grouping-and-aggregation","title":"Grouping and Aggregation","text":"<pre><code># Count employees by company\nja examples/people.jsonl --group-by person.job.company_name --count\n\n# Average salary by company\nja examples/people.jsonl \\\\\n  --group-by person.job.company_name \\\\\n  --agg 'avg_salary=avg(person.job.salary),count=count(*)' \\\\\n  --sort-by avg_salary --reverse\n\n# Salary statistics by state\nja examples/people.jsonl \\\\\n  --group-by person.location.state \\\\\n  --agg 'avg_salary=avg(person.job.salary),min_salary=min(person.job.salary),max_salary=max(person.job.salary),count=count(*)'\n</code></pre>"},{"location":"getting-started/#joins","title":"Joins","text":"<pre><code># Join people with their companies\nja examples/people.jsonl \\\\\n  --join examples/companies.jsonl \\\\\n  --on 'person.job.company_name = name' \\\\\n  --select person.name,person.job.title,name,industry,headquarters.city\n\n# Find people working for large tech companies\nja examples/people.jsonl \\\\\n  --join examples/companies.jsonl \\\\\n  --on 'person.job.company_name = name' \\\\\n  --where 'industry == \"Technology\" and size &gt; 1000' \\\\\n  --select person.name,person.job.title,name,size\n</code></pre>"},{"location":"getting-started/#advanced-examples","title":"Advanced Examples","text":""},{"location":"getting-started/#household-analysis","title":"Household Analysis","text":"<pre><code># Find households with multiple people\nja examples/people.jsonl \\\\\n  --group-by household_id \\\\\n  --agg 'count=count(*),members=collect(person.name.first)' \\\\\n  --where 'count &gt; 1' \\\\\n  --select household_id,count,members\n\n# Average age by household\nja examples/people.jsonl \\\\\n  --group-by household_id \\\\\n  --agg 'avg_age=avg(person.age),family_name=first(person.name.last)' \\\\\n  --select family_name,avg_age \\\\\n  --sort-by avg_age --reverse\n</code></pre>"},{"location":"getting-started/#multi-step-pipelines","title":"Multi-step Pipelines","text":"<pre><code># Complex analysis: High earners by industry and location\nja examples/people.jsonl \\\\\n  --join examples/companies.jsonl --on 'person.job.company_name = name' \\\\\n  --where 'person.job.salary &gt;= 70000' \\\\\n  --group-by 'industry,person.location.state' \\\\\n  --agg 'count=count(*),avg_salary=avg(person.job.salary)' \\\\\n  --where 'count &gt;= 2' \\\\\n  --sort-by avg_salary --reverse\n</code></pre>"},{"location":"getting-started/#chained-grouping","title":"Chained Grouping","text":"<pre><code># Group by industry, then by job title within each industry\nja examples/people.jsonl \\\\\n  --join examples/companies.jsonl --on 'person.job.company_name = name' \\\\\n  --group-by industry \\\\\n  --group-by person.job.title \\\\\n  --agg 'count=count(*),avg_salary=avg(person.job.salary)' \\\\\n  --sort-by avg_salary --reverse\n</code></pre>"},{"location":"getting-started/#key-concepts","title":"Key Concepts","text":""},{"location":"getting-started/#nested-json-navigation","title":"Nested JSON Navigation","text":"<p>ja uses JSONPath-like syntax to navigate nested structures:</p> <ul> <li><code>person.name.first</code> - Access nested fields with dots</li> <li><code>person.location.state</code> - Navigate deep into objects</li> <li><code>headquarters.city</code> - Works with any level of nesting</li> </ul>"},{"location":"getting-started/#algebraic-operations","title":"Algebraic Operations","text":"<p>ja operations are composable and can be chained:</p> <pre><code># Each operation produces a new relation\nja data.jsonl --where 'age &gt; 25' | ja --group-by department | ja --agg 'count=count(*)'\n</code></pre>"},{"location":"getting-started/#streaming-processing","title":"Streaming Processing","text":"<p>ja processes data in a streaming fashion, making it efficient for large datasets:</p> <pre><code># Generate larger dataset for testing\nja-generate-dataset --num-companies 100 --num-people 10000 --output-dir large/\n\n# Still processes efficiently\nja large/people.jsonl --group-by person.location.state --count\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Concepts Guide for deeper understanding</li> <li>Explore Chained Groups for advanced grouping</li> <li>Check out the Cookbook for real-world examples</li> <li>Try the Interactive REPL for experimentation</li> </ul>"},{"location":"getting-started/#generated-data-reference","title":"Generated Data Reference","text":"<p>The <code>ja-generate-dataset</code> command creates two related files:</p>"},{"location":"getting-started/#companiesjsonl-structure","title":"companies.jsonl Structure","text":"<pre><code>{\n  \"id\": \"uuid\",\n  \"name\": \"Company Name\",\n  \"industry\": \"Technology\",\n  \"headquarters\": {\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"},\n  \"size\": 1500,\n  \"founded\": 2010\n}\n</code></pre>"},{"location":"getting-started/#peoplejsonl-structure","title":"people.jsonl Structure","text":"<pre><code>{\n  \"id\": \"uuid\",\n  \"created_at\": \"2023-05-15T10:30:00Z\",\n  \"status\": \"active\",\n  \"household_id\": \"household-uuid\",\n  \"person\": {\n    \"name\": {\"first\": \"Sarah\", \"last\": \"Johnson\"},\n    \"age\": 32,\n    \"gender\": \"female\",\n    \"email\": \"sarah.johnson@gmail.com\",\n    \"phone\": \"555-123-4567\",\n    \"location\": {\"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\"},\n    \"interests\": [\"hiking\", \"photography\"],\n    \"job\": {\n      \"title\": \"Software Engineer\",\n      \"company_name\": \"Tech Solutions Inc\", \n      \"salary\": 95000.0\n    }\n  }\n}\n</code></pre> <p>The data includes realistic relationships:</p> <ul> <li>Employment: <code>person.job.company_name</code> matches company <code>name</code></li> <li>Households: People with the same <code>household_id</code> share last names and locations</li> <li>Geographic: Hierarchical city/state/country structure with <code>ja</code></li> </ul> <p>Welcome to <code>ja</code>, the JSONL Algebra toolkit! This guide will walk you through the basics of using <code>ja</code> to manipulate JSONL data with the power of relational algebra.</p>"},{"location":"getting-started/#what-is-jsonl","title":"What is JSONL?","text":"<p>JSONL (JSON Lines) is a convenient format for storing structured data where each line is a valid JSON object. It's perfect for streaming and processing large datasets because you can read it line by line.</p> <p>Example JSONL file: <pre><code>{\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n{\"name\": \"Bob\", \"age\": 25, \"city\": \"San Francisco\"}\n{\"name\": \"Charlie\", \"age\": 35, \"city\": \"New York\"}\n</code></pre></p>"},{"location":"getting-started/#installation_1","title":"Installation","text":"<pre><code>pip install jsonl-algebra\n</code></pre> <p>This installs the <code>ja</code> command-line tool and the Python library.</p>"},{"location":"getting-started/#your-first-commands","title":"Your First Commands","text":""},{"location":"getting-started/#1-viewing-data","title":"1. Viewing Data","text":"<p>The simplest operation is to view your data:</p> <pre><code>cat data.jsonl\n</code></pre>"},{"location":"getting-started/#2-selecting-rows-filtering","title":"2. Selecting Rows (Filtering)","text":"<p>Use <code>select</code> to filter rows based on conditions:</p> <pre><code># Select people over 30\nja select 'age &gt; `30`' data.jsonl\n\n# Select people from New York\nja select 'city == `\"New York\"`' data.jsonl\n</code></pre>"},{"location":"getting-started/#3-projecting-columns","title":"3. Projecting Columns","text":"<p>Use <code>project</code> to select specific fields:</p> <pre><code># Get just names and ages\nja project name,age data.jsonl\n\n# Project nested fields\nja project user.name,user.email users.jsonl\n</code></pre>"},{"location":"getting-started/#4-working-with-nested-data","title":"4. Working with Nested Data","text":"<p><code>ja</code> excels at handling nested JSON structures:</p> <pre><code># Given nested data like:\n# {\"person\": {\"name\": {\"first\": \"Alice\", \"last\": \"Smith\"}, \"age\": 30}}\n\n# Project nested fields\nja project person.name.first data.jsonl\n\n# Flatten nested structures\nja project person.name.first,person.age --flatten data.jsonl\n# Output: {\"person.name.first\": \"Alice\", \"person.age\": 30}\n</code></pre>"},{"location":"getting-started/#a-complete-example","title":"A Complete Example","text":"<p>Let's walk through a real-world scenario. You have two files:</p> <p>users.jsonl: <pre><code>{\"id\": 1, \"name\": \"Alice\", \"department\": \"Sales\"}\n{\"id\": 2, \"name\": \"Bob\", \"department\": \"Engineering\"}\n{\"id\": 3, \"name\": \"Charlie\", \"department\": \"Sales\"}\n</code></pre></p> <p>sales.jsonl: <pre><code>{\"user_id\": 1, \"amount\": 1000, \"date\": \"2024-01-01\"}\n{\"user_id\": 1, \"amount\": 1500, \"date\": \"2024-01-02\"}\n{\"user_id\": 2, \"amount\": 2000, \"date\": \"2024-01-01\"}\n{\"user_id\": 3, \"amount\": 1200, \"date\": \"2024-01-01\"}\n</code></pre></p> <p>Goal: Find total sales by department.</p> <pre><code># Step 1: Join users with their sales\nja join users.jsonl sales.jsonl --on id=user_id &gt; joined.jsonl\n\n# Step 2: Group by department and sum amounts\nja groupby department --agg total=sum(amount) joined.jsonl\n\n# Or do it all in one pipeline:\nja join users.jsonl sales.jsonl --on id=user_id | \\\n  ja groupby department --agg total=sum(amount)\n</code></pre> <p>Output: <pre><code>{\"department\": \"Sales\", \"total\": 3700}\n{\"department\": \"Engineering\", \"total\": 2000}\n</code></pre></p>"},{"location":"getting-started/#command-chaining","title":"Command Chaining","text":"<p>One of <code>ja</code>'s most powerful features is the ability to chain commands using Unix pipes:</p> <pre><code># Complex data pipeline\ncat data.jsonl | \\\n  ja select 'status == `\"active\"`' | \\\n  ja project user.name,amount | \\\n  ja sort amount --desc | \\\n  head -10\n</code></pre>"},{"location":"getting-started/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/#1-finding-unique-values","title":"1. Finding Unique Values","text":"<pre><code>ja project category data.jsonl | ja distinct\n</code></pre>"},{"location":"getting-started/#2-data-validation","title":"2. Data Validation","text":"<pre><code># Find records with missing fields\nja select '!email' users.jsonl\n</code></pre>"},{"location":"getting-started/#3-computing-statistics","title":"3. Computing Statistics","text":"<pre><code># Average order amount by customer\nja groupby customer_id --agg avg_amount=avg(amount) orders.jsonl\n</code></pre>"},{"location":"getting-started/#4-data-transformation","title":"4. Data Transformation","text":"<pre><code># Rename fields\nja rename old_name=new_name,price=cost data.jsonl\n\n# Flatten nested structures for export\nja project user.name,user.email,order.total --flatten data.jsonl | \\\n  ja export csv &gt; output.csv\n</code></pre>"},{"location":"getting-started/#next-steps_1","title":"Next Steps","text":"<ul> <li>Learn about Advanced Operations</li> <li>Explore the Interactive REPL</li> <li>Read about Schema Management</li> <li>Check out the API Reference</li> </ul>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<pre><code># General help\nja --help\n\n# Command-specific help\nja select --help\nja groupby --help\n</code></pre> <p>Remember: <code>ja</code> is designed to be intuitive. If you know SQL or have used Unix tools like <code>awk</code> or <code>sed</code>, you'll feel right at home!</p>"},{"location":"quickstart/","title":"Quickstart: Your First 5 Minutes with ja","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install jsonl-algebra\n</code></pre> <p>Verify it's working:</p> <pre><code>ja --version\n</code></pre>"},{"location":"quickstart/#your-first-pipeline","title":"Your First Pipeline","text":"<p>Let's analyze some order data. Create <code>orders.jsonl</code>:</p> <pre><code>{\"order_id\": 1, \"customer\": \"Alice\", \"amount\": 99.99, \"status\": \"shipped\"}\n{\"order_id\": 2, \"customer\": \"Bob\", \"amount\": 149.99, \"status\": \"pending\"}\n{\"order_id\": 3, \"customer\": \"Alice\", \"amount\": 79.99, \"status\": \"shipped\"}\n{\"order_id\": 4, \"customer\": \"Charlie\", \"amount\": 199.99, \"status\": \"shipped\"}\n{\"order_id\": 5, \"customer\": \"Bob\", \"amount\": 59.99, \"status\": \"cancelled\"}\n</code></pre>"},{"location":"quickstart/#1-filter-orders","title":"1. Filter Orders","text":"<p>Get only shipped orders:</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl\n</code></pre>"},{"location":"quickstart/#2-calculate-totals","title":"2. Calculate Totals","text":"<p>Total revenue from shipped orders:</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl | ja agg total=sum(amount)\n</code></pre> <p>Output:</p> <pre><code>{\"total\": 379.97}\n</code></pre>"},{"location":"quickstart/#3-group-by-customer","title":"3. Group by Customer","text":"<p>Revenue per customer (shipped only):</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl \\\n  | ja groupby customer \\\n  | ja agg revenue=sum(amount),orders=count\n</code></pre> <p>Output:</p> <pre><code>{\"customer\": \"Alice\", \"revenue\": 179.98, \"orders\": 2}\n{\"customer\": \"Charlie\", \"revenue\": 199.99, \"orders\": 1}\n</code></pre>"},{"location":"quickstart/#4-join-with-customer-data","title":"4. Join with Customer Data","text":"<p>Create <code>customers.jsonl</code>:</p> <pre><code>{\"name\": \"Alice\", \"tier\": \"gold\", \"region\": \"west\"}\n{\"name\": \"Bob\", \"tier\": \"silver\", \"region\": \"east\"}\n{\"name\": \"Charlie\", \"tier\": \"gold\", \"region\": \"west\"}\n</code></pre> <p>Join and analyze:</p> <pre><code>ja join customers.jsonl orders.jsonl --on name=customer \\\n  | ja select 'status == \"shipped\"' \\\n  | ja groupby region \\\n  | ja agg revenue=sum(amount)\n</code></pre> <p>Output:</p> <pre><code>{\"region\": \"west\", \"revenue\": 379.97}\n</code></pre>"},{"location":"quickstart/#5-multi-level-grouping","title":"5. Multi-Level Grouping","text":"<p>Showcase the power of chained groupby:</p> <pre><code>ja select 'status == \"shipped\"' orders.jsonl \\\n  | ja groupby customer \\\n  | ja groupby amount \\\n  | ja agg count\n</code></pre> <p>Output:</p> <pre><code>{\"customer\": \"Alice\", \"amount\": 99.99, \"count\": 1}\n{\"customer\": \"Alice\", \"amount\": 79.99, \"count\": 1}\n{\"customer\": \"Charlie\", \"amount\": 199.99, \"count\": 1}\n</code></pre>"},{"location":"quickstart/#key-concepts-demonstrated","title":"Key Concepts Demonstrated","text":"<ol> <li>Filtering: Use <code>select</code> with expressions</li> <li>Aggregation: Use <code>agg</code> for calculations</li> <li>Grouping: Use <code>groupby</code> to segment data</li> <li>Joining: Combine data from multiple files</li> <li>Chaining: Use pipes to build complex pipelines</li> <li>Multi-level Grouping: Chain groupby operations for hierarchical analysis</li> </ol>"},{"location":"quickstart/#interactive-mode","title":"Interactive Mode","text":"<p>Want to explore? Try the REPL:</p> <pre><code>ja repl\n\nja&gt; from orders.jsonl\nInput source set to: orders.jsonl\nja&gt; select status == \"shipped\"\nAdded: select status == \"shipped\"\nja&gt; groupby customer\nAdded: groupby customer\nja&gt; agg revenue=sum(amount)\nAdded: agg revenue=sum(amount)\nja&gt; execute\nExecuting: ja select 'status == \"shipped\"' orders.jsonl | ja groupby customer - | ja agg revenue=sum(amount) -\n\n--- Output ---\n{\"customer\": \"Alice\", \"revenue\": 179.98}\n{\"customer\": \"Charlie\", \"revenue\": 199.99}\n--------------\n</code></pre>"},{"location":"quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"quickstart/#data-exploration","title":"Data Exploration","text":"<pre><code># See the structure\nja project customer,amount orders.jsonl | head -5\n\n# Find unique values\nja project status orders.jsonl | ja distinct\n\n# Quick statistics\nja agg count,avg_amount=avg(amount),total=sum(amount) orders.jsonl\n</code></pre>"},{"location":"quickstart/#filtering-and-aggregation","title":"Filtering and Aggregation","text":"<pre><code># Conditional aggregation\nja agg shipped_revenue=sum_if(amount,status==\"shipped\") orders.jsonl\n\n# Top customers\nja groupby customer orders.jsonl \\\n  | ja agg total=sum(amount) \\\n  | ja sort total --desc \\\n  | head -5\n</code></pre>"},{"location":"quickstart/#working-with-nested-data","title":"Working with Nested Data","text":"<pre><code># Assuming nested structure like {\"user\": {\"id\": 1, \"name\": \"Alice\"}}\nja project user.name,user.id nested.jsonl\nja groupby user.region nested.jsonl | ja agg count\nja select 'user.age &gt; 30' nested.jsonl\n</code></pre>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>Learn all operations \u2192</li> <li>Work with nested data \u2192</li> <li>Understand the theory \u2192</li> <li>See real examples \u2192</li> </ul>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<pre><code># General help\nja --help\n\n# Operation help\nja select --help\nja groupby --help\nja agg --help\n\n# Interactive help\nja repl\nja&gt; help\n</code></pre> <p>Welcome to the world of JSONL algebra! \ud83c\udf89</p>"},{"location":"reference/","title":"API Reference","text":"<p>Welcome to the complete API reference for JSONL Algebra. Every function and class is listed here with its full documentation.</p>"},{"location":"reference/#ja.core","title":"<code>ja.core</code>","text":"<p>Core relational operations for the JSONL algebra system.</p> <p>This module implements the fundamental set and relational operations that form the algebra for manipulating collections of JSON objects. All operations are designed to work with lists of dictionaries, making them suitable for processing JSONL data.</p>"},{"location":"reference/#ja.core-classes","title":"Classes","text":""},{"location":"reference/#ja.core-functions","title":"Functions","text":""},{"location":"reference/#ja.core.select","title":"<code>select(data, expr, use_jmespath=False)</code>","text":"<p>Filter rows based on an expression.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries to filter</p> required <code>expr</code> <code>str</code> <p>Expression to evaluate (simple expression or JMESPath)</p> required <code>use_jmespath</code> <code>bool</code> <p>If True, use JMESPath evaluation</p> <code>False</code> <p>Returns:</p> Type Description <code>Relation</code> <p>List of rows where the expression evaluates to true</p> Source code in <code>ja/core.py</code> <pre><code>def select(\n    data: Relation, expr: str, use_jmespath: bool = False\n) -&gt; Relation:\n    \"\"\"Filter rows based on an expression.\n\n    Args:\n        data: List of dictionaries to filter\n        expr: Expression to evaluate (simple expression or JMESPath)\n        use_jmespath: If True, use JMESPath evaluation\n\n    Returns:\n        List of rows where the expression evaluates to true\n    \"\"\"\n    if use_jmespath:\n        compiled_expr = jmespath.compile(expr)\n        return [row for row in data if compiled_expr.search(row)]\n\n    # Use simple expression parser\n    parser = ExprEval()\n    result = []\n\n    # Handle 'and' at the command level for simplicity\n    if \" and \" in expr:\n        # Multiple conditions with 'and'\n        conditions = expr.split(\" and \")\n        for row in data:\n            if all(parser.evaluate(cond.strip(), row) for cond in conditions):\n                result.append(row)\n    elif \" or \" in expr:\n        # Multiple conditions with 'or'\n        conditions = expr.split(\" or \")\n        for row in data:\n            if any(parser.evaluate(cond.strip(), row) for cond in conditions):\n                result.append(row)\n    else:\n        # Single condition\n        for row in data:\n            if parser.evaluate(expr, row):\n                result.append(row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.core.project","title":"<code>project(data, fields, use_jmespath=False)</code>","text":"<p>Project specific fields from each row.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries to project</p> required <code>fields</code> <code>List[str] | str</code> <p>Comma-separated field names or expressions</p> required <code>use_jmespath</code> <code>bool</code> <p>If True, use JMESPath for projection</p> <code>False</code> <p>Returns:</p> Type Description <code>Relation</code> <p>List of dictionaries with only the specified fields</p> Source code in <code>ja/core.py</code> <pre><code>def project(\n    data: Relation, fields: List[str] | str, use_jmespath: bool = False\n) -&gt; Relation:\n    \"\"\"Project specific fields from each row.\n\n    Args:\n        data: List of dictionaries to project\n        fields: Comma-separated field names or expressions\n        use_jmespath: If True, use JMESPath for projection\n\n    Returns:\n        List of dictionaries with only the specified fields\n    \"\"\"\n\n    if use_jmespath:\n        compiled_expr = jmespath.compile(fields)\n        return [compiled_expr.search(row) for row in data]\n\n    # Parse field specifications\n    result = []\n    parser = ExprEval()\n    field_specs = fields if isinstance(fields, list) else fields.split(\",\")\n\n    for row in data:\n        new_row = {}\n\n        for spec in field_specs:\n            if \"=\" in spec:\n                # Computed field: \"total=amount*1.1\" or \"is_adult=age&gt;=18\"\n                name, expr = spec.split(\"=\", 1)\n                name = name.strip()\n                expr = expr.strip()\n\n                # Check if it's an arithmetic expression\n                arith_result = parser.evaluate_arithmetic(expr, row)\n                if arith_result is not None:\n                    new_row[name] = arith_result\n                else:\n                    # Try as boolean expression\n                    new_row[name] = parser.evaluate(expr, row)\n            else:\n                # Simple field projection\n                value = parser.get_field_value(row, spec)\n                if value is not None:\n                    # Build nested structure\n                    parser.set_field_value(new_row, spec, value)\n\n        result.append(new_row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.core.join","title":"<code>join(left, right, on)</code>","text":"<p>Inner join with nested-key support.</p> Source code in <code>ja/core.py</code> <pre><code>def join(left: Relation,\n         right: Relation,\n         on: List[Tuple[str, str]]) -&gt; Relation:\n    \"\"\"Inner join with nested-key support.\"\"\"\n    parser = ExprEval()\n\n    # index right side\n    right_index: Dict[Tuple[Any, ...], List[Row]] = defaultdict(list)\n    for r in right:\n        key = tuple(parser.get_field_value(r, rk) for _, rk in on)\n        if all(v is not None for v in key):\n            right_index[key].append(r)\n\n    # roots of every RHS join path (e.g. 'user.id' \u2192 'user')\n    rhs_roots = {re.split(r\"[.\\[]\", rk, 1)[0] for _, rk in on}\n\n    joined: Relation = []\n    for l in left:\n        l_key = tuple(parser.get_field_value(l, lk) for lk, _ in on)\n        if not all(v is not None for v in l_key):\n            continue\n        for r in right_index.get(l_key, []):\n            merged = r.copy()\n            merged.update(l)          # left wins\n            # drop right-side join columns\n            for root in rhs_roots:\n                merged.pop(root, None)\n            joined.append(merged)\n    return joined\n</code></pre>"},{"location":"reference/#ja.core.product","title":"<code>product(left, right)</code>","text":"<p>Cartesian product; colliding keys from right are prefixed with <code>b_</code>.</p> Source code in <code>ja/core.py</code> <pre><code>def product(left: Relation, right: Relation) -&gt; Relation:\n    \"\"\"Cartesian product; colliding keys from *right* are prefixed with ``b_``.\"\"\"\n    result: Relation = []\n    for l in left:\n        for r in right:\n            merged = l.copy()\n            for k, v in r.items():\n                if k in merged:\n                    merged[f\"b_{k}\"] = v\n                else:\n                    merged[k] = v\n            result.append(merged)\n    return result\n</code></pre>"},{"location":"reference/#ja.core.rename","title":"<code>rename(data, mapping)</code>","text":"<p>Rename fields in each row.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries</p> required <code>mapping</code> <code>Dict[str, str]</code> <p>Dictionary mapping old names to new names</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List with renamed fields</p> Source code in <code>ja/core.py</code> <pre><code>def rename(data: Relation, mapping: Dict[str, str]) -&gt; Relation:\n    \"\"\"Rename fields in each row.\n\n    Args:\n        data: List of dictionaries\n        mapping: Dictionary mapping old names to new names\n\n    Returns:\n        List with renamed fields\n    \"\"\"\n    result = []\n    for row in data:\n        new_row = {}\n        for key, value in row.items():\n            new_key = mapping.get(key, key)\n            new_row[new_key] = value\n        result.append(new_row)\n    return result\n</code></pre>"},{"location":"reference/#ja.core.union","title":"<code>union(left, right)</code>","text":"<p>Compute the union of two collections.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Relation</code> <p>First collection</p> required <code>right</code> <code>Relation</code> <p>Second collection</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>Union of the two collections</p> Source code in <code>ja/core.py</code> <pre><code>def union(\n    left: Relation, right: Relation\n) -&gt; Relation:\n    \"\"\"Compute the union of two collections.\n\n    Args:\n        left: First collection\n        right: Second collection\n\n    Returns:\n        Union of the two collections\n    \"\"\"\n    return left + right\n</code></pre>"},{"location":"reference/#ja.core.intersection","title":"<code>intersection(left, right)</code>","text":"<p>Compute the intersection of two collections.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Relation</code> <p>First collection</p> required <code>right</code> <code>Relation</code> <p>Second collection</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>Intersection of the two collections</p> Source code in <code>ja/core.py</code> <pre><code>def intersection(\n    left: Relation, right: Relation\n) -&gt; Relation:\n    \"\"\"Compute the intersection of two collections.\n\n    Args:\n        left: First collection\n        right: Second collection\n\n    Returns:\n        Intersection of the two collections\n    \"\"\"\n    # Convert right to a set of tuples for efficient lookup\n    right_set = {tuple(sorted(row.items())) for row in right}\n\n    result = []\n    for row in left:\n        if tuple(sorted(row.items())) in right_set:\n            result.append(row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.core.difference","title":"<code>difference(left, right)</code>","text":"<p>Compute the difference of two collections.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>Relation</code> <p>First collection</p> required <code>right</code> <code>Relation</code> <p>Second collection</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>Elements in left but not in right</p> Source code in <code>ja/core.py</code> <pre><code>def difference(\n    left: Relation, right: Relation\n) -&gt; Relation:\n    \"\"\"Compute the difference of two collections.\n\n    Args:\n        left: First collection\n        right: Second collection\n\n    Returns:\n        Elements in left but not in right\n    \"\"\"\n    # Convert right to a set of tuples for efficient lookup\n    right_set = {tuple(sorted(row.items())) for row in right}\n\n    result = []\n    for row in left:\n        if tuple(sorted(row.items())) not in right_set:\n            result.append(row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.core.distinct","title":"<code>distinct(data)</code>","text":"<p>Remove duplicate rows from a collection.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List with duplicates removed</p> Source code in <code>ja/core.py</code> <pre><code>def distinct(data: Relation) -&gt; Relation:\n    \"\"\"Remove duplicate rows from a collection.\n\n    Args:\n        data: List of dictionaries\n\n    Returns:\n        List with duplicates removed\n    \"\"\"\n    seen = set()\n    result = []\n\n    for row in data:\n        # Convert to tuple for hashability\n        row_tuple = tuple(sorted(row.items()))\n        if row_tuple not in seen:\n            seen.add(row_tuple)\n            result.append(row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.core.collect","title":"<code>collect(data)</code>","text":"<p>Collect metadata-grouped rows into actual groups.</p> <p>This function takes rows with _groups metadata (from groupby operations) and collects them into explicit groups. Each output row represents one group with all its members in a _rows array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries with _groups metadata</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List where each dict represents a group with _rows array</p> Example <p>Input: [     {\"id\": 1, \"region\": \"North\", \"_groups\": [{\"field\": \"region\", \"value\": \"North\"}]},     {\"id\": 2, \"region\": \"North\", \"_groups\": [{\"field\": \"region\", \"value\": \"North\"}]},     {\"id\": 3, \"region\": \"South\", \"_groups\": [{\"field\": \"region\", \"value\": \"South\"}]} ]</p> <p>Output: [     {\"region\": \"North\", \"_rows\": [{\"id\": 1, \"region\": \"North\"}, {\"id\": 2, \"region\": \"North\"}]},     {\"region\": \"South\", \"_rows\": [{\"id\": 3, \"region\": \"South\"}]} ]</p> Source code in <code>ja/core.py</code> <pre><code>def collect(data: Relation) -&gt; Relation:\n    \"\"\"Collect metadata-grouped rows into actual groups.\n\n    This function takes rows with _groups metadata (from groupby operations)\n    and collects them into explicit groups. Each output row represents one\n    group with all its members in a _rows array.\n\n    Args:\n        data: List of dictionaries with _groups metadata\n\n    Returns:\n        List where each dict represents a group with _rows array\n\n    Example:\n        Input:\n        [\n            {\"id\": 1, \"region\": \"North\", \"_groups\": [{\"field\": \"region\", \"value\": \"North\"}]},\n            {\"id\": 2, \"region\": \"North\", \"_groups\": [{\"field\": \"region\", \"value\": \"North\"}]},\n            {\"id\": 3, \"region\": \"South\", \"_groups\": [{\"field\": \"region\", \"value\": \"South\"}]}\n        ]\n\n        Output:\n        [\n            {\"region\": \"North\", \"_rows\": [{\"id\": 1, \"region\": \"North\"}, {\"id\": 2, \"region\": \"North\"}]},\n            {\"region\": \"South\", \"_rows\": [{\"id\": 3, \"region\": \"South\"}]}\n        ]\n    \"\"\"\n    if not data:\n        return []\n\n    # Check if data has grouping metadata\n    if \"_groups\" not in data[0]:\n        # No grouping metadata - treat entire dataset as one group\n        return [{\"_rows\": data}]\n\n    # Collect rows by their group keys\n    groups = defaultdict(list)\n\n    for row in data:\n        # Build group key from metadata\n        group_key = tuple((g[\"field\"], g[\"value\"]) for g in row[\"_groups\"])\n\n        # Create clean row without metadata\n        clean_row = {k: v for k, v in row.items() if not k.startswith(\"_\")}\n\n        groups[group_key].append(clean_row)\n\n    # Build output with one row per group\n    result = []\n    for group_key, rows in groups.items():\n        group_dict = {}\n\n        # Add group fields to output\n        for field, value in group_key:\n            group_dict[field] = value\n\n        # Add collected rows\n        group_dict[\"_rows\"] = rows\n\n        result.append(group_dict)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.cli","title":"<code>ja.cli</code>","text":"<p>Command-line interface for JSONL algebra operations.</p> <p>This module provides the main CLI entry point and argument parsing for all JSONL algebra operations including relational algebra, schema inference, data import/export, and interactive REPL mode.</p>"},{"location":"reference/#ja.cli-functions","title":"Functions","text":""},{"location":"reference/#ja.cli.json_error","title":"<code>json_error(error_type, message, details=None, exit_code=1)</code>","text":"<p>Output error in JSON format and exit.</p> <p>Parameters:</p> Name Type Description Default <code>error_type</code> <p>Type of error (e.g., \"ParseError\", \"IOError\")</p> required <code>message</code> <p>Human-readable error message</p> required <code>details</code> <p>Optional dict with additional error details</p> <code>None</code> <code>exit_code</code> <p>Exit code (default: 1)</p> <code>1</code> Source code in <code>ja/cli.py</code> <pre><code>def json_error(error_type, message, details=None, exit_code=1):\n    \"\"\"Output error in JSON format and exit.\n\n    Args:\n        error_type: Type of error (e.g., \"ParseError\", \"IOError\")\n        message: Human-readable error message\n        details: Optional dict with additional error details\n        exit_code: Exit code (default: 1)\n    \"\"\"\n    error_obj = {\"error\": {\"type\": error_type, \"message\": message}}\n    if details:\n        error_obj[\"error\"][\"details\"] = details\n\n    # If stderr is not a tty (redirected/piped), always output JSON\n    # If stderr is a tty, output human-readable unless JA_JSON_ERRORS is set\n    if not sys.stderr.isatty() or os.environ.get(\"JA_JSON_ERRORS\"):\n        print(json.dumps(error_obj), file=sys.stderr)\n    else:\n        # Human-readable format for terminal\n        print(f\"ja: error: {message}\", file=sys.stderr)\n        if details:\n            for key, value in details.items():\n                if value is not None and key != \"traceback\":\n                    print(f\"  {key}: {value}\", file=sys.stderr)\n\n    sys.exit(exit_code)\n</code></pre>"},{"location":"reference/#ja.cli.handle_export_command_group","title":"<code>handle_export_command_group(args)</code>","text":"<p>Handle export subcommands by delegating to appropriate handlers.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>Parsed command line arguments with export_cmd attribute.</p> required Source code in <code>ja/cli.py</code> <pre><code>def handle_export_command_group(args):\n    \"\"\"Handle export subcommands by delegating to appropriate handlers.\n\n    Args:\n        args: Parsed command line arguments with export_cmd attribute.\n    \"\"\"\n    export_command_handlers = {\n        \"array\": handle_to_array,\n        \"jsonl\": handle_to_jsonl,\n        \"explode\": handle_explode,\n        \"csv\": handle_to_csv,\n    }\n    handler = export_command_handlers.get(args.export_cmd)\n    if handler:\n        handler(args)\n    else:\n        # This should not be reached if subcommands are handled correctly in main\n        print(f\"Unknown export command: {args.export_cmd}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.cli.handle_import_command_group","title":"<code>handle_import_command_group(args)</code>","text":"<p>Handle import subcommands by delegating to appropriate handlers.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <p>Parsed command line arguments with import_cmd attribute.</p> required Source code in <code>ja/cli.py</code> <pre><code>def handle_import_command_group(args):\n    \"\"\"Handle import subcommands by delegating to appropriate handlers.\n\n    Args:\n        args: Parsed command line arguments with import_cmd attribute.\n    \"\"\"\n    import_command_handlers = {\n        \"csv\": handle_import_csv,\n        \"implode\": handle_implode,\n    }\n    handler = import_command_handlers.get(args.import_cmd)\n    if handler:\n        handler(args)\n    else:\n        # This should not be reached if subcommands are handled correctly in main\n        print(f\"Unknown import command: {args.import_cmd}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.repl","title":"<code>ja.repl</code>","text":"<p>Interactive REPL (Read-Eval-Print Loop) for JSONL algebra operations.</p> <p>This module provides a powerful, interactive shell for JSONL data manipulation with named datasets, immediate execution, and a non-destructive design.</p> <p>Key features: - Named datasets: Load and manage multiple JSONL files by name - Safe operations: All transformations require unique output names - Immediate execution: See results right away, no pipeline building - File-based streaming: Store paths, not data (memory efficient) - Shell integration: Execute bash commands with !"},{"location":"reference/#ja.repl-classes","title":"Classes","text":""},{"location":"reference/#ja.repl.ReplSession","title":"<code>ReplSession</code>","text":"<p>Interactive REPL session for JSONL data manipulation.</p> <p>This class manages a workspace of named datasets (JSONL files) and provides commands for loading, transforming, and exploring data interactively.</p> <p>Design principles: - Non-destructive: Operations create new datasets, never modify originals - Explicit: All operations require unique output names - Streaming: Store file paths, not data in memory</p> Source code in <code>ja/repl.py</code> <pre><code>class ReplSession:\n    \"\"\"Interactive REPL session for JSONL data manipulation.\n\n    This class manages a workspace of named datasets (JSONL files) and provides\n    commands for loading, transforming, and exploring data interactively.\n\n    Design principles:\n    - Non-destructive: Operations create new datasets, never modify originals\n    - Explicit: All operations require unique output names\n    - Streaming: Store file paths, not data in memory\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the REPL session.\"\"\"\n        self.datasets: Dict[str, str] = {}  # name -&gt; file_path\n        self.current_dataset: Optional[str] = None\n        self.settings = {\n            \"window_size\": 20,  # Default preview limit\n        }\n        self.temp_dir = tempfile.mkdtemp(prefix=\"ja_repl_\")\n        self.temp_counter = 0\n\n    def _get_temp_file(self, name: str) -&gt; str:\n        \"\"\"Generate a unique temp file path for a dataset name.\"\"\"\n        self.temp_counter += 1\n        return os.path.join(self.temp_dir, f\"{name}_{self.temp_counter}.jsonl\")\n\n    def _check_name_conflict(self, name: str) -&gt; None:\n        \"\"\"Raise error if dataset name already exists.\"\"\"\n        if name in self.datasets:\n            raise ValueError(\n                f\"Dataset '{name}' already exists. Use a different name.\"\n            )\n\n    def _require_current(self) -&gt; str:\n        \"\"\"Raise error if no current dataset is set.\"\"\"\n        if self.current_dataset is None:\n            raise ValueError(\n                \"No current dataset. Use 'load &lt;file&gt;' or 'cd &lt;name&gt;' first.\"\n            )\n        return self.current_dataset\n\n    def _execute_ja_command(self, cmd_parts: list) -&gt; subprocess.CompletedProcess:\n        \"\"\"Execute a ja command and return the result.\"\"\"\n        cmd = shlex.join(cmd_parts)\n        try:\n            result = subprocess.run(\n                cmd,\n                shell=True,\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n            return result\n        except Exception as e:\n            raise RuntimeError(f\"Failed to execute command: {e}\")\n\n    # ==================== Command Handlers ====================\n\n    def handle_load(self, args):\n        \"\"\"Load a JSONL file into the workspace.\n\n        Usage: load &lt;file&gt; [name]\n\n        If name is not provided, uses the file stem (filename without extension).\n        The loaded dataset becomes the current dataset.\n        \"\"\"\n        if not args:\n            print(\"Error: 'load' requires a file path.\")\n            print(\"Usage: load &lt;file&gt; [name]\")\n            return\n\n        file_path = args[0]\n        if not os.path.exists(file_path):\n            print(f\"Error: File not found: {file_path}\")\n            return\n\n        # Determine dataset name\n        if len(args) &gt; 1:\n            name = args[1]\n        else:\n            name = Path(file_path).stem\n\n        # Check for conflicts\n        try:\n            self._check_name_conflict(name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        # Register the dataset\n        self.datasets[name] = os.path.abspath(file_path)\n        self.current_dataset = name\n        print(f\"Loaded: {name} (current)\")\n        print(f\"  Path: {self.datasets[name]}\")\n\n    def handle_cd(self, args):\n        \"\"\"Switch to a different dataset.\n\n        Usage: cd &lt;name&gt;\n        \"\"\"\n        if not args:\n            print(\"Error: 'cd' requires a dataset name.\")\n            print(\"Usage: cd &lt;name&gt;\")\n            return\n\n        name = args[0]\n        if name not in self.datasets:\n            print(f\"Error: Unknown dataset '{name}'.\")\n            print(f\"Available datasets: {', '.join(self.datasets.keys())}\")\n            return\n\n        self.current_dataset = name\n        print(f\"Current dataset: {name}\")\n\n    def handle_pwd(self, args):\n        \"\"\"Show the current dataset name and path.\n\n        Usage: pwd\n        Alias: current\n        \"\"\"\n        if self.current_dataset is None:\n            print(\"No current dataset.\")\n            return\n\n        print(f\"Current dataset: {self.current_dataset}\")\n        print(f\"  Path: {self.datasets[self.current_dataset]}\")\n\n    def handle_current(self, args):\n        \"\"\"Alias for pwd.\"\"\"\n        self.handle_pwd(args)\n\n    def handle_datasets(self, args):\n        \"\"\"List all registered datasets.\n\n        Usage: datasets\n\n        Shows all loaded datasets with a marker for the current one.\n        \"\"\"\n        if not self.datasets:\n            print(\"No datasets loaded.\")\n            return\n\n        print(\"Registered datasets:\")\n        for name in sorted(self.datasets.keys()):\n            marker = \" (current)\" if name == self.current_dataset else \"\"\n            print(f\"  {name}{marker}\")\n            print(f\"    {self.datasets[name]}\")\n\n    def handle_save(self, args):\n        \"\"\"Save the current dataset to a file.\n\n        Usage: save &lt;file&gt;\n\n        Writes the current dataset to the specified file path.\n        Does not register the file as a new dataset.\n        \"\"\"\n        if not args:\n            print(\"Error: 'save' requires a file path.\")\n            print(\"Usage: save &lt;file&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = args[0]\n        input_file = self.datasets[current]\n\n        # Copy the current dataset to the output file\n        try:\n            with open(input_file, 'r') as inf, open(output_file, 'w') as outf:\n                outf.write(inf.read())\n            print(f\"Saved {current} to: {output_file}\")\n        except Exception as e:\n            print(f\"Error saving file: {e}\")\n\n    def handle_ls(self, args):\n        \"\"\"Preview a dataset.\n\n        Usage: ls [name] [--limit N]\n\n        Shows the first N lines of the dataset (default: window_size setting).\n        If name is omitted, shows the current dataset.\n        \"\"\"\n        # Parse arguments\n        dataset_name = None\n        limit = self.settings[\"window_size\"]\n\n        i = 0\n        while i &lt; len(args):\n            arg = args[i]\n            if arg == \"--limit\":\n                if i + 1 &gt;= len(args):\n                    print(\"Error: --limit requires a number.\")\n                    return\n                try:\n                    limit = int(args[i + 1])\n                    i += 2\n                except ValueError:\n                    print(f\"Error: Invalid limit value '{args[i + 1]}'.\")\n                    return\n            elif arg.startswith(\"--limit=\"):\n                try:\n                    limit = int(arg.split(\"=\", 1)[1])\n                    i += 1\n                except ValueError:\n                    print(f\"Error: Invalid limit value in '{arg}'.\")\n                    return\n            else:\n                dataset_name = arg\n                i += 1\n\n        # Determine which dataset to show\n        if dataset_name is None:\n            try:\n                dataset_name = self._require_current()\n            except ValueError as e:\n                print(f\"Error: {e}\")\n                return\n        elif dataset_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{dataset_name}'.\")\n            return\n\n        file_path = self.datasets[dataset_name]\n\n        # Use head to show first N lines\n        try:\n            result = subprocess.run(\n                [\"head\", f\"-n{limit}\", file_path],\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n            if result.returncode == 0:\n                print(result.stdout.rstrip())\n            else:\n                print(f\"Error reading dataset: {result.stderr}\")\n        except Exception as e:\n            print(f\"Error: {e}\")\n\n    def handle_shell(self, args):\n        \"\"\"Execute a shell command.\n\n        Usage: !&lt;command&gt;\n\n        Passes the command directly to the shell.\n        \"\"\"\n        # args is already the full command (without the !)\n        cmd = \" \".join(args)\n        try:\n            result = subprocess.run(\n                cmd,\n                shell=True,\n                check=False,\n            )\n        except Exception as e:\n            print(f\"Error executing shell command: {e}\")\n\n    def handle_window_size(self, args):\n        \"\"\"Get or set the window size setting.\n\n        Usage: window-size [N]\n\n        Without arguments, shows the current value.\n        With a number, sets the value.\n        \"\"\"\n        if not args:\n            print(f\"window-size: {self.settings['window_size']}\")\n            return\n\n        try:\n            new_size = int(args[0])\n            if new_size &lt;= 0:\n                print(\"Error: window-size must be a positive integer.\")\n                return\n            self.settings[\"window_size\"] = new_size\n            print(f\"window-size set to: {new_size}\")\n        except ValueError:\n            print(f\"Error: Invalid number '{args[0]}'.\")\n\n    def handle_info(self, args):\n        \"\"\"Show statistics and information about a dataset.\n\n        Usage: info [name]\n\n        If name is omitted, shows info for the current dataset.\n        Displays: row count, file size, fields, and a sample row.\n        \"\"\"\n        # Determine which dataset to show info for\n        dataset_name = None\n        if args:\n            dataset_name = args[0]\n            if dataset_name not in self.datasets:\n                print(f\"Error: Unknown dataset '{dataset_name}'.\")\n                return\n        else:\n            try:\n                dataset_name = self._require_current()\n            except ValueError as e:\n                print(f\"Error: {e}\")\n                return\n\n        file_path = self.datasets[dataset_name]\n\n        try:\n            import json\n            import os\n\n            # Get file size\n            file_size = os.path.getsize(file_path)\n            if file_size &lt; 1024:\n                size_str = f\"{file_size} B\"\n            elif file_size &lt; 1024 * 1024:\n                size_str = f\"{file_size / 1024:.1f} KB\"\n            else:\n                size_str = f\"{file_size / (1024 * 1024):.1f} MB\"\n\n            # Count rows and collect field names\n            row_count = 0\n            all_fields = set()\n            first_row = None\n\n            with open(file_path, 'r') as f:\n                for line in f:\n                    if line.strip():\n                        row_count += 1\n                        try:\n                            obj = json.loads(line)\n                            if first_row is None:\n                                first_row = obj\n                            # Collect field names (flatten nested objects)\n                            self._collect_fields(obj, all_fields)\n                        except json.JSONDecodeError:\n                            pass  # Skip malformed lines\n\n            # Sort fields for consistent display\n            fields = sorted(all_fields)\n\n            # Display info\n            print(f\"\\nDataset: {dataset_name}\")\n            print(f\"Path: {file_path}\")\n            print(f\"Rows: {row_count:,}\")\n            print(f\"Size: {size_str}\")\n\n            if fields:\n                # Limit field display to avoid clutter\n                if len(fields) &lt;= 20:\n                    print(f\"Fields: {', '.join(fields)}\")\n                else:\n                    print(f\"Fields ({len(fields)} total): {', '.join(fields[:20])}, ...\")\n\n            if first_row:\n                print(f\"\\nSample (first row):\")\n                print(f\"  {json.dumps(first_row, indent=2)}\")\n\n            print()\n\n        except FileNotFoundError:\n            print(f\"Error: File not found: {file_path}\")\n        except Exception as e:\n            print(f\"Error reading dataset: {e}\")\n\n    def _collect_fields(self, obj, field_set, prefix=\"\"):\n        \"\"\"Recursively collect field names from a JSON object.\n\n        Nested fields are represented with dot notation (e.g., 'user.name').\n        \"\"\"\n        if isinstance(obj, dict):\n            for key, value in obj.items():\n                full_key = f\"{prefix}.{key}\" if prefix else key\n                field_set.add(full_key)\n                if isinstance(value, dict):\n                    self._collect_fields(value, field_set, full_key)\n                elif isinstance(value, list) and value and isinstance(value[0], dict):\n                    # For arrays of objects, show the array field plus nested fields\n                    self._collect_fields(value[0], field_set, full_key)\n        elif isinstance(obj, list) and obj and isinstance(obj[0], dict):\n            self._collect_fields(obj[0], field_set, prefix)\n\n    # ==================== Unary Operations ====================\n\n    def handle_select(self, args):\n        \"\"\"Filter rows with an expression.\n\n        Usage: select '&lt;expr&gt;' &lt;output_name&gt;\n\n        Creates a new dataset with filtered rows.\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'select' requires an expression and output name.\")\n            print(\"Usage: select '&lt;expr&gt;' &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        expr = args[0]\n        output_name = args[1]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        # Create temp file for output\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        # Execute: ja select '&lt;expr&gt;' &lt;input&gt; &gt; &lt;output&gt;\n        cmd_parts = [\"ja\", \"select\", expr, input_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            # Save output to temp file\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_project(self, args):\n        \"\"\"Select specific fields.\n\n        Usage: project &lt;fields&gt; &lt;output_name&gt;\n\n        Creates a new dataset with only the specified fields.\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'project' requires fields and output name.\")\n            print(\"Usage: project &lt;fields&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        fields = args[0]\n        output_name = args[1]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        cmd_parts = [\"ja\", \"project\", fields, input_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_rename(self, args):\n        \"\"\"Rename fields.\n\n        Usage: rename &lt;mapping&gt; &lt;output_name&gt;\n\n        Example: rename old=new,foo=bar output\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'rename' requires a mapping and output name.\")\n            print(\"Usage: rename &lt;old=new,...&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        mapping = args[0]\n        output_name = args[1]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        cmd_parts = [\"ja\", \"rename\", mapping, input_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_distinct(self, args):\n        \"\"\"Remove duplicate rows.\n\n        Usage: distinct &lt;output_name&gt;\n        \"\"\"\n        if len(args) &lt; 1:\n            print(\"Error: 'distinct' requires an output name.\")\n            print(\"Usage: distinct &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_name = args[0]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        cmd_parts = [\"ja\", \"distinct\", input_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_sort(self, args):\n        \"\"\"Sort rows by key(s).\n\n        Usage: sort &lt;keys&gt; [--desc] &lt;output_name&gt;\n\n        Example: sort age,name output\n        Example: sort age --desc output\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'sort' requires keys and output name.\")\n            print(\"Usage: sort &lt;keys&gt; [--desc] &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        # Parse args: keys, optional --desc, output_name\n        keys = args[0]\n        desc = False\n        output_name = args[-1]\n\n        if \"--desc\" in args:\n            desc = True\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        cmd_parts = [\"ja\", \"sort\", keys, input_file]\n        if desc:\n            cmd_parts.append(\"--desc\")\n\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_groupby(self, args):\n        \"\"\"Group rows by a key.\n\n        Usage: groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output_name&gt;\n\n        Example: groupby region output\n        Example: groupby region --agg count,sum(amount) output\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'groupby' requires a key and output name.\")\n            print(\"Usage: groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        key = args[0]\n        output_name = args[-1]\n\n        # Check for --agg\n        agg_spec = None\n        if \"--agg\" in args:\n            agg_idx = args.index(\"--agg\")\n            if agg_idx + 1 &lt; len(args) - 1:  # -1 because last is output_name\n                agg_spec = args[agg_idx + 1]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        input_file = self.datasets[current]\n\n        cmd_parts = [\"ja\", \"groupby\", key, input_file]\n        if agg_spec:\n            cmd_parts.extend([\"--agg\", agg_spec])\n\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    # ==================== Binary Operations ====================\n\n    def handle_join(self, args):\n        \"\"\"Join with another dataset.\n\n        Usage: join &lt;dataset_name&gt; --on &lt;mapping&gt; &lt;output_name&gt;\n\n        Example: join orders --on user_id=id user_orders\n        \"\"\"\n        if len(args) &lt; 4 or \"--on\" not in args:\n            print(\"Error: 'join' requires a dataset, --on mapping, and output name.\")\n            print(\"Usage: join &lt;dataset&gt; --on &lt;mapping&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        right_name = args[0]\n        if right_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{right_name}'.\")\n            return\n\n        on_idx = args.index(\"--on\")\n        on_mapping = args[on_idx + 1]\n        output_name = args[-1]\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        left_file = self.datasets[current]\n        right_file = self.datasets[right_name]\n\n        cmd_parts = [\"ja\", \"join\", left_file, right_file, \"--on\", on_mapping]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_union(self, args):\n        \"\"\"Union with another dataset.\n\n        Usage: union &lt;dataset_name&gt; &lt;output_name&gt;\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'union' requires a dataset name and output name.\")\n            print(\"Usage: union &lt;dataset&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        right_name = args[0]\n        output_name = args[1]\n\n        if right_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{right_name}'.\")\n            return\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        left_file = self.datasets[current]\n        right_file = self.datasets[right_name]\n\n        cmd_parts = [\"ja\", \"union\", left_file, right_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_intersection(self, args):\n        \"\"\"Intersection with another dataset.\n\n        Usage: intersection &lt;dataset_name&gt; &lt;output_name&gt;\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'intersection' requires a dataset name and output name.\")\n            print(\"Usage: intersection &lt;dataset&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        right_name = args[0]\n        output_name = args[1]\n\n        if right_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{right_name}'.\")\n            return\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        left_file = self.datasets[current]\n        right_file = self.datasets[right_name]\n\n        cmd_parts = [\"ja\", \"intersection\", left_file, right_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_difference(self, args):\n        \"\"\"Difference with another dataset.\n\n        Usage: difference &lt;dataset_name&gt; &lt;output_name&gt;\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'difference' requires a dataset name and output name.\")\n            print(\"Usage: difference &lt;dataset&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        right_name = args[0]\n        output_name = args[1]\n\n        if right_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{right_name}'.\")\n            return\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        left_file = self.datasets[current]\n        right_file = self.datasets[right_name]\n\n        cmd_parts = [\"ja\", \"difference\", left_file, right_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_product(self, args):\n        \"\"\"Cartesian product with another dataset.\n\n        Usage: product &lt;dataset_name&gt; &lt;output_name&gt;\n        \"\"\"\n        if len(args) &lt; 2:\n            print(\"Error: 'product' requires a dataset name and output name.\")\n            print(\"Usage: product &lt;dataset&gt; &lt;output_name&gt;\")\n            return\n\n        try:\n            current = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        right_name = args[0]\n        output_name = args[1]\n\n        if right_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{right_name}'.\")\n            return\n\n        try:\n            self._check_name_conflict(output_name)\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n        output_file = self._get_temp_file(output_name)\n        left_file = self.datasets[current]\n        right_file = self.datasets[right_name]\n\n        cmd_parts = [\"ja\", \"product\", left_file, right_file]\n        result = self._execute_ja_command(cmd_parts)\n\n        if result.returncode == 0:\n            with open(output_file, 'w') as f:\n                f.write(result.stdout)\n\n            self.datasets[output_name] = output_file\n            self.current_dataset = output_name\n            print(f\"Created: {output_name} (current)\")\n        else:\n            print(f\"Error: {result.stderr}\")\n\n    def handle_help(self, args):\n        \"\"\"Display help message.\"\"\"\n        help_text = \"\"\"\nJSONL Algebra REPL - Interactive Data Manipulation\n\nDATASET MANAGEMENT:\n  load &lt;file&gt; [name]           Load a JSONL file (default name: file stem)\n  cd &lt;name&gt;                    Switch to a dataset\n  pwd / current                Show current dataset\n  datasets                     List all registered datasets\n  info [name]                  Show dataset statistics (rows, size, fields)\n  save &lt;file&gt;                  Save current dataset to file\n\nUNARY OPERATIONS (operate on current dataset):\n  select '&lt;expr&gt;' &lt;output&gt;     Filter rows with expression\n  project &lt;fields&gt; &lt;output&gt;    Select specific fields (comma-separated)\n  rename &lt;old=new&gt; &lt;output&gt;    Rename fields\n  distinct &lt;output&gt;            Remove duplicates\n  sort &lt;keys&gt; [--desc] &lt;out&gt;   Sort by keys\n  groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output&gt;\n                               Group and optionally aggregate\n\nBINARY OPERATIONS (combine current with another dataset):\n  join &lt;dataset&gt; --on &lt;map&gt; &lt;output&gt;\n                               Join datasets on keys\n  union &lt;dataset&gt; &lt;output&gt;     Union of datasets\n  intersection &lt;dataset&gt; &lt;out&gt; Intersection of datasets\n  difference &lt;dataset&gt; &lt;out&gt;   Difference of datasets\n  product &lt;dataset&gt; &lt;output&gt;   Cartesian product\n\nVIEWING &amp; EXPLORATION:\n  ls [name] [--limit N]        Preview dataset (default: current)\n  !&lt;command&gt;                   Execute shell command\n\nSETTINGS:\n  window-size [N]              Get/set preview window size\n\nMETA:\n  help                         Show this help\n  exit                         Quit REPL\n\nNOTES:\n- All operations create NEW datasets with unique names\n- Use dot notation for nested fields (e.g., user.name)\n- Current dataset is used as input for operations\n- Operations automatically switch to the new output dataset\n\nEXAMPLES:\n  ja&gt; load users.jsonl\n  ja&gt; select 'age &gt; 30' adults\n  ja&gt; project name,email adults_contact\n  ja&gt; load orders.jsonl\n  ja&gt; cd adults_contact\n  ja&gt; join orders --on user_id=id final\n  ja&gt; ls --limit 5\n  ja&gt; save results.jsonl\n\"\"\"\n        print(help_text)\n\n    def parse_command(self, line: str):\n        \"\"\"Parse a command line into command and arguments.\"\"\"\n        try:\n            parts = shlex.split(line)\n        except ValueError as e:\n            print(f\"Error parsing command: {e}\")\n            return None, None\n\n        if not parts:\n            return None, None\n\n        command = parts[0].lower()\n        args = parts[1:]\n        return command, args\n\n    def process(self, line: str):\n        \"\"\"Process a single command line.\"\"\"\n        if not line or line.strip() == \"\":\n            return\n\n        # Handle shell commands\n        if line.startswith(\"!\"):\n            cmd = line[1:].strip()\n            self.handle_shell(shlex.split(cmd))\n            return\n\n        command, args = self.parse_command(line)\n        if command is None:\n            return\n\n        # Command routing\n        handlers = {\n            \"load\": self.handle_load,\n            \"cd\": self.handle_cd,\n            \"pwd\": self.handle_pwd,\n            \"current\": self.handle_current,\n            \"datasets\": self.handle_datasets,\n            \"info\": self.handle_info,\n            \"save\": self.handle_save,\n            \"ls\": self.handle_ls,\n            \"window-size\": self.handle_window_size,\n            \"select\": self.handle_select,\n            \"project\": self.handle_project,\n            \"rename\": self.handle_rename,\n            \"distinct\": self.handle_distinct,\n            \"sort\": self.handle_sort,\n            \"groupby\": self.handle_groupby,\n            \"join\": self.handle_join,\n            \"union\": self.handle_union,\n            \"intersection\": self.handle_intersection,\n            \"difference\": self.handle_difference,\n            \"product\": self.handle_product,\n            \"help\": self.handle_help,\n            \"exit\": lambda _: sys.exit(0),\n        }\n\n        handler = handlers.get(command)\n        if handler:\n            try:\n                handler(args)\n            except Exception as e:\n                print(f\"Error: {e}\")\n                import traceback\n                traceback.print_exc()\n        else:\n            print(f\"Unknown command: '{command}'. Type 'help' for available commands.\")\n\n    def run(self, initial_args=None):\n        \"\"\"Run the REPL main loop.\"\"\"\n        print(\"Welcome to ja REPL. Type 'help' for commands, 'exit' to quit.\")\n\n        # Handle initial args (e.g., ja repl data.jsonl)\n        if initial_args and len(initial_args) &gt; 0:\n            # Auto-load the file\n            initial_line = f\"load {shlex.join(initial_args)}\"\n            self.process(initial_line)\n\n        while True:\n            try:\n                line = input(\"ja&gt; \").strip()\n                self.process(line)\n            except EOFError:\n                print(\"\\nExiting...\")\n                sys.exit(0)\n            except KeyboardInterrupt:\n                print(\"\\nInterrupted. Type 'exit' or Ctrl-D to quit.\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession-functions","title":"Functions","text":""},{"location":"reference/#ja.repl.ReplSession.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the REPL session.</p> Source code in <code>ja/repl.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the REPL session.\"\"\"\n    self.datasets: Dict[str, str] = {}  # name -&gt; file_path\n    self.current_dataset: Optional[str] = None\n    self.settings = {\n        \"window_size\": 20,  # Default preview limit\n    }\n    self.temp_dir = tempfile.mkdtemp(prefix=\"ja_repl_\")\n    self.temp_counter = 0\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_load","title":"<code>handle_load(args)</code>","text":"<p>Load a JSONL file into the workspace.</p> <p>Usage: load  [name] <p>If name is not provided, uses the file stem (filename without extension). The loaded dataset becomes the current dataset.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_load(self, args):\n    \"\"\"Load a JSONL file into the workspace.\n\n    Usage: load &lt;file&gt; [name]\n\n    If name is not provided, uses the file stem (filename without extension).\n    The loaded dataset becomes the current dataset.\n    \"\"\"\n    if not args:\n        print(\"Error: 'load' requires a file path.\")\n        print(\"Usage: load &lt;file&gt; [name]\")\n        return\n\n    file_path = args[0]\n    if not os.path.exists(file_path):\n        print(f\"Error: File not found: {file_path}\")\n        return\n\n    # Determine dataset name\n    if len(args) &gt; 1:\n        name = args[1]\n    else:\n        name = Path(file_path).stem\n\n    # Check for conflicts\n    try:\n        self._check_name_conflict(name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    # Register the dataset\n    self.datasets[name] = os.path.abspath(file_path)\n    self.current_dataset = name\n    print(f\"Loaded: {name} (current)\")\n    print(f\"  Path: {self.datasets[name]}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_cd","title":"<code>handle_cd(args)</code>","text":"<p>Switch to a different dataset.</p> <p>Usage: cd  Source code in <code>ja/repl.py</code> <pre><code>def handle_cd(self, args):\n    \"\"\"Switch to a different dataset.\n\n    Usage: cd &lt;name&gt;\n    \"\"\"\n    if not args:\n        print(\"Error: 'cd' requires a dataset name.\")\n        print(\"Usage: cd &lt;name&gt;\")\n        return\n\n    name = args[0]\n    if name not in self.datasets:\n        print(f\"Error: Unknown dataset '{name}'.\")\n        print(f\"Available datasets: {', '.join(self.datasets.keys())}\")\n        return\n\n    self.current_dataset = name\n    print(f\"Current dataset: {name}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_pwd","title":"<code>handle_pwd(args)</code>","text":"<p>Show the current dataset name and path.</p> <p>Usage: pwd Alias: current</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_pwd(self, args):\n    \"\"\"Show the current dataset name and path.\n\n    Usage: pwd\n    Alias: current\n    \"\"\"\n    if self.current_dataset is None:\n        print(\"No current dataset.\")\n        return\n\n    print(f\"Current dataset: {self.current_dataset}\")\n    print(f\"  Path: {self.datasets[self.current_dataset]}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_current","title":"<code>handle_current(args)</code>","text":"<p>Alias for pwd.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_current(self, args):\n    \"\"\"Alias for pwd.\"\"\"\n    self.handle_pwd(args)\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_datasets","title":"<code>handle_datasets(args)</code>","text":"<p>List all registered datasets.</p> <p>Usage: datasets</p> <p>Shows all loaded datasets with a marker for the current one.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_datasets(self, args):\n    \"\"\"List all registered datasets.\n\n    Usage: datasets\n\n    Shows all loaded datasets with a marker for the current one.\n    \"\"\"\n    if not self.datasets:\n        print(\"No datasets loaded.\")\n        return\n\n    print(\"Registered datasets:\")\n    for name in sorted(self.datasets.keys()):\n        marker = \" (current)\" if name == self.current_dataset else \"\"\n        print(f\"  {name}{marker}\")\n        print(f\"    {self.datasets[name]}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_save","title":"<code>handle_save(args)</code>","text":"<p>Save the current dataset to a file.</p> <p>Usage: save  <p>Writes the current dataset to the specified file path. Does not register the file as a new dataset.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_save(self, args):\n    \"\"\"Save the current dataset to a file.\n\n    Usage: save &lt;file&gt;\n\n    Writes the current dataset to the specified file path.\n    Does not register the file as a new dataset.\n    \"\"\"\n    if not args:\n        print(\"Error: 'save' requires a file path.\")\n        print(\"Usage: save &lt;file&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = args[0]\n    input_file = self.datasets[current]\n\n    # Copy the current dataset to the output file\n    try:\n        with open(input_file, 'r') as inf, open(output_file, 'w') as outf:\n            outf.write(inf.read())\n        print(f\"Saved {current} to: {output_file}\")\n    except Exception as e:\n        print(f\"Error saving file: {e}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_ls","title":"<code>handle_ls(args)</code>","text":"<p>Preview a dataset.</p> <p>Usage: ls [name][--limit N]</p> <p>Shows the first N lines of the dataset (default: window_size setting). If name is omitted, shows the current dataset.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_ls(self, args):\n    \"\"\"Preview a dataset.\n\n    Usage: ls [name] [--limit N]\n\n    Shows the first N lines of the dataset (default: window_size setting).\n    If name is omitted, shows the current dataset.\n    \"\"\"\n    # Parse arguments\n    dataset_name = None\n    limit = self.settings[\"window_size\"]\n\n    i = 0\n    while i &lt; len(args):\n        arg = args[i]\n        if arg == \"--limit\":\n            if i + 1 &gt;= len(args):\n                print(\"Error: --limit requires a number.\")\n                return\n            try:\n                limit = int(args[i + 1])\n                i += 2\n            except ValueError:\n                print(f\"Error: Invalid limit value '{args[i + 1]}'.\")\n                return\n        elif arg.startswith(\"--limit=\"):\n            try:\n                limit = int(arg.split(\"=\", 1)[1])\n                i += 1\n            except ValueError:\n                print(f\"Error: Invalid limit value in '{arg}'.\")\n                return\n        else:\n            dataset_name = arg\n            i += 1\n\n    # Determine which dataset to show\n    if dataset_name is None:\n        try:\n            dataset_name = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n    elif dataset_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{dataset_name}'.\")\n        return\n\n    file_path = self.datasets[dataset_name]\n\n    # Use head to show first N lines\n    try:\n        result = subprocess.run(\n            [\"head\", f\"-n{limit}\", file_path],\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n        if result.returncode == 0:\n            print(result.stdout.rstrip())\n        else:\n            print(f\"Error reading dataset: {result.stderr}\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_shell","title":"<code>handle_shell(args)</code>","text":"<p>Execute a shell command.</p> <p>Usage: ! <p>Passes the command directly to the shell.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_shell(self, args):\n    \"\"\"Execute a shell command.\n\n    Usage: !&lt;command&gt;\n\n    Passes the command directly to the shell.\n    \"\"\"\n    # args is already the full command (without the !)\n    cmd = \" \".join(args)\n    try:\n        result = subprocess.run(\n            cmd,\n            shell=True,\n            check=False,\n        )\n    except Exception as e:\n        print(f\"Error executing shell command: {e}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_window_size","title":"<code>handle_window_size(args)</code>","text":"<p>Get or set the window size setting.</p> <p>Usage: window-size [N]</p> <p>Without arguments, shows the current value. With a number, sets the value.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_window_size(self, args):\n    \"\"\"Get or set the window size setting.\n\n    Usage: window-size [N]\n\n    Without arguments, shows the current value.\n    With a number, sets the value.\n    \"\"\"\n    if not args:\n        print(f\"window-size: {self.settings['window_size']}\")\n        return\n\n    try:\n        new_size = int(args[0])\n        if new_size &lt;= 0:\n            print(\"Error: window-size must be a positive integer.\")\n            return\n        self.settings[\"window_size\"] = new_size\n        print(f\"window-size set to: {new_size}\")\n    except ValueError:\n        print(f\"Error: Invalid number '{args[0]}'.\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_info","title":"<code>handle_info(args)</code>","text":"<p>Show statistics and information about a dataset.</p> <p>Usage: info [name]</p> <p>If name is omitted, shows info for the current dataset. Displays: row count, file size, fields, and a sample row.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_info(self, args):\n    \"\"\"Show statistics and information about a dataset.\n\n    Usage: info [name]\n\n    If name is omitted, shows info for the current dataset.\n    Displays: row count, file size, fields, and a sample row.\n    \"\"\"\n    # Determine which dataset to show info for\n    dataset_name = None\n    if args:\n        dataset_name = args[0]\n        if dataset_name not in self.datasets:\n            print(f\"Error: Unknown dataset '{dataset_name}'.\")\n            return\n    else:\n        try:\n            dataset_name = self._require_current()\n        except ValueError as e:\n            print(f\"Error: {e}\")\n            return\n\n    file_path = self.datasets[dataset_name]\n\n    try:\n        import json\n        import os\n\n        # Get file size\n        file_size = os.path.getsize(file_path)\n        if file_size &lt; 1024:\n            size_str = f\"{file_size} B\"\n        elif file_size &lt; 1024 * 1024:\n            size_str = f\"{file_size / 1024:.1f} KB\"\n        else:\n            size_str = f\"{file_size / (1024 * 1024):.1f} MB\"\n\n        # Count rows and collect field names\n        row_count = 0\n        all_fields = set()\n        first_row = None\n\n        with open(file_path, 'r') as f:\n            for line in f:\n                if line.strip():\n                    row_count += 1\n                    try:\n                        obj = json.loads(line)\n                        if first_row is None:\n                            first_row = obj\n                        # Collect field names (flatten nested objects)\n                        self._collect_fields(obj, all_fields)\n                    except json.JSONDecodeError:\n                        pass  # Skip malformed lines\n\n        # Sort fields for consistent display\n        fields = sorted(all_fields)\n\n        # Display info\n        print(f\"\\nDataset: {dataset_name}\")\n        print(f\"Path: {file_path}\")\n        print(f\"Rows: {row_count:,}\")\n        print(f\"Size: {size_str}\")\n\n        if fields:\n            # Limit field display to avoid clutter\n            if len(fields) &lt;= 20:\n                print(f\"Fields: {', '.join(fields)}\")\n            else:\n                print(f\"Fields ({len(fields)} total): {', '.join(fields[:20])}, ...\")\n\n        if first_row:\n            print(f\"\\nSample (first row):\")\n            print(f\"  {json.dumps(first_row, indent=2)}\")\n\n        print()\n\n    except FileNotFoundError:\n        print(f\"Error: File not found: {file_path}\")\n    except Exception as e:\n        print(f\"Error reading dataset: {e}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_select","title":"<code>handle_select(args)</code>","text":"<p>Filter rows with an expression.</p> <p>Usage: select ''  <p>Creates a new dataset with filtered rows.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_select(self, args):\n    \"\"\"Filter rows with an expression.\n\n    Usage: select '&lt;expr&gt;' &lt;output_name&gt;\n\n    Creates a new dataset with filtered rows.\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'select' requires an expression and output name.\")\n        print(\"Usage: select '&lt;expr&gt;' &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    expr = args[0]\n    output_name = args[1]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    # Create temp file for output\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    # Execute: ja select '&lt;expr&gt;' &lt;input&gt; &gt; &lt;output&gt;\n    cmd_parts = [\"ja\", \"select\", expr, input_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        # Save output to temp file\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_project","title":"<code>handle_project(args)</code>","text":"<p>Select specific fields.</p> <p>Usage: project  <p>Creates a new dataset with only the specified fields.</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_project(self, args):\n    \"\"\"Select specific fields.\n\n    Usage: project &lt;fields&gt; &lt;output_name&gt;\n\n    Creates a new dataset with only the specified fields.\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'project' requires fields and output name.\")\n        print(\"Usage: project &lt;fields&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    fields = args[0]\n    output_name = args[1]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    cmd_parts = [\"ja\", \"project\", fields, input_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_rename","title":"<code>handle_rename(args)</code>","text":"<p>Rename fields.</p> <p>Usage: rename  <p>Example: rename old=new,foo=bar output</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_rename(self, args):\n    \"\"\"Rename fields.\n\n    Usage: rename &lt;mapping&gt; &lt;output_name&gt;\n\n    Example: rename old=new,foo=bar output\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'rename' requires a mapping and output name.\")\n        print(\"Usage: rename &lt;old=new,...&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    mapping = args[0]\n    output_name = args[1]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    cmd_parts = [\"ja\", \"rename\", mapping, input_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_distinct","title":"<code>handle_distinct(args)</code>","text":"<p>Remove duplicate rows.</p> <p>Usage: distinct  Source code in <code>ja/repl.py</code> <pre><code>def handle_distinct(self, args):\n    \"\"\"Remove duplicate rows.\n\n    Usage: distinct &lt;output_name&gt;\n    \"\"\"\n    if len(args) &lt; 1:\n        print(\"Error: 'distinct' requires an output name.\")\n        print(\"Usage: distinct &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_name = args[0]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    cmd_parts = [\"ja\", \"distinct\", input_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_sort","title":"<code>handle_sort(args)</code>","text":"<p>Sort rows by key(s).</p> <p>Usage: sort  [--desc]  <p>Example: sort age,name output Example: sort age --desc output</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_sort(self, args):\n    \"\"\"Sort rows by key(s).\n\n    Usage: sort &lt;keys&gt; [--desc] &lt;output_name&gt;\n\n    Example: sort age,name output\n    Example: sort age --desc output\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'sort' requires keys and output name.\")\n        print(\"Usage: sort &lt;keys&gt; [--desc] &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    # Parse args: keys, optional --desc, output_name\n    keys = args[0]\n    desc = False\n    output_name = args[-1]\n\n    if \"--desc\" in args:\n        desc = True\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    cmd_parts = [\"ja\", \"sort\", keys, input_file]\n    if desc:\n        cmd_parts.append(\"--desc\")\n\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_groupby","title":"<code>handle_groupby(args)</code>","text":"<p>Group rows by a key.</p> <p>Usage: groupby  [--agg ]  <p>Example: groupby region output Example: groupby region --agg count,sum(amount) output</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_groupby(self, args):\n    \"\"\"Group rows by a key.\n\n    Usage: groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output_name&gt;\n\n    Example: groupby region output\n    Example: groupby region --agg count,sum(amount) output\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'groupby' requires a key and output name.\")\n        print(\"Usage: groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    key = args[0]\n    output_name = args[-1]\n\n    # Check for --agg\n    agg_spec = None\n    if \"--agg\" in args:\n        agg_idx = args.index(\"--agg\")\n        if agg_idx + 1 &lt; len(args) - 1:  # -1 because last is output_name\n            agg_spec = args[agg_idx + 1]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    input_file = self.datasets[current]\n\n    cmd_parts = [\"ja\", \"groupby\", key, input_file]\n    if agg_spec:\n        cmd_parts.extend([\"--agg\", agg_spec])\n\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_join","title":"<code>handle_join(args)</code>","text":"<p>Join with another dataset.</p> <p>Usage: join  --on  <p>Example: join orders --on user_id=id user_orders</p> Source code in <code>ja/repl.py</code> <pre><code>def handle_join(self, args):\n    \"\"\"Join with another dataset.\n\n    Usage: join &lt;dataset_name&gt; --on &lt;mapping&gt; &lt;output_name&gt;\n\n    Example: join orders --on user_id=id user_orders\n    \"\"\"\n    if len(args) &lt; 4 or \"--on\" not in args:\n        print(\"Error: 'join' requires a dataset, --on mapping, and output name.\")\n        print(\"Usage: join &lt;dataset&gt; --on &lt;mapping&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    right_name = args[0]\n    if right_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{right_name}'.\")\n        return\n\n    on_idx = args.index(\"--on\")\n    on_mapping = args[on_idx + 1]\n    output_name = args[-1]\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    left_file = self.datasets[current]\n    right_file = self.datasets[right_name]\n\n    cmd_parts = [\"ja\", \"join\", left_file, right_file, \"--on\", on_mapping]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_union","title":"<code>handle_union(args)</code>","text":"<p>Union with another dataset.</p> <p>Usage: union  Source code in <code>ja/repl.py</code> <pre><code>def handle_union(self, args):\n    \"\"\"Union with another dataset.\n\n    Usage: union &lt;dataset_name&gt; &lt;output_name&gt;\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'union' requires a dataset name and output name.\")\n        print(\"Usage: union &lt;dataset&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    right_name = args[0]\n    output_name = args[1]\n\n    if right_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{right_name}'.\")\n        return\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    left_file = self.datasets[current]\n    right_file = self.datasets[right_name]\n\n    cmd_parts = [\"ja\", \"union\", left_file, right_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_intersection","title":"<code>handle_intersection(args)</code>","text":"<p>Intersection with another dataset.</p> <p>Usage: intersection  Source code in <code>ja/repl.py</code> <pre><code>def handle_intersection(self, args):\n    \"\"\"Intersection with another dataset.\n\n    Usage: intersection &lt;dataset_name&gt; &lt;output_name&gt;\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'intersection' requires a dataset name and output name.\")\n        print(\"Usage: intersection &lt;dataset&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    right_name = args[0]\n    output_name = args[1]\n\n    if right_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{right_name}'.\")\n        return\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    left_file = self.datasets[current]\n    right_file = self.datasets[right_name]\n\n    cmd_parts = [\"ja\", \"intersection\", left_file, right_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_difference","title":"<code>handle_difference(args)</code>","text":"<p>Difference with another dataset.</p> <p>Usage: difference  Source code in <code>ja/repl.py</code> <pre><code>def handle_difference(self, args):\n    \"\"\"Difference with another dataset.\n\n    Usage: difference &lt;dataset_name&gt; &lt;output_name&gt;\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'difference' requires a dataset name and output name.\")\n        print(\"Usage: difference &lt;dataset&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    right_name = args[0]\n    output_name = args[1]\n\n    if right_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{right_name}'.\")\n        return\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    left_file = self.datasets[current]\n    right_file = self.datasets[right_name]\n\n    cmd_parts = [\"ja\", \"difference\", left_file, right_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_product","title":"<code>handle_product(args)</code>","text":"<p>Cartesian product with another dataset.</p> <p>Usage: product  Source code in <code>ja/repl.py</code> <pre><code>def handle_product(self, args):\n    \"\"\"Cartesian product with another dataset.\n\n    Usage: product &lt;dataset_name&gt; &lt;output_name&gt;\n    \"\"\"\n    if len(args) &lt; 2:\n        print(\"Error: 'product' requires a dataset name and output name.\")\n        print(\"Usage: product &lt;dataset&gt; &lt;output_name&gt;\")\n        return\n\n    try:\n        current = self._require_current()\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    right_name = args[0]\n    output_name = args[1]\n\n    if right_name not in self.datasets:\n        print(f\"Error: Unknown dataset '{right_name}'.\")\n        return\n\n    try:\n        self._check_name_conflict(output_name)\n    except ValueError as e:\n        print(f\"Error: {e}\")\n        return\n\n    output_file = self._get_temp_file(output_name)\n    left_file = self.datasets[current]\n    right_file = self.datasets[right_name]\n\n    cmd_parts = [\"ja\", \"product\", left_file, right_file]\n    result = self._execute_ja_command(cmd_parts)\n\n    if result.returncode == 0:\n        with open(output_file, 'w') as f:\n            f.write(result.stdout)\n\n        self.datasets[output_name] = output_file\n        self.current_dataset = output_name\n        print(f\"Created: {output_name} (current)\")\n    else:\n        print(f\"Error: {result.stderr}\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.handle_help","title":"<code>handle_help(args)</code>","text":"<p>Display help message.</p> Source code in <code>ja/repl.py</code> <pre><code>    def handle_help(self, args):\n        \"\"\"Display help message.\"\"\"\n        help_text = \"\"\"\nJSONL Algebra REPL - Interactive Data Manipulation\n\nDATASET MANAGEMENT:\n  load &lt;file&gt; [name]           Load a JSONL file (default name: file stem)\n  cd &lt;name&gt;                    Switch to a dataset\n  pwd / current                Show current dataset\n  datasets                     List all registered datasets\n  info [name]                  Show dataset statistics (rows, size, fields)\n  save &lt;file&gt;                  Save current dataset to file\n\nUNARY OPERATIONS (operate on current dataset):\n  select '&lt;expr&gt;' &lt;output&gt;     Filter rows with expression\n  project &lt;fields&gt; &lt;output&gt;    Select specific fields (comma-separated)\n  rename &lt;old=new&gt; &lt;output&gt;    Rename fields\n  distinct &lt;output&gt;            Remove duplicates\n  sort &lt;keys&gt; [--desc] &lt;out&gt;   Sort by keys\n  groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output&gt;\n                               Group and optionally aggregate\n\nBINARY OPERATIONS (combine current with another dataset):\n  join &lt;dataset&gt; --on &lt;map&gt; &lt;output&gt;\n                               Join datasets on keys\n  union &lt;dataset&gt; &lt;output&gt;     Union of datasets\n  intersection &lt;dataset&gt; &lt;out&gt; Intersection of datasets\n  difference &lt;dataset&gt; &lt;out&gt;   Difference of datasets\n  product &lt;dataset&gt; &lt;output&gt;   Cartesian product\n\nVIEWING &amp; EXPLORATION:\n  ls [name] [--limit N]        Preview dataset (default: current)\n  !&lt;command&gt;                   Execute shell command\n\nSETTINGS:\n  window-size [N]              Get/set preview window size\n\nMETA:\n  help                         Show this help\n  exit                         Quit REPL\n\nNOTES:\n- All operations create NEW datasets with unique names\n- Use dot notation for nested fields (e.g., user.name)\n- Current dataset is used as input for operations\n- Operations automatically switch to the new output dataset\n\nEXAMPLES:\n  ja&gt; load users.jsonl\n  ja&gt; select 'age &gt; 30' adults\n  ja&gt; project name,email adults_contact\n  ja&gt; load orders.jsonl\n  ja&gt; cd adults_contact\n  ja&gt; join orders --on user_id=id final\n  ja&gt; ls --limit 5\n  ja&gt; save results.jsonl\n\"\"\"\n        print(help_text)\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.parse_command","title":"<code>parse_command(line)</code>","text":"<p>Parse a command line into command and arguments.</p> Source code in <code>ja/repl.py</code> <pre><code>def parse_command(self, line: str):\n    \"\"\"Parse a command line into command and arguments.\"\"\"\n    try:\n        parts = shlex.split(line)\n    except ValueError as e:\n        print(f\"Error parsing command: {e}\")\n        return None, None\n\n    if not parts:\n        return None, None\n\n    command = parts[0].lower()\n    args = parts[1:]\n    return command, args\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.process","title":"<code>process(line)</code>","text":"<p>Process a single command line.</p> Source code in <code>ja/repl.py</code> <pre><code>def process(self, line: str):\n    \"\"\"Process a single command line.\"\"\"\n    if not line or line.strip() == \"\":\n        return\n\n    # Handle shell commands\n    if line.startswith(\"!\"):\n        cmd = line[1:].strip()\n        self.handle_shell(shlex.split(cmd))\n        return\n\n    command, args = self.parse_command(line)\n    if command is None:\n        return\n\n    # Command routing\n    handlers = {\n        \"load\": self.handle_load,\n        \"cd\": self.handle_cd,\n        \"pwd\": self.handle_pwd,\n        \"current\": self.handle_current,\n        \"datasets\": self.handle_datasets,\n        \"info\": self.handle_info,\n        \"save\": self.handle_save,\n        \"ls\": self.handle_ls,\n        \"window-size\": self.handle_window_size,\n        \"select\": self.handle_select,\n        \"project\": self.handle_project,\n        \"rename\": self.handle_rename,\n        \"distinct\": self.handle_distinct,\n        \"sort\": self.handle_sort,\n        \"groupby\": self.handle_groupby,\n        \"join\": self.handle_join,\n        \"union\": self.handle_union,\n        \"intersection\": self.handle_intersection,\n        \"difference\": self.handle_difference,\n        \"product\": self.handle_product,\n        \"help\": self.handle_help,\n        \"exit\": lambda _: sys.exit(0),\n    }\n\n    handler = handlers.get(command)\n    if handler:\n        try:\n            handler(args)\n        except Exception as e:\n            print(f\"Error: {e}\")\n            import traceback\n            traceback.print_exc()\n    else:\n        print(f\"Unknown command: '{command}'. Type 'help' for available commands.\")\n</code></pre>"},{"location":"reference/#ja.repl.ReplSession.run","title":"<code>run(initial_args=None)</code>","text":"<p>Run the REPL main loop.</p> Source code in <code>ja/repl.py</code> <pre><code>def run(self, initial_args=None):\n    \"\"\"Run the REPL main loop.\"\"\"\n    print(\"Welcome to ja REPL. Type 'help' for commands, 'exit' to quit.\")\n\n    # Handle initial args (e.g., ja repl data.jsonl)\n    if initial_args and len(initial_args) &gt; 0:\n        # Auto-load the file\n        initial_line = f\"load {shlex.join(initial_args)}\"\n        self.process(initial_line)\n\n    while True:\n        try:\n            line = input(\"ja&gt; \").strip()\n            self.process(line)\n        except EOFError:\n            print(\"\\nExiting...\")\n            sys.exit(0)\n        except KeyboardInterrupt:\n            print(\"\\nInterrupted. Type 'exit' or Ctrl-D to quit.\")\n</code></pre>"},{"location":"reference/#ja.repl-functions","title":"Functions","text":""},{"location":"reference/#ja.repl.repl","title":"<code>repl(parsed_cli_args)</code>","text":"<p>Entry point for the ja repl command.</p> Source code in <code>ja/repl.py</code> <pre><code>def repl(parsed_cli_args):\n    \"\"\"Entry point for the ja repl command.\"\"\"\n    session = ReplSession()\n    initial_args = getattr(parsed_cli_args, \"initial_args\", [])\n    session.run(initial_args)\n</code></pre>"},{"location":"reference/#ja.commands","title":"<code>ja.commands</code>","text":"<p>Command handlers for the JSONL algebra CLI.</p> <p>This module connects the command-line interface to the core data processing functions. Each <code>handle_*</code> function is responsible for reading input data, calling the appropriate core function, and writing the results to stdout.</p>"},{"location":"reference/#ja.commands-functions","title":"Functions","text":""},{"location":"reference/#ja.commands.get_input_stream","title":"<code>get_input_stream(file_path)</code>","text":"<p>Yield a readable file-like object.</p> <ul> <li>If file_path is None or '-', yield sys.stdin.</li> <li>Otherwise open the given path for reading.</li> </ul> Source code in <code>ja/commands.py</code> <pre><code>@contextmanager\ndef get_input_stream(file_path):\n    \"\"\"\n    Yield a readable file-like object.\n\n    - If file_path is None or '-', yield sys.stdin.\n    - Otherwise open the given path for reading.\n    \"\"\"\n    if file_path is not None and file_path != \"-\":\n        f = open(file_path, \"r\")\n        try:\n            yield f\n        finally:\n            f.close()\n    else:\n        yield sys.stdin\n</code></pre>"},{"location":"reference/#ja.commands.read_jsonl","title":"<code>read_jsonl(input_stream)</code>","text":"<p>Read JSONL data from a file-like object.</p> Source code in <code>ja/commands.py</code> <pre><code>def read_jsonl(input_stream) -&gt; List[Dict[str, Any]]:\n    \"\"\"Read JSONL data from a file-like object.\"\"\"\n    return [json.loads(line) for line in input_stream]\n</code></pre>"},{"location":"reference/#ja.commands.write_jsonl","title":"<code>write_jsonl(rows)</code>","text":"<p>Write a collection of objects as JSONL to stdout.</p> Source code in <code>ja/commands.py</code> <pre><code>def write_jsonl(rows: List[Dict[str, Any]]) -&gt; None:\n    \"\"\"Write a collection of objects as JSONL to stdout.\"\"\"\n    for row in rows:\n        print(json.dumps(row))\n</code></pre>"},{"location":"reference/#ja.commands.write_json_object","title":"<code>write_json_object(obj)</code>","text":"<p>Write a single object as pretty-printed JSON to stdout.</p> Source code in <code>ja/commands.py</code> <pre><code>def write_json_object(obj: Any) -&gt; None:\n    \"\"\"Write a single object as pretty-printed JSON to stdout.\"\"\"\n    print(json.dumps(obj, indent=2))\n</code></pre>"},{"location":"reference/#ja.commands.json_error","title":"<code>json_error(error_type, message, details=None)</code>","text":"<p>Print a JSON error message to stderr and exit.</p> Source code in <code>ja/commands.py</code> <pre><code>def json_error(error_type: str, message: str, details: Dict[str, Any] = None) -&gt; None:\n    \"\"\"Print a JSON error message to stderr and exit.\"\"\"\n    error_info = {\n        \"error\": {\n            \"type\": error_type,\n            \"message\": message,\n        }\n    }\n    if details:\n        error_info[\"error\"][\"details\"] = details\n    print(json.dumps(error_info), file=sys.stderr)\n    sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_select","title":"<code>handle_select(args)</code>","text":"<p>Handle select command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_select(args):\n    \"\"\"Handle select command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    use_jmespath = hasattr(args, \"jmespath\") and args.jmespath\n\n    try:\n        result = select(data, args.expr, use_jmespath=use_jmespath)\n        write_jsonl(result)\n    except jmespath.exceptions.ParseError as e:\n        json_error(\n            \"JMESPathParseError\",\n            f\"Invalid JMESPath expression: {e}\",\n            {\"expression\": args.expr},\n        )\n</code></pre>"},{"location":"reference/#ja.commands.handle_project","title":"<code>handle_project(args)</code>","text":"<p>Handle project command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_project(args):\n    \"\"\"Handle project command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    use_jmespath = hasattr(args, \"jmespath\") and args.jmespath\n\n    try:\n        result = project(data, args.expr, use_jmespath=use_jmespath)\n        write_jsonl(result)\n    except jmespath.exceptions.ParseError as e:\n        json_error(\n            \"JMESPathParseError\",\n            f\"Invalid JMESPath expression: {e}\",\n            {\"expression\": args.expr},\n        )\n</code></pre>"},{"location":"reference/#ja.commands.handle_join","title":"<code>handle_join(args)</code>","text":"<p>Handle join command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_join(args):\n    \"\"\"Handle join command.\"\"\"\n    with get_input_stream(args.left) as f:\n        left = read_jsonl(f)\n    with get_input_stream(args.right) as f:\n        right = read_jsonl(f)\n\n    lcol_str, rcol_str = args.on.split(\"=\", 1)\n    lcol = lcol_str.strip()\n    rcol = rcol_str.strip()\n\n    result = join(left, right, [(lcol, rcol)])\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_product","title":"<code>handle_product(args)</code>","text":"<p>Handle product command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_product(args):\n    \"\"\"Handle product command.\"\"\"\n    with get_input_stream(args.left) as f:\n        left_data = read_jsonl(f)\n    with get_input_stream(args.right) as f:\n        right_data = read_jsonl(f)\n\n    result = product(left_data, right_data)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_rename","title":"<code>handle_rename(args)</code>","text":"<p>Handle rename command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_rename(args):\n    \"\"\"Handle rename command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    mapping_pairs = args.mapping.split(\",\")\n    mapping = {}\n    for pair_str in mapping_pairs:\n        parts = pair_str.split(\"=\", 1)\n        if len(parts) == 2:\n            old_name, new_name = parts\n            mapping[old_name.strip()] = new_name.strip()\n        else:\n            print(\n                f\"Warning: Malformed rename pair '{pair_str.strip()}' ignored.\",\n                file=sys.stderr,\n            )\n\n    result = rename(data, mapping)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_union","title":"<code>handle_union(args)</code>","text":"<p>Handle union command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_union(args):\n    \"\"\"Handle union command.\"\"\"\n    with get_input_stream(args.left) as f:\n        left_data = read_jsonl(f)\n    with get_input_stream(args.right) as f:\n        right_data = read_jsonl(f)\n\n    result = union(left_data, right_data)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_intersection","title":"<code>handle_intersection(args)</code>","text":"<p>Handle intersection command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_intersection(args):\n    \"\"\"Handle intersection command.\"\"\"\n    with get_input_stream(args.left) as f:\n        left_data = read_jsonl(f)\n    with get_input_stream(args.right) as f:\n        right_data = read_jsonl(f)\n\n    result = intersection(left_data, right_data)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_difference","title":"<code>handle_difference(args)</code>","text":"<p>Handle difference command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_difference(args):\n    \"\"\"Handle difference command.\"\"\"\n    with get_input_stream(args.left) as f:\n        left_data = read_jsonl(f)\n    with get_input_stream(args.right) as f:\n        right_data = read_jsonl(f)\n\n    result = difference(left_data, right_data)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_distinct","title":"<code>handle_distinct(args)</code>","text":"<p>Handle distinct command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_distinct(args):\n    \"\"\"Handle distinct command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    result = distinct(data)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_sort","title":"<code>handle_sort(args)</code>","text":"<p>Handle sort command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_sort(args):\n    \"\"\"Handle sort command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    result = sort_by(data, args.keys, descending=args.desc)\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_groupby","title":"<code>handle_groupby(args)</code>","text":"<p>Handle groupby command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_groupby(args):\n    \"\"\"Handle groupby command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    if hasattr(args, \"agg\") and args.agg:\n        # Traditional groupby with aggregation\n        result = groupby_agg(data, args.key, args.agg)\n    else:\n        # Check if input is already grouped - look for new format\n        if data and \"_groups\" in data[0]:\n            # This is a chained groupby\n            result = groupby_chained(data, args.key)\n        else:\n            # First groupby\n            result = groupby_with_metadata(data, args.key)\n\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_agg","title":"<code>handle_agg(args)</code>","text":"<p>Handle agg command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_agg(args):\n    \"\"\"Handle agg command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    if not data:\n        write_jsonl([])\n        return\n\n    # Check if input has group metadata - use new format\n    if \"_groups\" in data[0]:\n        # Process grouped data\n        result = aggregate_grouped_data(data, args.agg)\n    else:\n        # Process ungrouped data\n        result = [aggregate_single_group(data, args.agg)]\n\n    write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.commands.handle_schema_infer","title":"<code>handle_schema_infer(args)</code>","text":"<p>Handle schema infer command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_schema_infer(args):\n    \"\"\"Handle schema infer command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    schema = infer_schema(data)\n    write_json_object(schema)\n</code></pre>"},{"location":"reference/#ja.commands.handle_to_array","title":"<code>handle_to_array(args)</code>","text":"<p>Handle to-array command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_to_array(args):\n    \"\"\"Handle to-array command.\"\"\"\n    with get_input_stream(args.file) as input_stream:\n        array_string = jsonl_to_json_array_string(input_stream)\n        print(array_string)\n</code></pre>"},{"location":"reference/#ja.commands.handle_to_jsonl","title":"<code>handle_to_jsonl(args)</code>","text":"<p>Handle to-jsonl command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_to_jsonl(args):\n    \"\"\"Handle to-jsonl command.\"\"\"\n    with get_input_stream(args.file) as input_stream:\n        try:\n            for line in json_array_to_jsonl_lines(input_stream):\n                print(line)\n        except ValueError as e:\n            print(f\"Error: {e}\", file=sys.stderr)\n            sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_explode","title":"<code>handle_explode(args)</code>","text":"<p>Handle explode command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_explode(args):\n    \"\"\"Handle explode command.\"\"\"\n    input_filename_stem = \"jsonl_output\"  # Default stem\n    if args.file and args.file != \"-\":\n        input_filename_stem = Path(args.file).stem\n\n    output_directory = args.output_dir if args.output_dir else input_filename_stem\n\n    with get_input_stream(args.file) as input_stream:\n        try:\n            jsonl_to_dir(input_stream, output_directory, input_filename_stem)\n        except Exception as e:\n            print(f\"Error during explode operation: {e}\", file=sys.stderr)\n            sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_implode","title":"<code>handle_implode(args)</code>","text":"<p>Handle implode command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_implode(args):\n    \"\"\"Handle implode command.\"\"\"\n    try:\n        for line in dir_to_jsonl_lines(\n            args.input_dir, args.add_filename_key, args.recursive\n        ):\n            print(line)\n    except ValueError as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"An unexpected error occurred during implode: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_import_csv","title":"<code>handle_import_csv(args)</code>","text":"<p>Handle import-csv command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_import_csv(args):\n    \"\"\"Handle import-csv command.\"\"\"\n    with get_input_stream(args.file) as input_stream:\n        try:\n            for line in csv_to_jsonl_lines(\n                input_stream, has_header=args.has_header, infer_types=args.infer_types\n            ):\n                print(line)\n        except Exception as e:\n            print(\n                f\"An unexpected error occurred during CSV import: {e}\", file=sys.stderr\n            )\n            sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_to_csv","title":"<code>handle_to_csv(args)</code>","text":"<p>Handle to-csv command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_to_csv(args):\n    \"\"\"Handle to-csv command.\"\"\"\n    column_functions = {}\n    if args.apply:\n        for col, expr_str in args.apply:\n            try:\n                # WARNING: eval() is a security risk if the expression is not from a trusted source.\n                func = eval(expr_str)\n                if not callable(func):\n                    raise ValueError(\n                        f\"Expression for column '{col}' did not evaluate to a callable function.\"\n                    )\n                column_functions[col] = func\n            except Exception as e:\n                print(\n                    f\"Error parsing --apply expression for column '{col}': {e}\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    with get_input_stream(args.file) as input_stream:\n        try:\n            jsonl_to_csv_stream(\n                input_stream,\n                sys.stdout,\n                flatten=args.flatten,\n                flatten_sep=args.flatten_sep,\n                column_functions=column_functions,\n            )\n        except Exception as e:\n            print(\n                f\"An unexpected error occurred during CSV export: {e}\", file=sys.stderr\n            )\n            sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_schema_validate","title":"<code>handle_schema_validate(args)</code>","text":"<p>Handle schema validate command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_schema_validate(args):\n    \"\"\"Handle schema validate command.\"\"\"\n    try:\n        import jsonschema\n    except ImportError:\n        print(\n            \"jsonschema is not installed. Please install it with: pip install jsonschema\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    # Can't read both from stdin\n    if args.schema == \"-\" and (not args.file or args.file == \"-\"):\n        print(\n            \"Error: When reading schema from stdin, a file argument for the data to validate must be provided.\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    try:\n        with get_input_stream(args.schema) as f:\n            schema = json.load(f)\n    except (IOError, json.JSONDecodeError) as e:\n        print(\n            f\"Error reading or parsing schema file {args.schema}: {e}\", file=sys.stderr\n        )\n        sys.exit(1)\n\n    # If schema was from stdin, the file MUST be from a file, not stdin.\n    data_source = args.file if args.schema == \"-\" else (args.file or \"-\")\n\n    with get_input_stream(data_source) as lines:\n        validation_failed = False\n        for i, line in enumerate(lines, 1):\n            try:\n                instance = json.loads(line)\n                jsonschema.validate(instance=instance, schema=schema)\n                print(line.strip())\n            except json.JSONDecodeError as e:\n                print(f\"Error decoding JSON on line {i}: {e}\", file=sys.stderr)\n                validation_failed = True\n            except jsonschema.exceptions.ValidationError as e:\n                print(f\"Validation error on line {i}: {e.message}\", file=sys.stderr)\n                validation_failed = True\n\n    if validation_failed:\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#ja.commands.handle_collect","title":"<code>handle_collect(args)</code>","text":"<p>Handle collect command.</p> Source code in <code>ja/commands.py</code> <pre><code>def handle_collect(args):\n    \"\"\"Handle collect command.\"\"\"\n    with get_input_stream(args.file) as f:\n        data = read_jsonl(f)\n\n    if not data:\n        write_jsonl([])\n        return\n\n    # Check for streaming flag\n    if hasattr(args, \"streaming\") and args.streaming:\n        json_error(\n            \"StreamingError\",\n            \"Collect operation requires seeing all data and cannot be performed in streaming mode. \"\n            \"Remove --streaming flag or use window-based processing with --window-size\",\n        )\n        return\n\n    # Handle window-based collection\n    if hasattr(args, \"window_size\") and args.window_size:\n        # Process data in windows\n        window_size = args.window_size\n        for i in range(0, len(data), window_size):\n            window = data[i : i + window_size]\n            result = collect(window)\n            write_jsonl(result)\n    else:\n        # Collect all data at once\n        result = collect(data)\n        write_jsonl(result)\n</code></pre>"},{"location":"reference/#ja.group","title":"<code>ja.group</code>","text":"<p>Grouping operations for JSONL algebra.</p> <p>This module provides grouping functionality that supports both immediate aggregation and metadata-based chaining for multi-level grouping.</p>"},{"location":"reference/#ja.group-classes","title":"Classes","text":""},{"location":"reference/#ja.group-functions","title":"Functions","text":""},{"location":"reference/#ja.group.groupby_with_metadata","title":"<code>groupby_with_metadata(data, group_key)</code>","text":"<p>Group data and add metadata fields.</p> <p>This function enables chained groupby operations by adding special metadata fields to each row: - _groups: List of {field, value} objects representing the grouping hierarchy - _group_size: Total number of rows in this group - _group_index: This row's index within its group</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries to group</p> required <code>group_key</code> <code>str</code> <p>Field to group by (supports dot notation)</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List with group metadata added to each row</p> Source code in <code>ja/group.py</code> <pre><code>def groupby_with_metadata(data: Relation, group_key: str) -&gt; Relation:\n    \"\"\"Group data and add metadata fields.\n\n    This function enables chained groupby operations by adding special\n    metadata fields to each row:\n    - _groups: List of {field, value} objects representing the grouping hierarchy\n    - _group_size: Total number of rows in this group\n    - _group_index: This row's index within its group\n\n    Args:\n        data: List of dictionaries to group\n        group_key: Field to group by (supports dot notation)\n\n    Returns:\n        List with group metadata added to each row\n    \"\"\"\n    parser = ExprEval()\n\n    # First pass: collect groups\n    groups = defaultdict(list)\n    for row in data:\n        try:\n            # print(row, file=sys.stderr)\n            key_value = parser.get_field_value(row, group_key)\n            groups[key_value].append(row)\n        except Exception as e:\n            key_value = json.dumps(key_value, ensure_ascii=False, sort_keys=True)\n            groups[key_value].append(row)\n\n    # Second pass: add metadata to each row\n    # Second pass: add metadata and flatten\n    result = []\n    last_index = len(groups) - 1\n\n    for i, (group_value, group_rows) in enumerate(groups.items()):\n        print(\"Processing group:\", group_value, \"Size:\", len(group_rows), \"Index:\", i,   \"Last Index:\", last_index, file=sys.stderr)\n        group_size = len(group_rows)\n        for index, row in enumerate(group_rows):\n            # Create new row with metadata\n            new_row = row.copy()\n            # check if group_value is a serialized json value\n            if isinstance(group_value, str):\n                try:\n                    group_value = json.loads(group_value)\n                    # print(group_value)\n                    # print(\"Deserialized group value:\", group_value)\n                except json.JSONDecodeError:\n                    pass\n                    # print({\"Huh?\"})\n            # print(\"Processing group:\", group_value, \"Size:\", group_size)\n            new_row[\"_groups\"] = [{\"field\": group_key, \"value\": group_value}]\n            new_row[\"_group_size\"] = group_size\n            new_row[\"_group_index\"] = index\n            result.append(new_row)\n\n    print(\"Done processing groups\", file=sys.stderr)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.group.groupby_chained","title":"<code>groupby_chained(grouped_data, new_group_key)</code>","text":"<p>Apply groupby to already-grouped data.</p> <p>This function handles multi-level grouping by building on existing group metadata.</p> <p>Parameters:</p> Name Type Description Default <code>grouped_data</code> <code>Relation</code> <p>Data with existing group metadata</p> required <code>new_group_key</code> <code>str</code> <p>Field to group by</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List with nested group metadata</p> Source code in <code>ja/group.py</code> <pre><code>def groupby_chained(grouped_data: Relation, new_group_key: str) -&gt; Relation:\n    \"\"\"Apply groupby to already-grouped data.\n\n    This function handles multi-level grouping by building on existing\n    group metadata.\n\n    Args:\n        grouped_data: Data with existing group metadata\n        new_group_key: Field to group by\n\n    Returns:\n        List with nested group metadata\n    \"\"\"\n    parser = ExprEval()\n\n    # Group within existing groups\n    nested_groups = defaultdict(list)\n\n    import sys\n    print(\"hi\", file=sys.stderr)\n\n    for row in grouped_data:\n        # Get existing groups\n        existing_groups = row.get(\"_groups\", [])\n        try:\n            # print(row, file=sys.stderr)\n            key_value = parser.get_field_value(row, new_group_key)\n            nested_groups[key_value].append(row)\n        except Exception as e:\n            key_value = json.dumps(key_value, ensure_ascii=False, sort_keys=True)\n            nested_groups[key_value].append(row)\n\n        new_key_value = parser.get_field_value(row, new_group_key)\n\n        print(\"Processing row:\", row, \"New group key:\", new_group_key, \"Value:\", new_key_value, file=sys.stderr)\n\n        # Create a tuple key for grouping (for internal use only)\n\n        group_tuple = tuple((g[\"field\"], g[\"value\"]) for g in existing_groups)\n        group_tuple += ((new_group_key, new_key_value),)\n\n        print(\"Hmm...\", file=sys.stderr)\n        try:\n\n            nested_groups[group_tuple].append(row)\n        except Exception as e:\n            # make group_tuple hashable\n            # here is how to do it: \n            group_tuple = tuple(map(str, group_tuple))\n            nested_groups[group_tuple].append(row)\n\n    import sys\n    print(\"hi\", file=sys.stderr)\n    # Add new metadata\n    result = []\n    for group_tuple, group_rows in nested_groups.items():\n        group_size = len(group_rows)\n\n        for index, row in enumerate(group_rows):\n            new_row = row.copy()\n\n            value = parser.get_field_value(row, new_group_key)\n\n            # Extend the groups list\n            new_row[\"_groups\"] = row.get(\"_groups\", []).copy()\n            new_row[\"_groups\"].append({\n                \"field\": new_group_key,\n                \"value\": value\n            })\n\n            new_row[\"_group_size\"] = group_size\n            new_row[\"_group_index\"] = index\n            result.append(new_row)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.group.groupby_agg","title":"<code>groupby_agg(data, group_key, agg_spec)</code>","text":"<p>Group and aggregate in one operation.</p> <p>This function is kept for backward compatibility and for the --agg flag. It's more efficient for simple cases but less flexible than chaining.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries to group and aggregate</p> required <code>group_key</code> <code>str</code> <p>Field to group by</p> required <code>agg_spec</code> <code>Union[str, List[Tuple[str, str]]]</code> <p>Aggregation specification</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List of aggregated results, one per group</p> Source code in <code>ja/group.py</code> <pre><code>def groupby_agg(data: Relation, group_key: str, agg_spec: Union[str, List[Tuple[str, str]]]) -&gt; Relation:\n    \"\"\"Group and aggregate in one operation.\n\n    This function is kept for backward compatibility and for the --agg flag.\n    It's more efficient for simple cases but less flexible than chaining.\n\n    Args:\n        data: List of dictionaries to group and aggregate\n        group_key: Field to group by\n        agg_spec: Aggregation specification\n\n    Returns:\n        List of aggregated results, one per group\n    \"\"\"\n    parser = ExprEval()\n\n    # Group data\n    groups = defaultdict(list)\n    for row in data:\n        key = parser.get_field_value(row, group_key)\n        groups[key].append(row)\n\n    # Apply aggregations\n    result = []\n\n    # Handle both string and list inputs for backward compatibility\n    if isinstance(agg_spec, str):\n        agg_specs = parse_agg_specs(agg_spec)\n    else:\n        # Convert old list format to new format\n        agg_specs = []\n        for name, field in agg_spec:\n            if name == \"count\":\n                agg_specs.append((\"count\", \"count\"))\n            elif name in [\"sum\", \"avg\", \"min\", \"max\"]:\n                agg_specs.append((f\"{name}_{field}\", f\"{name}({field})\"))\n\n    for key, group_rows in groups.items():\n        row_result = {group_key: key}\n        for spec in agg_specs:\n            row_result.update(apply_single_agg(spec, group_rows))\n        result.append(row_result)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.agg","title":"<code>ja.agg</code>","text":"<p>Aggregation engine for JSONL algebra operations.</p> <p>This module provides all aggregation functionality including parsing aggregation specifications, applying aggregations to data, and all built-in aggregation functions (sum, avg, min, max, etc.).</p>"},{"location":"reference/#ja.agg-classes","title":"Classes","text":""},{"location":"reference/#ja.agg-functions","title":"Functions","text":""},{"location":"reference/#ja.agg.parse_agg_specs","title":"<code>parse_agg_specs(agg_spec)</code>","text":"<p>Parse aggregation specification string.</p> <p>Parameters:</p> Name Type Description Default <code>agg_spec</code> <code>str</code> <p>Aggregation specification (e.g., \"count, avg_age=avg(age)\")</p> required <p>Returns:</p> Type Description <code>List[Tuple[str, str]]</code> <p>List of (name, expression) tuples</p> Source code in <code>ja/agg.py</code> <pre><code>def parse_agg_specs(agg_spec: str) -&gt; List[Tuple[str, str]]:\n    \"\"\"Parse aggregation specification string.\n\n    Args:\n        agg_spec: Aggregation specification (e.g., \"count, avg_age=avg(age)\")\n\n    Returns:\n        List of (name, expression) tuples\n    \"\"\"\n    specs = []\n    for part in agg_spec.split(\",\"):\n        part = part.strip()\n        if \"=\" in part:\n            # Named aggregation: avg_age=avg(age)\n            name, expr = part.split(\"=\", 1)\n            specs.append((name.strip(), expr.strip()))\n        else:\n            # Simple aggregation: count\n            specs.append((part, part))\n    return specs\n</code></pre>"},{"location":"reference/#ja.agg.apply_single_agg","title":"<code>apply_single_agg(spec, data)</code>","text":"<p>Apply a single aggregation to data.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Tuple[str, str]</code> <p>(name, expression) tuple</p> required <code>data</code> <code>Relation</code> <p>List of dictionaries</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with aggregation result</p> Source code in <code>ja/agg.py</code> <pre><code>def apply_single_agg(spec: Tuple[str, str], data: Relation) -&gt; Dict[str, Any]:\n    \"\"\"Apply a single aggregation to data.\n\n    Args:\n        spec: (name, expression) tuple\n        data: List of dictionaries\n\n    Returns:\n        Dictionary with aggregation result\n    \"\"\"\n    name, expr = spec\n    parser = ExprEval()\n\n    # Parse the aggregation expression\n    if \"(\" in expr and expr.endswith(\")\"):\n        func_name = expr[:expr.index(\"(\")]\n        field_expr = expr[expr.index(\"(\") + 1:-1].strip()\n    else:\n        func_name = expr\n        field_expr = \"\"\n\n    # Handle conditional aggregations\n    if \"_if\" in func_name:\n        # e.g., count_if(status == active) or sum_if(amount, status == paid)\n        base_func = func_name.replace(\"_if\", \"\")\n\n        if \",\" in field_expr:\n            # sum_if(amount, status == paid)\n            field, condition = field_expr.split(\",\", 1)\n            field = field.strip()\n            condition = condition.strip()\n\n            # Filter data based on condition\n            filtered_data = [row for row in data if parser.evaluate(condition, row)]\n\n            # Apply base aggregation to filtered data\n            if base_func == \"sum\":\n                values = [parser.get_field_value(row, field) for row in filtered_data]\n                return {name: sum(v for v in values if v is not None)}\n            elif base_func == \"avg\":\n                values = [parser.get_field_value(row, field) for row in filtered_data]\n                values = [v for v in values if v is not None]\n                return {name: sum(values) / len(values) if values else 0}\n            elif base_func == \"count\":\n                return {name: len(filtered_data)}\n        else:\n            # count_if(status == active)\n            filtered_data = [row for row in data if parser.evaluate(field_expr, row)]\n            return {name: len(filtered_data)}\n\n    # Regular aggregations\n    if func_name == \"count\":\n        return {name: len(data)}\n\n    elif func_name in AGGREGATION_FUNCTIONS:\n        if func_name in [\"first\", \"last\"]:\n            # Special handling for first/last\n            if not data:\n                return {name: None}\n            row = data[0] if func_name == \"first\" else data[-1]\n            value = parser.get_field_value(row, field_expr) if field_expr else row\n            return {name: value}\n        else:\n            # Collect values for aggregation\n            values = []\n            for row in data:\n                if field_expr:\n                    # Try arithmetic evaluation first\n                    val = parser.evaluate_arithmetic(field_expr, row)\n                    if val is None:\n                        val = parser.get_field_value(row, field_expr)\n                else:\n                    val = row\n                if val is not None:\n                    values.append(val)\n\n            # Apply aggregation functionsum(_agg_numeric_values(values))\n            result = AGGREGATION_FUNCTIONS[func_name](values)\n            return {name: result}\n\n    return {name: None}\n</code></pre>"},{"location":"reference/#ja.agg.aggregate_single_group","title":"<code>aggregate_single_group(data, agg_spec)</code>","text":"<p>Aggregate ungrouped data as a single group.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Relation</code> <p>List of dictionaries</p> required <code>agg_spec</code> <code>str</code> <p>Aggregation specification</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with aggregation results</p> Source code in <code>ja/agg.py</code> <pre><code>def aggregate_single_group(data: Relation, agg_spec: str) -&gt; Dict[str, Any]:\n    \"\"\"Aggregate ungrouped data as a single group.\n\n    Args:\n        data: List of dictionaries\n        agg_spec: Aggregation specification\n\n    Returns:\n        Dictionary with aggregation results\n    \"\"\"\n    agg_specs = parse_agg_specs(agg_spec)\n    result = {}\n\n    for spec in agg_specs:\n        result.update(apply_single_agg(spec, data))\n\n    return result\n</code></pre>"},{"location":"reference/#ja.agg.aggregate_grouped_data","title":"<code>aggregate_grouped_data(grouped_data, agg_spec)</code>","text":"<p>Aggregate data that has group metadata.</p> <p>Parameters:</p> Name Type Description Default <code>grouped_data</code> <code>Relation</code> <p>Data with group metadata</p> required <code>agg_spec</code> <code>str</code> <p>Aggregation specification</p> required <p>Returns:</p> Type Description <code>Relation</code> <p>List of aggregated results</p> Source code in <code>ja/agg.py</code> <pre><code>def aggregate_grouped_data(grouped_data: Relation, agg_spec: str) -&gt; Relation:\n    \"\"\"Aggregate data that has group metadata.\n\n    Args:\n        grouped_data: Data with group metadata\n        agg_spec: Aggregation specification\n\n    Returns:\n        List of aggregated results\n    \"\"\"\n    from collections import defaultdict\n\n    # Group by the combination of all grouping fields\n    groups = defaultdict(list)\n    group_keys = {}\n\n    for row in grouped_data:\n        # Use the _groups list to create a grouping key\n        groups_list = row.get(\"_groups\", [])\n\n        # Create a tuple key for internal grouping\n        group_tuple = tuple((g[\"field\"], g[\"value\"]) for g in groups_list)\n\n        # Store the groups for this tuple\n        if group_tuple not in group_keys:\n            group_keys[group_tuple] = groups_list\n\n        # Remove metadata for aggregation\n        clean_row = {k: v for k, v in row.items() if not k.startswith(\"_group\")}\n        groups[group_tuple].append(clean_row)\n\n    # Apply aggregations\n    result = []\n\n    for group_tuple, group_rows in groups.items():\n        # Start with all grouping fields\n        agg_result = {}\n\n        # Add all grouping fields from the metadata\n        for group_info in group_keys[group_tuple]:\n            agg_result[group_info[\"field\"]] = group_info[\"value\"]\n\n        # Parse and apply aggregations\n        agg_specs = parse_agg_specs(agg_spec)\n        for spec in agg_specs:\n            agg_result.update(apply_single_agg(spec, group_rows))\n\n        result.append(agg_result)\n\n    return result\n</code></pre>"},{"location":"reference/#ja.export","title":"<code>ja.export</code>","text":"<p>Utilities for exporting JSONL data to other formats.</p> <p>This module provides a collection of functions for converting JSONL data into various other formats. It powers the <code>ja export</code> command group, enabling transformations like converting JSONL to a standard JSON array or \"exploding\" a JSONL file into a directory of individual JSON files.</p>"},{"location":"reference/#ja.export-functions","title":"Functions","text":""},{"location":"reference/#ja.export.jsonl_to_json_array_string","title":"<code>jsonl_to_json_array_string(jsonl_input_stream)</code>","text":"<p>Read JSONL from a stream and return a JSON array string.</p> <p>Parameters:</p> Name Type Description Default <code>jsonl_input_stream</code> <p>Input stream containing JSONL data.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A JSON array string containing all records.</p> Source code in <code>ja/export.py</code> <pre><code>def jsonl_to_json_array_string(jsonl_input_stream) -&gt; str:\n    \"\"\"Read JSONL from a stream and return a JSON array string.\n\n    Args:\n        jsonl_input_stream: Input stream containing JSONL data.\n\n    Returns:\n        A JSON array string containing all records.\n    \"\"\"\n    records = []\n    for line in jsonl_input_stream:\n        try:\n            records.append(json.loads(line))\n        except json.JSONDecodeError as e:\n            print(\n                f\"Skipping invalid JSON line: {line.strip()} - Error: {e}\",\n                file=sys.stderr,\n            )\n            continue\n    return json.dumps(records, indent=2)\n</code></pre>"},{"location":"reference/#ja.export.json_array_to_jsonl_lines","title":"<code>json_array_to_jsonl_lines(json_array_input_stream)</code>","text":"<p>Read a JSON array from a stream and yield each element as a JSONL line.</p> <p>Parameters:</p> Name Type Description Default <code>json_array_input_stream</code> <p>Input stream containing a JSON array.</p> required <p>Yields:</p> Type Description <p>JSON strings representing each array element.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is not a valid JSON array.</p> Source code in <code>ja/export.py</code> <pre><code>def json_array_to_jsonl_lines(json_array_input_stream):\n    \"\"\"Read a JSON array from a stream and yield each element as a JSONL line.\n\n    Args:\n        json_array_input_stream: Input stream containing a JSON array.\n\n    Yields:\n        JSON strings representing each array element.\n\n    Raises:\n        ValueError: If the input is not a valid JSON array.\n    \"\"\"\n    try:\n        json_string = \"\".join(json_array_input_stream)\n        data = json.loads(json_string)\n        if not isinstance(data, list):\n            raise ValueError(\"Input is not a JSON array.\")\n        for record in data:\n            yield json.dumps(record)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON array input: {e}\")\n    except ValueError as e:\n        raise e\n</code></pre>"},{"location":"reference/#ja.export.jsonl_to_dir","title":"<code>jsonl_to_dir(jsonl_input_stream, output_dir_path_str, input_filename_stem='data')</code>","text":"<p>Exports JSONL lines to individual JSON files in a directory. The output directory is named after input_filename_stem if output_dir_path_str is not specific. Files are named item-.json. Source code in <code>ja/export.py</code> <pre><code>def jsonl_to_dir(\n    jsonl_input_stream, output_dir_path_str: str, input_filename_stem: str = \"data\"\n):\n    \"\"\"\n    Exports JSONL lines to individual JSON files in a directory.\n    The output directory is named after input_filename_stem if output_dir_path_str is not specific.\n    Files are named item-&lt;index&gt;.json.\n    \"\"\"\n    output_dir = pathlib.Path(output_dir_path_str)\n\n    # If output_dir_path_str was just a name (not a path), it might be used as the stem.\n    # If it's a directory, we use the provided input_filename_stem for the sub-directory.\n    if (\n        output_dir.is_dir() and not output_dir.exists()\n    ):  # A path like \"output/my_data\" where \"output\" exists\n        # This case is tricky. Let's assume output_dir_path_str is the target directory.\n        pass\n    elif not output_dir.name.endswith((\".jsonl\", \".json\")) and not output_dir.exists():\n        # Treat as a new directory to be created directly\n        pass\n    else:  # Default behavior: create a subdirectory based on the input stem\n        output_dir = output_dir / input_filename_stem\n\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    count = 0\n    for i, line in enumerate(jsonl_input_stream):\n        try:\n            record = json.loads(line)\n            file_path = output_dir / f\"item-{i}.json\"\n            with open(file_path, \"w\") as f:\n                json.dump(record, f, indent=2)\n            count += 1\n        except json.JSONDecodeError as e:\n            print(\n                f\"Skipping invalid JSON line during export: {line.strip()} - Error: {e}\",\n                file=sys.stderr,\n            )\n            continue\n    print(f\"Exported {count} items to {output_dir.resolve()}\", file=sys.stderr)\n</code></pre>"},{"location":"reference/#ja.export.dir_to_jsonl","title":"<code>dir_to_jsonl(input_dir_path_str, add_filename_key=None, recursive=False)</code>","text":"<p>Converts JSON files in a directory to JSONL lines. Files are sorted by 'item-.json' pattern if applicable, otherwise lexicographically. Optionally adds filename as a key to each JSON object. Source code in <code>ja/export.py</code> <pre><code>def dir_to_jsonl(\n    input_dir_path_str: str, add_filename_key: str = None, recursive: bool = False\n):\n    \"\"\"\n    Converts JSON files in a directory to JSONL lines.\n    Files are sorted by 'item-&lt;index&gt;.json' pattern if applicable, otherwise lexicographically.\n    Optionally adds filename as a key to each JSON object.\n    \"\"\"\n    input_dir = pathlib.Path(input_dir_path_str)\n    if not input_dir.is_dir():\n        raise ValueError(f\"Input path is not a directory: {input_dir_path_str}\")\n\n    json_files_paths = []\n    if recursive:\n        for root, _, files in os.walk(input_dir):\n            for file in files:\n                if file.lower().endswith(\".json\"):\n                    json_files_paths.append(pathlib.Path(root) / file)\n    else:\n        for item in input_dir.iterdir():\n            if item.is_file() and item.name.lower().endswith(\".json\"):\n                json_files_paths.append(item)\n\n    sorted_file_paths = _sort_files_for_implode(json_files_paths)\n\n    for file_path in sorted_file_paths:\n        try:\n            with open(file_path, \"r\") as f:\n                data = json.load(f)\n\n            if add_filename_key:\n                # Use relative path from the input_dir to keep it cleaner\n                relative_filename = str(file_path.relative_to(input_dir))\n                actual_key = _ensure_unique_key(data, add_filename_key)\n                data[actual_key] = relative_filename\n\n            yield json.dumps(data)\n        except json.JSONDecodeError as e:\n            print(\n                f\"Skipping invalid JSON file: {file_path} - Error: {e}\", file=sys.stderr\n            )\n            continue\n        except Exception as e:\n            print(f\"Error processing file {file_path}: {e}\", file=sys.stderr)\n            continue\n</code></pre>"},{"location":"reference/#ja.exporter","title":"<code>ja.exporter</code>","text":"<p>Export your JSONL data to other popular formats like CSV.</p> <p>This module is your gateway to the wider data ecosystem. It provides powerful and flexible tools to convert your JSONL data into formats that are easy to use with spreadsheets, traditional databases, or other data analysis tools.</p> <p>The key feature is its intelligent handling of nested JSON, which can be \"flattened\" into separate columns, making complex data accessible in a simple CSV format.</p>"},{"location":"reference/#ja.exporter-functions","title":"Functions","text":""},{"location":"reference/#ja.exporter.jsonl_to_csv_stream","title":"<code>jsonl_to_csv_stream(jsonl_stream, output_stream, flatten=True, flatten_sep='.', column_functions=None)</code>","text":"<p>Convert a stream of JSONL data into a CSV stream.</p> <p>This is a highly flexible function for exporting your data. It reads JSONL records, intelligently discovers all possible headers (even if they vary between lines), and writes to a CSV format.</p> <p>It shines when dealing with nested data. By default, it will flatten structures like <code>{\"user\": {\"name\": \"X\"}}</code> into a <code>user.name</code> column. You can also provide custom functions to transform data on the fly.</p> <p>Parameters:</p> Name Type Description Default <code>jsonl_stream</code> <p>An input stream (like a file handle) yielding JSONL strings.</p> required <code>output_stream</code> <p>An output stream (like <code>sys.stdout</code> or a file handle)            where the CSV data will be written.</p> required <code>flatten</code> <code>bool</code> <p>If <code>True</code>, nested dictionaries are flattened into columns             with dot-separated keys. Defaults to <code>True</code>.</p> <code>True</code> <code>flatten_sep</code> <code>str</code> <p>The separator to use when flattening keys.                Defaults to \".\".</p> <code>'.'</code> <code>column_functions</code> <code>dict</code> <p>A dictionary mapping column names to functions                      that will be applied to that column's data                      before writing to CSV. For example,                      <code>{\"price\": float}</code>.</p> <code>None</code> Source code in <code>ja/exporter.py</code> <pre><code>def jsonl_to_csv_stream(\n    jsonl_stream,\n    output_stream,\n    flatten: bool = True,\n    flatten_sep: str = \".\",\n    column_functions: dict = None,\n):\n    \"\"\"Convert a stream of JSONL data into a CSV stream.\n\n    This is a highly flexible function for exporting your data. It reads JSONL\n    records, intelligently discovers all possible headers (even if they vary\n    between lines), and writes to a CSV format.\n\n    It shines when dealing with nested data. By default, it will flatten\n    structures like `{\"user\": {\"name\": \"X\"}}` into a `user.name` column.\n    You can also provide custom functions to transform data on the fly.\n\n    Args:\n        jsonl_stream: An input stream (like a file handle) yielding JSONL strings.\n        output_stream: An output stream (like `sys.stdout` or a file handle)\n                       where the CSV data will be written.\n        flatten (bool): If `True`, nested dictionaries are flattened into columns\n                        with dot-separated keys. Defaults to `True`.\n        flatten_sep (str): The separator to use when flattening keys.\n                           Defaults to \".\".\n        column_functions (dict): A dictionary mapping column names to functions\n                                 that will be applied to that column's data\n                                 before writing to CSV. For example,\n                                 `{\"price\": float}`.\n    \"\"\"\n    if column_functions is None:\n        column_functions = {}\n\n    # First pass: Discover all possible headers from the entire stream\n    records = [json.loads(line) for line in jsonl_stream if line.strip()]\n    if not records:\n        return\n\n    # Apply column functions before flattening\n    for rec in records:\n        for col, func in column_functions.items():\n            if col in rec:\n                try:\n                    rec[col] = func(rec[col])\n                except Exception as e:\n                    # Optionally, log this error or handle it as needed\n                    print(\n                        f\"Error applying function to column '{col}' for a record: {e}\",\n                        file=sys.stderr,\n                    )\n\n    if flatten:\n        processed_records = [(_flatten_dict(rec, sep=flatten_sep)) for rec in records]\n    else:\n        processed_records = []\n        for rec in records:\n            processed_rec = {}\n            for k, v in rec.items():\n                if isinstance(v, (dict, list)):\n                    processed_rec[k] = json.dumps(v)\n                else:\n                    processed_rec[k] = v\n            processed_records.append(processed_rec)\n\n    # Discover all unique keys to form the CSV header\n    headers = []\n    header_set = set()\n    for rec in processed_records:\n        for key in rec.keys():\n            if key not in header_set:\n                header_set.add(key)\n                headers.append(key)\n\n    # Second pass: Write to the output stream\n    writer = csv.DictWriter(output_stream, fieldnames=headers, lineterminator=\"\\n\")\n    writer.writeheader()\n    writer.writerows(processed_records)\n</code></pre>"},{"location":"reference/#ja.importer","title":"<code>ja.importer</code>","text":"<p>Import data from other formats like CSV into the world of JSONL.</p> <p>This module is the bridge that brings your existing data into the JSONL Algebra ecosystem. It provides a collection of powerful functions for converting various data formats\u2014such as CSV or directories of individual JSON files\u2014into the clean, line-oriented JSONL format that <code>ja</code> is built to handle.</p>"},{"location":"reference/#ja.importer-functions","title":"Functions","text":""},{"location":"reference/#ja.importer.dir_to_jsonl_lines","title":"<code>dir_to_jsonl_lines(dir_path)</code>","text":"<p>Stream a directory of .json or .jsonl files as a single JSONL stream.</p> <p>A handy utility for consolidating data. It reads all files ending in <code>.json</code> or <code>.jsonl</code> from a specified directory and yields each JSON object as a separate line. This is perfect for preparing a dataset that has been stored as many small files.</p> <ul> <li>For <code>.json</code> files, the entire file is treated as a single JSON object.</li> <li>For <code>.jsonl</code> files, each line is treated as a separate JSON object.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>str</code> <p>The path to the directory to read.</p> required <p>Yields:</p> Type Description <p>A string for each JSON object found, ready for processing.</p> Source code in <code>ja/importer.py</code> <pre><code>def dir_to_jsonl_lines(dir_path):\n    \"\"\"Stream a directory of .json or .jsonl files as a single JSONL stream.\n\n    A handy utility for consolidating data. It reads all files ending in `.json`\n    or `.jsonl` from a specified directory and yields each JSON object as a\n    separate line. This is perfect for preparing a dataset that has been\n    stored as many small files.\n\n    - For `.json` files, the entire file is treated as a single JSON object.\n    - For `.jsonl` files, each line is treated as a separate JSON object.\n\n    Args:\n        dir_path (str): The path to the directory to read.\n\n    Yields:\n        A string for each JSON object found, ready for processing.\n    \"\"\"\n    for filename in sorted(os.listdir(dir_path)):\n        file_path = os.path.join(dir_path, filename)\n        if filename.endswith(\".json\"):\n            try:\n                with open(file_path, \"r\") as f:\n                    yield f.read().strip()\n            except (IOError, json.JSONDecodeError) as e:\n                print(f\"Error reading or parsing {file_path}: {e}\", file=sys.stderr)\n        elif filename.endswith(\".jsonl\"):\n            try:\n                with open(file_path, \"r\") as f:\n                    for line in f:\n                        yield line.strip()\n            except IOError as e:\n                print(f\"Error reading {file_path}: {e}\", file=sys.stderr)\n</code></pre>"},{"location":"reference/#ja.importer.csv_to_jsonl_lines","title":"<code>csv_to_jsonl_lines(csv_input_stream, has_header, infer_types=False)</code>","text":"<p>Convert a stream of CSV data into a stream of JSONL lines.</p> <p>This function reads CSV data and transforms each row into a JSON object. It can automatically handle headers to use as keys and can even infer the data types of your values, converting them from strings to numbers or booleans where appropriate.</p> <p>Parameters:</p> Name Type Description Default <code>csv_input_stream</code> <p>An input stream (like a file handle) containing CSV data.</p> required <code>has_header</code> <code>bool</code> <p>Set to <code>True</code> if the first row of the CSV is a header                that should be used for JSON keys.</p> required <code>infer_types</code> <code>bool</code> <p>If <code>True</code>, automatically convert values to <code>int</code>,                 <code>float</code>, <code>bool</code>, or <code>None</code>. Defaults to <code>False</code>.</p> <code>False</code> <p>Yields:</p> Type Description <p>A JSON-formatted string for each row in the CSV data.</p> Source code in <code>ja/importer.py</code> <pre><code>def csv_to_jsonl_lines(csv_input_stream, has_header: bool, infer_types: bool = False):\n    \"\"\"Convert a stream of CSV data into a stream of JSONL lines.\n\n    This function reads CSV data and transforms each row into a JSON object.\n    It can automatically handle headers to use as keys and can even infer the\n    data types of your values, converting them from strings to numbers or\n    booleans where appropriate.\n\n    Args:\n        csv_input_stream: An input stream (like a file handle) containing CSV data.\n        has_header (bool): Set to `True` if the first row of the CSV is a header\n                           that should be used for JSON keys.\n        infer_types (bool): If `True`, automatically convert values to `int`,\n                            `float`, `bool`, or `None`. Defaults to `False`.\n\n    Yields:\n        A JSON-formatted string for each row in the CSV data.\n    \"\"\"\n\n    def process_row(row):\n        if not infer_types:\n            return row\n        return {k: _infer_value(v) for k, v in row.items()}\n\n    if has_header:\n        # Use DictReader which handles headers automatically\n        reader = csv.DictReader(csv_input_stream)\n        for row in reader:\n            yield json.dumps(process_row(row))\n    else:\n        # Use the standard reader and manually create dictionaries\n        reader = csv.reader(csv_input_stream)\n        headers = []\n        try:\n            first_row = next(reader)\n            # Generate headers based on the number of columns in the first row\n            headers = [f\"col_{i}\" for i in range(len(first_row))]\n            # Yield the first row which we've already consumed\n            row_dict = dict(zip(headers, first_row))\n            yield json.dumps(process_row(row_dict))\n        except StopIteration:\n            return  # Handle empty file\n\n        # Yield the rest of the rows\n        for row in reader:\n            row_dict = dict(zip(headers, row))\n            yield json.dumps(process_row(row_dict))\n</code></pre>"},{"location":"reference/#ja.schema","title":"<code>ja.schema</code>","text":"<p>Discover the structure of your data automatically.</p> <p>This module provides powerful tools to infer a JSON Schema from your JSONL files. A schema acts as a blueprint for your data, describing its fields, types, and which fields are required. This is incredibly useful for validation, documentation, and ensuring data quality.</p>"},{"location":"reference/#ja.schema-functions","title":"Functions","text":""},{"location":"reference/#ja.schema.get_json_type","title":"<code>get_json_type(value)</code>","text":"<p>Determine the appropriate JSON Schema type for a given Python value.</p> <p>Maps Python types to their corresponding JSON Schema type names.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>Any Python value.</p> required <p>Returns:</p> Type Description <p>The JSON Schema type name as a string.</p> Example <p>get_json_type(\"hello\") 'string' get_json_type(42) 'integer'</p> Source code in <code>ja/schema.py</code> <pre><code>def get_json_type(value):\n    \"\"\"Determine the appropriate JSON Schema type for a given Python value.\n\n    Maps Python types to their corresponding JSON Schema type names.\n\n    Args:\n        value: Any Python value.\n\n    Returns:\n        The JSON Schema type name as a string.\n\n    Example:\n        &gt;&gt;&gt; get_json_type(\"hello\")\n        'string'\n        &gt;&gt;&gt; get_json_type(42)\n        'integer'\n    \"\"\"\n    if isinstance(value, str):\n        return \"string\"\n    if isinstance(value, bool):\n        return \"boolean\"\n    if isinstance(value, int):\n        return \"integer\"\n    if isinstance(value, float):\n        return \"number\"\n    if value is None:\n        return \"null\"\n    if isinstance(value, list):\n        return \"array\"\n    if isinstance(value, dict):\n        return \"object\"\n    return \"unknown\"\n</code></pre>"},{"location":"reference/#ja.schema.merge_schemas","title":"<code>merge_schemas(s1, s2)</code>","text":"<p>Intelligently merge two JSON schemas into one.</p> <p>This is the secret sauce that allows schema inference to work across many different JSON objects, even if they have different fields or types. It handles type unions (e.g., a field that is sometimes a string, sometimes an integer) and recursively merges nested object properties and array item schemas.</p> <p>Parameters:</p> Name Type Description Default <code>s1</code> <p>First JSON schema dictionary or None.</p> required <code>s2</code> <p>Second JSON schema dictionary or None.</p> required <p>Returns:</p> Type Description <p>A merged schema dictionary combining both inputs.</p> Example <p>s1 = {\"type\": \"string\"} s2 = {\"type\": \"integer\"} merge_schemas(s1, s2)</p> Source code in <code>ja/schema.py</code> <pre><code>def merge_schemas(s1, s2):\n    \"\"\"Intelligently merge two JSON schemas into one.\n\n    This is the secret sauce that allows schema inference to work across many\n    different JSON objects, even if they have different fields or types. It handles\n    type unions (e.g., a field that is sometimes a string, sometimes an integer)\n    and recursively merges nested object properties and array item schemas.\n\n    Args:\n        s1: First JSON schema dictionary or None.\n        s2: Second JSON schema dictionary or None.\n\n    Returns:\n        A merged schema dictionary combining both inputs.\n\n    Example:\n        &gt;&gt;&gt; s1 = {\"type\": \"string\"}\n        &gt;&gt;&gt; s2 = {\"type\": \"integer\"}\n        &gt;&gt;&gt; merge_schemas(s1, s2)\n        {'type': ['integer', 'string']}\n    \"\"\"\n    if s1 is None:\n        return s2\n    if s2 is None:\n        return s1\n    if s1 == s2:\n        return s1\n\n    # Merge types\n    type1 = s1.get(\"type\", [])\n    if not isinstance(type1, list):\n        type1 = [type1]\n    type2 = s2.get(\"type\", [])\n    if not isinstance(type2, list):\n        type2 = [type2]\n\n    merged_types = sorted(list(set(type1) | set(type2)))\n    if \"integer\" in merged_types and \"number\" in merged_types:\n        merged_types.remove(\"integer\")\n\n    merged_schema = {}\n    if len(merged_types) == 1:\n        merged_schema[\"type\"] = merged_types[0]\n    else:\n        merged_schema[\"type\"] = merged_types\n\n    # If both schemas could be objects, merge properties\n    if \"object\" in type1 and \"object\" in type2:\n        props1 = s1.get(\"properties\", {})\n        props2 = s2.get(\"properties\", {})\n        all_keys = set(props1.keys()) | set(props2.keys())\n        merged_props = {\n            key: merge_schemas(props1.get(key), props2.get(key)) for key in all_keys\n        }\n        if merged_props:\n            merged_schema[\"properties\"] = merged_props\n\n    # If both schemas could be arrays, merge items\n    if \"array\" in type1 and \"array\" in type2:\n        items1 = s1.get(\"items\")\n        items2 = s2.get(\"items\")\n        merged_items = merge_schemas(items1, items2)\n        if merged_items:\n            merged_schema[\"items\"] = merged_items\n\n    return merged_schema\n</code></pre>"},{"location":"reference/#ja.schema.infer_value_schema","title":"<code>infer_value_schema(value)</code>","text":"<p>Infer a JSON Schema for a single Python value.</p> <p>Creates a schema that describes the structure and type of the given value, handling nested objects and arrays recursively.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>Any JSON-serializable Python value.</p> required <p>Returns:</p> Type Description <p>A JSON schema dictionary describing the value.</p> Example <p>infer_value_schema({\"name\": \"Alice\", \"age\": 30}) {'type': 'object', 'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}}}</p> Source code in <code>ja/schema.py</code> <pre><code>def infer_value_schema(value):\n    \"\"\"Infer a JSON Schema for a single Python value.\n\n    Creates a schema that describes the structure and type of the given value,\n    handling nested objects and arrays recursively.\n\n    Args:\n        value: Any JSON-serializable Python value.\n\n    Returns:\n        A JSON schema dictionary describing the value.\n\n    Example:\n        &gt;&gt;&gt; infer_value_schema({\"name\": \"Alice\", \"age\": 30})\n        {'type': 'object', 'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}}}\n    \"\"\"\n    type_name = get_json_type(value)\n    schema = {\"type\": type_name}\n    if type_name == \"object\":\n        schema[\"properties\"] = {k: infer_value_schema(v) for k, v in value.items()}\n    elif type_name == \"array\":\n        if value:\n            item_schema = None\n            for item in value:\n                item_schema = merge_schemas(item_schema, infer_value_schema(item))\n            if item_schema:\n                schema[\"items\"] = item_schema\n    return schema\n</code></pre>"},{"location":"reference/#ja.schema.add_required_fields","title":"<code>add_required_fields(schema, data_samples)</code>","text":"<p>Refine a schema by identifying which fields are always present.</p> <p>This function analyzes a list of data samples and updates the schema to mark fields as 'required' if they appear in every single sample. This process is applied recursively to nested objects, making the resulting schema more precise.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <p>The schema dictionary to modify in place.</p> required <code>data_samples</code> <p>A list of data samples to analyze for required fields.</p> required Example <p>If all samples in <code>data_samples</code> have 'name' and 'age' fields, this function adds <code>{\"required\": [\"age\", \"name\"]}</code> to the schema.</p> Source code in <code>ja/schema.py</code> <pre><code>def add_required_fields(schema, data_samples):\n    \"\"\"Refine a schema by identifying which fields are always present.\n\n    This function analyzes a list of data samples and updates the schema to mark\n    fields as 'required' if they appear in every single sample. This process is\n    applied recursively to nested objects, making the resulting schema more precise.\n\n    Args:\n        schema: The schema dictionary to modify in place.\n        data_samples: A list of data samples to analyze for required fields.\n\n    Example:\n        If all samples in `data_samples` have 'name' and 'age' fields, this\n        function adds `{\"required\": [\"age\", \"name\"]}` to the schema.\n    \"\"\"\n    if schema.get(\"type\") == \"object\" and \"properties\" in schema:\n        # For object schemas, find fields present in all samples\n        dict_samples = [s for s in data_samples if isinstance(s, dict)]\n        if dict_samples:\n            required_keys = set(dict_samples[0].keys())\n            for sample in dict_samples[1:]:\n                required_keys.intersection_update(sample.keys())\n            if required_keys:\n                schema[\"required\"] = sorted(list(required_keys))\n\n        # Recursively add required fields to nested object properties\n        for prop_name, prop_schema in schema[\"properties\"].items():\n            prop_samples = [s.get(prop_name) for s in dict_samples if prop_name in s]\n            if prop_samples:\n                add_required_fields(prop_schema, prop_samples)\n\n    elif schema.get(\"type\") == \"array\" and \"items\" in schema:\n        # For array schemas, collect all array items and add required fields\n        array_items = []\n        for sample in data_samples:\n            if isinstance(sample, list):\n                array_items.extend(sample)\n        if array_items:\n            add_required_fields(schema[\"items\"], array_items)\n</code></pre>"},{"location":"reference/#ja.schema.infer_schema","title":"<code>infer_schema(data)</code>","text":"<p>Infer a complete JSON schema from a collection of data records.</p> <p>This is the main entry point for schema inference. Give it an iterable of JSON objects (like a list of dictionaries), and it will return a complete JSON Schema that describes the entire dataset. It automatically handles varying fields, mixed types, nested structures, and identifies required fields.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>An iterable of data records (typically dictionaries).</p> required <p>Returns:</p> Type Description <p>A JSON schema dictionary with <code>$schema</code>, type, properties, and required fields.</p> Example <p>data = [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}] schema = infer_schema(data) schema[\"properties\"][\"name\"] {'type': 'string'} schema[\"required\"]['age', 'name']</p> Source code in <code>ja/schema.py</code> <pre><code>def infer_schema(data):\n    \"\"\"Infer a complete JSON schema from a collection of data records.\n\n    This is the main entry point for schema inference. Give it an iterable of\n    JSON objects (like a list of dictionaries), and it will return a complete\n    JSON Schema that describes the entire dataset. It automatically handles\n    varying fields, mixed types, nested structures, and identifies required fields.\n\n    Args:\n        data: An iterable of data records (typically dictionaries).\n\n    Returns:\n        A JSON schema dictionary with `$schema`, type, properties, and required fields.\n\n    Example:\n        &gt;&gt;&gt; data = [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}]\n        &gt;&gt;&gt; schema = infer_schema(data)\n        &gt;&gt;&gt; schema[\"properties\"][\"name\"]\n        {'type': 'string'}\n        &gt;&gt;&gt; schema[\"required\"]\n        ['age', 'name']\n    \"\"\"\n    records = list(data)\n    if not records:\n        return {\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"type\": \"object\",\n            \"properties\": {},\n        }\n\n    # Infer schema for each record\n    inferred_schemas = [infer_value_schema(rec) for rec in records]\n\n    # Merge all inferred schemas\n    merged_schema = None\n    for s in inferred_schemas:\n        merged_schema = merge_schemas(merged_schema, s)\n\n    # Add required fields recursively\n    if merged_schema:\n        add_required_fields(merged_schema, records)\n\n    # Add the meta-schema URL\n    final_schema = {\"$schema\": \"http://json-schema.org/draft-07/schema#\"}\n    if merged_schema:\n        final_schema.update(merged_schema)\n\n    return final_schema\n</code></pre>"},{"location":"reference/#ja.expr","title":"<code>ja.expr</code>","text":"<p>Expression parser for ja commands.</p> <p>This module provides a lightweight expression parser that allows intuitive syntax without quotes for most common cases.</p>"},{"location":"reference/#ja.expr-classes","title":"Classes","text":""},{"location":"reference/#ja.expr.ExprEval","title":"<code>ExprEval</code>","text":"<p>Parse and evaluate expressions for filtering, comparison, and arithmetic.</p> Source code in <code>ja/expr.py</code> <pre><code>class ExprEval:\n    \"\"\"Parse and evaluate expressions for filtering, comparison, and arithmetic.\"\"\"\n\n    def __init__(self):\n        # Operators in precedence order (longest first to handle &gt;= before &gt;)\n        self.operators = [\n            (\"==\", operator.eq),\n            (\"!=\", operator.ne),\n            (\"&gt;=\", operator.ge),\n            (\"&lt;=\", operator.le),\n            (\"&gt;\", operator.gt),\n            (\"&lt;\", operator.lt),\n        ]\n\n    def parse_value(self, value_str: str) -&gt; Any:\n        \"\"\"Parse a value string into appropriate Python type.\n\n        Examples:\n            \"123\" -&gt; 123\n            \"12.5\" -&gt; 12.5\n            \"true\" -&gt; True\n            \"false\" -&gt; False\n            \"null\" -&gt; None\n            \"active\" -&gt; \"active\" (string)\n        \"\"\"\n        value_str = value_str.strip()\n\n        # Empty string\n        if not value_str:\n            return \"\"\n\n        # Boolean literals (case-insensitive)\n        if value_str.lower() == \"true\":\n            return True\n        if value_str.lower() == \"false\":\n            return False\n\n        # Null literal\n        if value_str.lower() in (\"null\", \"none\"):\n            return None\n\n        # Numbers\n        try:\n            if \".\" in value_str:\n                return float(value_str)\n            return int(value_str)\n        except ValueError:\n            pass\n\n        # Quoted strings (remove quotes)\n        if (value_str.startswith('\"') and value_str.endswith('\"')) or (\n            value_str.startswith(\"'\") and value_str.endswith(\"'\")\n        ):\n            return value_str[1:-1]\n\n        # Unquoted strings (the nice default!)\n        return value_str\n\n    def get_field_value(self, obj: Dict[str, Any], field_path: str) -&gt; Any:\n        \"\"\"Get value from nested object using dot notation.\n\n        Examples:\n            get_field_value({\"user\": {\"name\": \"Alice\"}}, \"user.name\") -&gt; \"Alice\"\n            get_field_value({\"items\": [{\"id\": 1}]}, \"items[0].id\") -&gt; 1\n        \"\"\"\n        if not field_path:\n            return obj\n\n        current = obj\n\n        # Handle array indexing and dots\n        parts = re.split(r\"\\.|\\[|\\]\", field_path)\n        parts = [p for p in parts if p]  # Remove empty strings\n\n        for part in parts:\n            if current is None:\n                return None\n\n            # Try as dict key\n            if isinstance(current, dict):\n                current = current.get(part)\n            # Try as array index\n            elif isinstance(current, list):\n                try:\n                    idx = int(part)\n                    current = current[idx] if 0 &lt;= idx &lt; len(current) else None\n                except (ValueError, IndexError):\n                    return None\n            else:\n                return None\n\n        return current\n\n    def set_field_value(self, obj: Dict[str, Any], field_path: str, value: Any) -&gt; None:\n        \"\"\"Set value in nested object using dot notation.\"\"\"\n        if not field_path:\n            return\n\n        parts = field_path.split(\".\")\n        current = obj\n\n        # Navigate to the parent of the target field\n        for part in parts[:-1]:\n            if part not in current:\n                current[part] = {}\n            current = current[part]\n\n        # Set the value\n        current[parts[-1]] = value\n\n    def evaluate_comparison(self, left: Any, op_str: str, right: Any) -&gt; bool:\n        \"\"\"Evaluate a comparison operation.\"\"\"\n        op_func = None\n        for op, func in self.operators:\n            if op == op_str:\n                op_func = func\n                break\n\n        if op_func is None:\n            raise ValueError(f\"Unknown operator: {op_str}\")\n\n        # Special handling for null comparisons\n        if left is None or right is None:\n            if op_str == \"==\":\n                return left == right\n            elif op_str == \"!=\":\n                return left != right\n            else:\n                return False\n\n        # Type coercion for comparison\n        try:\n            return op_func(left, right)\n        except (TypeError, ValueError):\n            # If comparison fails, try string comparison\n            try:\n                return op_func(str(left), str(right))\n            except:\n                return False\n\n    def evaluate(self, expr: str, context: Dict[str, Any]) -&gt; bool:\n        \"\"\"Parse and evaluate an expression.\n\n        Examples:\n            \"status == active\"\n            \"age &gt; 30\"\n            \"user.type == premium\"\n        \"\"\"\n        expr = expr.strip()\n\n        # Empty expression is false\n        if not expr:\n            return False\n\n        # Check for operators\n        for op_str, op_func in self.operators:\n            if op_str in expr:\n                # Split on the FIRST occurrence of the operator\n                parts = expr.split(op_str, 1)\n                if len(parts) == 2:\n                    left_expr = parts[0].strip()\n                    right_expr = parts[1].strip()\n\n                    # Left side is always a field path\n                    left_val = self.get_field_value(context, left_expr)\n\n                    # Right side: check if it's a field or a literal\n                    # A token is a field if it exists as a key in the context\n                    # and is not a boolean/null keyword.\n                    if right_expr in context and right_expr.lower() not in ['true', 'false', 'null', 'none']:\n                        # It's a field reference\n                        right_val = self.get_field_value(context, right_expr)\n                    else:\n                        # It's a literal value\n                        right_val = self.parse_value(right_expr)\n\n                    return self.evaluate_comparison(left_val, op_str, right_val)\n\n        # No operator found - treat as existence/truthiness check\n        value = self.get_field_value(context, expr)\n        return bool(value)\n\n    def evaluate_arithmetic(\n        self, expr: str, context: Dict[str, Any]\n    ) -&gt; Optional[float]:\n        \"\"\"Evaluate simple arithmetic expressions.\n\n        Examples:\n            \"amount * 1.1\"\n            \"score + bonus\"\n        \"\"\"\n        # Simple arithmetic support\n        for op, func in [\n            (\"*\", operator.mul),\n            (\"+\", operator.add),\n            (\"-\", operator.sub),\n            (\"/\", operator.truediv),\n        ]:\n            if op in expr:\n                parts = expr.split(op, 1)\n                if len(parts) == 2:\n                    left_str = parts[0].strip()\n                    right_str = parts[1].strip()\n\n                    # Get left value (field or literal)\n                    left_val = self.get_field_value(context, left_str)\n                    if left_val is None:\n                        left_val = self.parse_value(left_str)\n\n                    # Get right value (field or literal)\n                    right_val = self.get_field_value(context, right_str)\n                    if right_val is None:\n                        right_val = self.parse_value(right_str)\n\n                    try:\n                        return func(float(left_val), float(right_val))\n                    except (TypeError, ValueError):\n                        return None\n\n        # No operator - try as field or literal\n        val = self.get_field_value(context, expr)\n        if val is None:\n            val = self.parse_value(expr)\n\n        try:\n            return float(val)\n        except (TypeError, ValueError):\n            return None\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval-functions","title":"Functions","text":""},{"location":"reference/#ja.expr.ExprEval.parse_value","title":"<code>parse_value(value_str)</code>","text":"<p>Parse a value string into appropriate Python type.</p> <p>Examples:</p> <p>\"123\" -&gt; 123 \"12.5\" -&gt; 12.5 \"true\" -&gt; True \"false\" -&gt; False \"null\" -&gt; None \"active\" -&gt; \"active\" (string)</p> Source code in <code>ja/expr.py</code> <pre><code>def parse_value(self, value_str: str) -&gt; Any:\n    \"\"\"Parse a value string into appropriate Python type.\n\n    Examples:\n        \"123\" -&gt; 123\n        \"12.5\" -&gt; 12.5\n        \"true\" -&gt; True\n        \"false\" -&gt; False\n        \"null\" -&gt; None\n        \"active\" -&gt; \"active\" (string)\n    \"\"\"\n    value_str = value_str.strip()\n\n    # Empty string\n    if not value_str:\n        return \"\"\n\n    # Boolean literals (case-insensitive)\n    if value_str.lower() == \"true\":\n        return True\n    if value_str.lower() == \"false\":\n        return False\n\n    # Null literal\n    if value_str.lower() in (\"null\", \"none\"):\n        return None\n\n    # Numbers\n    try:\n        if \".\" in value_str:\n            return float(value_str)\n        return int(value_str)\n    except ValueError:\n        pass\n\n    # Quoted strings (remove quotes)\n    if (value_str.startswith('\"') and value_str.endswith('\"')) or (\n        value_str.startswith(\"'\") and value_str.endswith(\"'\")\n    ):\n        return value_str[1:-1]\n\n    # Unquoted strings (the nice default!)\n    return value_str\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval.get_field_value","title":"<code>get_field_value(obj, field_path)</code>","text":"<p>Get value from nested object using dot notation.</p> <p>Examples:</p> <p>get_field_value({\"user\": {\"name\": \"Alice\"}}, \"user.name\") -&gt; \"Alice\" get_field_value({\"items\": [{\"id\": 1}]}, \"items[0].id\") -&gt; 1</p> Source code in <code>ja/expr.py</code> <pre><code>def get_field_value(self, obj: Dict[str, Any], field_path: str) -&gt; Any:\n    \"\"\"Get value from nested object using dot notation.\n\n    Examples:\n        get_field_value({\"user\": {\"name\": \"Alice\"}}, \"user.name\") -&gt; \"Alice\"\n        get_field_value({\"items\": [{\"id\": 1}]}, \"items[0].id\") -&gt; 1\n    \"\"\"\n    if not field_path:\n        return obj\n\n    current = obj\n\n    # Handle array indexing and dots\n    parts = re.split(r\"\\.|\\[|\\]\", field_path)\n    parts = [p for p in parts if p]  # Remove empty strings\n\n    for part in parts:\n        if current is None:\n            return None\n\n        # Try as dict key\n        if isinstance(current, dict):\n            current = current.get(part)\n        # Try as array index\n        elif isinstance(current, list):\n            try:\n                idx = int(part)\n                current = current[idx] if 0 &lt;= idx &lt; len(current) else None\n            except (ValueError, IndexError):\n                return None\n        else:\n            return None\n\n    return current\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval.set_field_value","title":"<code>set_field_value(obj, field_path, value)</code>","text":"<p>Set value in nested object using dot notation.</p> Source code in <code>ja/expr.py</code> <pre><code>def set_field_value(self, obj: Dict[str, Any], field_path: str, value: Any) -&gt; None:\n    \"\"\"Set value in nested object using dot notation.\"\"\"\n    if not field_path:\n        return\n\n    parts = field_path.split(\".\")\n    current = obj\n\n    # Navigate to the parent of the target field\n    for part in parts[:-1]:\n        if part not in current:\n            current[part] = {}\n        current = current[part]\n\n    # Set the value\n    current[parts[-1]] = value\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval.evaluate_comparison","title":"<code>evaluate_comparison(left, op_str, right)</code>","text":"<p>Evaluate a comparison operation.</p> Source code in <code>ja/expr.py</code> <pre><code>def evaluate_comparison(self, left: Any, op_str: str, right: Any) -&gt; bool:\n    \"\"\"Evaluate a comparison operation.\"\"\"\n    op_func = None\n    for op, func in self.operators:\n        if op == op_str:\n            op_func = func\n            break\n\n    if op_func is None:\n        raise ValueError(f\"Unknown operator: {op_str}\")\n\n    # Special handling for null comparisons\n    if left is None or right is None:\n        if op_str == \"==\":\n            return left == right\n        elif op_str == \"!=\":\n            return left != right\n        else:\n            return False\n\n    # Type coercion for comparison\n    try:\n        return op_func(left, right)\n    except (TypeError, ValueError):\n        # If comparison fails, try string comparison\n        try:\n            return op_func(str(left), str(right))\n        except:\n            return False\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval.evaluate","title":"<code>evaluate(expr, context)</code>","text":"<p>Parse and evaluate an expression.</p> <p>Examples:</p> <p>\"status == active\" \"age &gt; 30\" \"user.type == premium\"</p> Source code in <code>ja/expr.py</code> <pre><code>def evaluate(self, expr: str, context: Dict[str, Any]) -&gt; bool:\n    \"\"\"Parse and evaluate an expression.\n\n    Examples:\n        \"status == active\"\n        \"age &gt; 30\"\n        \"user.type == premium\"\n    \"\"\"\n    expr = expr.strip()\n\n    # Empty expression is false\n    if not expr:\n        return False\n\n    # Check for operators\n    for op_str, op_func in self.operators:\n        if op_str in expr:\n            # Split on the FIRST occurrence of the operator\n            parts = expr.split(op_str, 1)\n            if len(parts) == 2:\n                left_expr = parts[0].strip()\n                right_expr = parts[1].strip()\n\n                # Left side is always a field path\n                left_val = self.get_field_value(context, left_expr)\n\n                # Right side: check if it's a field or a literal\n                # A token is a field if it exists as a key in the context\n                # and is not a boolean/null keyword.\n                if right_expr in context and right_expr.lower() not in ['true', 'false', 'null', 'none']:\n                    # It's a field reference\n                    right_val = self.get_field_value(context, right_expr)\n                else:\n                    # It's a literal value\n                    right_val = self.parse_value(right_expr)\n\n                return self.evaluate_comparison(left_val, op_str, right_val)\n\n    # No operator found - treat as existence/truthiness check\n    value = self.get_field_value(context, expr)\n    return bool(value)\n</code></pre>"},{"location":"reference/#ja.expr.ExprEval.evaluate_arithmetic","title":"<code>evaluate_arithmetic(expr, context)</code>","text":"<p>Evaluate simple arithmetic expressions.</p> <p>Examples:</p> <p>\"amount * 1.1\" \"score + bonus\"</p> Source code in <code>ja/expr.py</code> <pre><code>def evaluate_arithmetic(\n    self, expr: str, context: Dict[str, Any]\n) -&gt; Optional[float]:\n    \"\"\"Evaluate simple arithmetic expressions.\n\n    Examples:\n        \"amount * 1.1\"\n        \"score + bonus\"\n    \"\"\"\n    # Simple arithmetic support\n    for op, func in [\n        (\"*\", operator.mul),\n        (\"+\", operator.add),\n        (\"-\", operator.sub),\n        (\"/\", operator.truediv),\n    ]:\n        if op in expr:\n            parts = expr.split(op, 1)\n            if len(parts) == 2:\n                left_str = parts[0].strip()\n                right_str = parts[1].strip()\n\n                # Get left value (field or literal)\n                left_val = self.get_field_value(context, left_str)\n                if left_val is None:\n                    left_val = self.parse_value(left_str)\n\n                # Get right value (field or literal)\n                right_val = self.get_field_value(context, right_str)\n                if right_val is None:\n                    right_val = self.parse_value(right_str)\n\n                try:\n                    return func(float(left_val), float(right_val))\n                except (TypeError, ValueError):\n                    return None\n\n    # No operator - try as field or literal\n    val = self.get_field_value(context, expr)\n    if val is None:\n        val = self.parse_value(expr)\n\n    try:\n        return float(val)\n    except (TypeError, ValueError):\n        return None\n</code></pre>"},{"location":"advanced/repl/","title":"Interactive REPL Guide","text":"<p>The <code>ja</code> REPL (Read-Eval-Print Loop) provides an interactive environment for building data pipelines step-by-step. It's perfect for data exploration, prototyping complex queries, and learning the tool.</p>"},{"location":"advanced/repl/#getting-started","title":"Getting Started","text":"<p>Launch the REPL:</p> <pre><code>ja repl\n</code></pre> <p>You'll see:</p> <pre><code>Welcome to ja REPL! \ud83d\ude80 Type 'help' for commands, 'exit' to quit.\nja&gt;\n</code></pre>"},{"location":"advanced/repl/#basic-commands","title":"Basic Commands","text":""},{"location":"advanced/repl/#setting-data-source","title":"Setting Data Source","text":"<pre><code>ja&gt; from orders.jsonl\nInput source set to: orders.jsonl\n\nja&gt; from stdin\nInput source set to: stdin\n</code></pre>"},{"location":"advanced/repl/#building-a-pipeline","title":"Building a Pipeline","text":"<pre><code>ja&gt; from orders.jsonl\nja&gt; select status == \"shipped\"\nAdded: select status == \"shipped\"\nja&gt; groupby customer\nAdded: groupby customer\nja&gt; agg total=sum(amount)\nAdded: agg total=sum(amount)\n</code></pre>"},{"location":"advanced/repl/#viewing-the-pipeline","title":"Viewing the Pipeline","text":"<pre><code>ja&gt; pipeline\nCurrent pipeline:\n  Input: orders.jsonl\n  1. select status == \"shipped\"\n  2. groupby customer\n  3. agg total=sum(amount)\n</code></pre>"},{"location":"advanced/repl/#executing-the-pipeline","title":"Executing the Pipeline","text":"<pre><code>ja&gt; execute\nExecuting: ja select 'status == \"shipped\"' orders.jsonl | ja groupby customer - | ja agg total=sum(amount) -\n\n--- Output ---\n{\"customer\": \"Alice\", \"total\": 179.98}\n{\"customer\": \"Charlie\", \"total\": 199.99}\n--------------\n</code></pre>"},{"location":"advanced/repl/#advanced-features","title":"Advanced Features","text":""},{"location":"advanced/repl/#no-quotes-required","title":"No Quotes Required","text":"<p>Unlike the command line, expressions don't need quotes in the REPL:</p> <pre><code># Command line\nja select 'age &gt; 30 and status == \"active\"' users.jsonl\n\n# REPL\nja&gt; select age &gt; 30 and status == \"active\"\n</code></pre>"},{"location":"advanced/repl/#limited-output","title":"Limited Output","text":"<p>View just a few lines while building your pipeline:</p> <pre><code>ja&gt; execute --lines=5\n</code></pre>"},{"location":"advanced/repl/#generate-scripts","title":"Generate Scripts","text":"<p>See the equivalent bash script:</p> <pre><code>ja&gt; compile\n\n--- Compiled Bash Script ---\n#!/bin/bash\n# Generated by ja REPL\nja select 'status == \"shipped\"' orders.jsonl | \\\n  ja groupby customer - | \\\n  ja agg 'total=sum(amount)' -\n--------------------------\n</code></pre>"},{"location":"advanced/repl/#reset-pipeline","title":"Reset Pipeline","text":"<p>Start over:</p> <pre><code>ja&gt; reset\nPipeline reset.\n</code></pre>"},{"location":"advanced/repl/#data-exploration-workflow","title":"Data Exploration Workflow","text":""},{"location":"advanced/repl/#1-start-with-data-inspection","title":"1. Start with Data Inspection","text":"<pre><code>ja&gt; from large_dataset.jsonl\nja&gt; execute --lines=3\n# See the structure and sample data\n</code></pre>"},{"location":"advanced/repl/#2-build-filters-incrementally","title":"2. Build Filters Incrementally","text":"<pre><code>ja&gt; select timestamp &gt; \"2024-01-01\"\nja&gt; execute --lines=5\n# Check the filtering is working\n\nja&gt; select amount &gt; 100\nja&gt; execute --lines=5\n# Add another filter and verify\n</code></pre>"},{"location":"advanced/repl/#3-add-transformations","title":"3. Add Transformations","text":"<pre><code>ja&gt; project customer,amount,month=timestamp[0:7]\nja&gt; execute --lines=5\n# See the transformed data\n</code></pre>"},{"location":"advanced/repl/#4-group-and-aggregate","title":"4. Group and Aggregate","text":"<pre><code>ja&gt; groupby month\nja&gt; execute --lines=10\n# Inspect the grouping\n\nja&gt; groupby customer\nja&gt; execute --lines=10\n# Add second level grouping\n\nja&gt; agg revenue=sum(amount),orders=count\nja&gt; execute\n# Final aggregation\n</code></pre>"},{"location":"advanced/repl/#complex-query-building","title":"Complex Query Building","text":""},{"location":"advanced/repl/#multi-join-analysis","title":"Multi-Join Analysis","text":"<pre><code>ja&gt; from orders.jsonl\nja&gt; join customers.jsonl --on customer_id=id\nja&gt; execute --lines=3\n# Check the join worked\n\nja&gt; join products.jsonl --on product_id=id  \nja&gt; execute --lines=3\n# Add second join\n\nja&gt; select order_date &gt; \"2024-01-01\"\nja&gt; project customer.name,product.category,total=quantity*price\nja&gt; groupby customer.tier\nja&gt; groupby product.category\nja&gt; agg revenue=sum(total),orders=count\nja&gt; execute\n</code></pre>"},{"location":"advanced/repl/#time-series-analysis","title":"Time Series Analysis","text":"<pre><code>ja&gt; from events.jsonl\nja&gt; project timestamp,user_id,event_type,date=timestamp[0:10]\nja&gt; execute --lines=5\n\nja&gt; groupby date\nja&gt; execute --lines=10\n# Check daily grouping\n\nja&gt; groupby event_type\nja&gt; agg events=count,unique_users=count_distinct(user_id)\nja&gt; sort date,event_type\nja&gt; execute\n</code></pre>"},{"location":"advanced/repl/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":""},{"location":"advanced/repl/#check-each-step","title":"Check Each Step","text":"<pre><code>ja&gt; from data.jsonl\nja&gt; select complicated_condition\nja&gt; execute --lines=1\n# Is anything matching?\n\nja&gt; pipeline\n# Review the steps so far\n\nja&gt; reset\n# Start over if needed\n</code></pre>"},{"location":"advanced/repl/#inspect-intermediate-results","title":"Inspect Intermediate Results","text":"<pre><code>ja&gt; groupby category\nja&gt; execute --lines=5\n# See the grouping metadata\n\nja&gt; select _group_size &gt; 10\nja&gt; execute --lines=5\n# Filter based on group size\n</code></pre>"},{"location":"advanced/repl/#common-issues","title":"Common Issues","text":"<p>No Output After Filtering:</p> <pre><code>ja&gt; from data.jsonl\nja&gt; execute --lines=5\n# Check source data\n\nja&gt; select some_condition\nja&gt; execute --lines=5\n# See if filter is too restrictive\n</code></pre> <p>Unexpected Grouping:</p> <pre><code>ja&gt; groupby field\nja&gt; project field,_groups,_group_size\nja&gt; execute --lines=10\n# Inspect the grouping structure\n</code></pre>"},{"location":"advanced/repl/#repl-specific-features","title":"REPL-Specific Features","text":""},{"location":"advanced/repl/#smart-expression-parsing","title":"Smart Expression Parsing","text":"<p>The REPL intelligently parses expressions:</p> <pre><code># These all work without quotes\nja&gt; select age &gt; 30\nja&gt; select status == \"active\" and score &gt;= 80\nja&gt; project name,total=price*quantity\nja&gt; agg revenue=sum(amount),count\n</code></pre>"},{"location":"advanced/repl/#command-history","title":"Command History","text":"<p>Use arrow keys to navigate command history:</p> <ul> <li>\u2191/\u2193: Previous/next command</li> <li>Ctrl+C: Interrupt current command (continues REPL)</li> <li>Ctrl+D or <code>exit</code>: Exit REPL</li> </ul>"},{"location":"advanced/repl/#auto-completion","title":"Auto-completion","text":"<p>The REPL provides context-aware suggestions for:</p> <ul> <li>Command names</li> <li>Field names (when available)</li> <li>Common aggregation functions</li> </ul>"},{"location":"advanced/repl/#scripting-from-repl","title":"Scripting from REPL","text":""},{"location":"advanced/repl/#save-pipelines","title":"Save Pipelines","text":"<p>Generate scripts for reuse:</p> <pre><code>ja&gt; from orders.jsonl\nja&gt; select status == \"shipped\"\nja&gt; groupby customer\nja&gt; agg total=sum(amount)\nja&gt; compile &gt; analysis_script.sh\n</code></pre>"},{"location":"advanced/repl/#parameterized-queries","title":"Parameterized Queries","text":"<p>Build templates:</p> <pre><code># In the REPL, build your pipeline\nja&gt; from data.jsonl\nja&gt; select 'date &gt;= \"$START_DATE\"'\nja&gt; groupby category  \nja&gt; agg total=sum(amount)\nja&gt; compile\n\n# Then edit the generated script to use variables\n</code></pre>"},{"location":"advanced/repl/#best-practices","title":"Best Practices","text":""},{"location":"advanced/repl/#1-start-small","title":"1. Start Small","text":"<pre><code>ja&gt; from large_file.jsonl\nja&gt; execute --lines=5\n# Always check a sample first\n</code></pre>"},{"location":"advanced/repl/#2-build-incrementally","title":"2. Build Incrementally","text":"<pre><code># Add operations one at a time\nja&gt; select condition1\nja&gt; execute --lines=5\nja&gt; select condition2  \nja&gt; execute --lines=5\nja&gt; groupby field\nja&gt; execute --lines=10\n</code></pre>"},{"location":"advanced/repl/#3-use-the-pipeline-view","title":"3. Use the Pipeline View","text":"<pre><code>ja&gt; pipeline\n# Regular check of what you've built\n</code></pre>"},{"location":"advanced/repl/#4-save-complex-queries","title":"4. Save Complex Queries","text":"<pre><code>ja&gt; compile &gt; my_analysis.sh\n# Don't lose complex work\n</code></pre>"},{"location":"advanced/repl/#5-explore-before-committing","title":"5. Explore Before Committing","text":"<pre><code># Try different approaches\nja&gt; groupby customer\nja&gt; execute --lines=5\nja&gt; reset\nja&gt; groupby product  \nja&gt; execute --lines=5\n# Compare different groupings\n</code></pre>"},{"location":"advanced/repl/#integration-with-external-tools","title":"Integration with External Tools","text":""},{"location":"advanced/repl/#pipe-to-external-commands","title":"Pipe to External Commands","text":"<pre><code>ja&gt; execute | jq '.[] | select(.revenue &gt; 1000)'\nja&gt; execute | head -20\nja&gt; execute | sort -n\n</code></pre>"},{"location":"advanced/repl/#export-results","title":"Export Results","text":"<pre><code>ja&gt; execute &gt; results.jsonl\nja&gt; compile &gt; analysis.sh\n</code></pre>"},{"location":"advanced/repl/#help-and-documentation","title":"Help and Documentation","text":""},{"location":"advanced/repl/#in-repl-help","title":"In-REPL Help","text":"<pre><code>ja&gt; help\n# Comprehensive help with examples\n\nja&gt; help select\n# Command-specific help (if available)\n</code></pre>"},{"location":"advanced/repl/#examples-and-tips","title":"Examples and Tips","text":"<p>The REPL help includes:</p> <ul> <li>Command examples</li> <li>Expression syntax</li> <li>Aggregation functions</li> <li>Common patterns</li> <li>Troubleshooting tips</li> </ul>"},{"location":"advanced/repl/#advanced-workflows","title":"Advanced Workflows","text":""},{"location":"advanced/repl/#data-quality-exploration","title":"Data Quality Exploration","text":"<pre><code>ja&gt; from messy_data.jsonl\nja&gt; project name,email,age\nja&gt; execute --lines=10\n# See what fields look like\n\nja&gt; agg count,nulls=count_if(email==null),invalids=count_if(!email.contains(\"@\"))\nja&gt; execute\n# Check data quality\n\nja&gt; select email != null and email.contains(\"@\") and age &gt; 0\nja&gt; execute --lines=5\n# Clean data step by step\n</code></pre>"},{"location":"advanced/repl/#schema-discovery","title":"Schema Discovery","text":"<pre><code>ja&gt; from unknown_data.jsonl\nja&gt; execute --lines=1\n# See the structure\n\nja&gt; project _keys=keys(.)\nja&gt; execute --lines=10\n# See all field names\n\nja&gt; groupby typeof(some_field)\nja&gt; agg count\nja&gt; execute\n# Check field types\n</code></pre>"},{"location":"advanced/repl/#performance-testing","title":"Performance Testing","text":"<pre><code>ja&gt; from huge_file.jsonl\nja&gt; select simple_condition\nja&gt; execute --lines=1000\n# Test filter performance\n\nja&gt; project field1,field2,field3\nja&gt; execute --lines=1000  \n# Test projection performance\n</code></pre>"},{"location":"advanced/repl/#next-steps","title":"Next Steps","text":"<ul> <li>Performance Optimization - Make your queries faster</li> <li>Complex Expressions - Advanced filtering</li> <li>Cookbook Examples - Real-world patterns</li> </ul>"},{"location":"cli/overview/","title":"CLI Overview","text":"<p>The ja command-line tool is your gateway to powerful JSONL data manipulation. This page provides an overview of the CLI architecture, usage patterns, and core principles.</p>"},{"location":"cli/overview/#command-structure","title":"Command Structure","text":"<p>All ja commands follow a consistent pattern:</p> <pre><code>ja &lt;command&gt; [options] [files...]\n</code></pre>"},{"location":"cli/overview/#anatomy-of-a-command","title":"Anatomy of a Command","text":"<pre><code>ja select 'age &gt; 30' --output filtered.jsonl users.jsonl\n\u2502  \u2502      \u2502          \u2502                    \u2502\n\u2502  \u2502      \u2502          \u2502                    \u2514\u2500 Input file(s)\n\u2502  \u2502      \u2502          \u2514\u2500 Optional flags\n\u2502  \u2502      \u2514\u2500 Command-specific arguments\n\u2502  \u2514\u2500 Command name\n\u2514\u2500 Program name\n</code></pre>"},{"location":"cli/overview/#core-commands","title":"Core Commands","text":""},{"location":"cli/overview/#data-filtering-selection","title":"Data Filtering &amp; Selection","text":"Command Purpose Example select Filter rows by condition <code>ja select 'age &gt; 30' users.jsonl</code> distinct Remove duplicate rows <code>ja distinct users.jsonl</code>"},{"location":"cli/overview/#data-transformation","title":"Data Transformation","text":"Command Purpose Example project Select specific fields <code>ja project name,email users.jsonl</code> rename Rename fields <code>ja rename old=new users.jsonl</code> explode Flatten arrays <code>ja explode tags users.jsonl</code> implode Group values into arrays <code>ja implode --key user_id --field tag</code>"},{"location":"cli/overview/#data-combination","title":"Data Combination","text":"Command Purpose Example join Combine datasets <code>ja join users.jsonl orders.jsonl --on id=user_id</code> union Merge all rows <code>ja union file1.jsonl file2.jsonl</code> intersection Find common rows <code>ja intersection file1.jsonl file2.jsonl</code> difference Find unique rows <code>ja difference file1.jsonl file2.jsonl</code> product Cartesian product <code>ja product file1.jsonl file2.jsonl</code>"},{"location":"cli/overview/#aggregation-grouping","title":"Aggregation &amp; Grouping","text":"Command Purpose Example groupby Group by fields <code>ja groupby city users.jsonl</code> agg Aggregate grouped data <code>ja agg \"total=sum(amount)\"</code>"},{"location":"cli/overview/#data-organization","title":"Data Organization","text":"Command Purpose Example sort Sort by field <code>ja sort age --desc users.jsonl</code> collect Collect stream into array <code>ja collect users.jsonl</code>"},{"location":"cli/overview/#import-export","title":"Import &amp; Export","text":"Command Purpose Example import csv Convert CSV to JSONL <code>ja import csv data.csv</code> export csv Convert JSONL to CSV <code>ja export csv data.jsonl</code> export json Convert to JSON array <code>ja export json data.jsonl</code>"},{"location":"cli/overview/#schema-validation","title":"Schema &amp; Validation","text":"Command Purpose Example schema infer Infer JSON schema <code>ja schema infer users.jsonl</code> schema validate Validate against schema <code>ja schema validate schema.json users.jsonl</code>"},{"location":"cli/overview/#interactive","title":"Interactive","text":"Command Purpose Example repl Interactive mode <code>ja repl users.jsonl</code>"},{"location":"cli/overview/#inputoutput-patterns","title":"Input/Output Patterns","text":""},{"location":"cli/overview/#reading-input","title":"Reading Input","text":"<p>ja commands accept input in three ways:</p> From FileFrom stdinFrom Multiple Files <pre><code>ja select 'age &gt; 30' users.jsonl\n</code></pre> <pre><code>cat users.jsonl | ja select 'age &gt; 30'\n</code></pre> <pre><code>ja union file1.jsonl file2.jsonl file3.jsonl\n</code></pre>"},{"location":"cli/overview/#writing-output","title":"Writing Output","text":"<p>By default, output goes to stdout:</p> To stdout (default)To File (redirect)To File (--output flag)To Pipeline <pre><code>ja select 'age &gt; 30' users.jsonl\n# Output appears on screen\n</code></pre> <pre><code>ja select 'age &gt; 30' users.jsonl &gt; filtered.jsonl\n</code></pre> <pre><code>ja select 'age &gt; 30' --output filtered.jsonl users.jsonl\n</code></pre> <pre><code>ja select 'age &gt; 30' users.jsonl | ja project name,email\n</code></pre>"},{"location":"cli/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"cli/overview/#pattern-1-filter-transform-save","title":"Pattern 1: Filter-Transform-Save","text":"<pre><code>cat input.jsonl \\\n  | ja select 'status == \"active\"' \\\n  | ja project id,name,email \\\n  | ja sort name \\\n  &gt; output.jsonl\n</code></pre>"},{"location":"cli/overview/#pattern-2-join-aggregate-report","title":"Pattern 2: Join-Aggregate-Report","text":"<pre><code>ja join users.jsonl orders.jsonl --on user_id=user_id \\\n  | ja groupby user.name --agg total=sum:amount,count \\\n  | ja sort total --desc \\\n  | head -10\n</code></pre>"},{"location":"cli/overview/#pattern-3-multi-source-union","title":"Pattern 3: Multi-Source Union","text":"<pre><code>ja union logs-*.jsonl \\\n  | ja select 'level == \"ERROR\"' \\\n  | ja project timestamp,message,service\n</code></pre>"},{"location":"cli/overview/#pattern-4-schema-first-validation","title":"Pattern 4: Schema-First Validation","text":"<pre><code># 1. Infer schema from good data\nja schema infer good_data.jsonl &gt; schema.json\n\n# 2. Validate new data\nja schema validate schema.json new_data.jsonl\n\n# 3. Process if valid\nja select 'verified == true' new_data.jsonl | ...\n</code></pre>"},{"location":"cli/overview/#global-options","title":"Global Options","text":"<p>These flags work with most commands:</p> Flag Description Example <code>--help</code>, <code>-h</code> Show help <code>ja select --help</code> <code>--version</code> Show version <code>ja --version</code> <code>--output &lt;file&gt;</code>, <code>-o</code> Output file <code>ja select ... -o result.jsonl</code> <code>--verbose</code>, <code>-v</code> Verbose output <code>ja -v select ...</code>"},{"location":"cli/overview/#expression-syntax","title":"Expression Syntax","text":"<p>Many commands use expressions for filtering or calculations:</p>"},{"location":"cli/overview/#basic-expressions","title":"Basic Expressions","text":"<pre><code># Equality\nja select 'status == \"active\"'\n\n# Comparison\nja select 'age &gt; 30'\nja select 'price &lt;= 100'\n\n# Logical operators\nja select 'age &gt; 18 and status == \"active\"'\nja select 'role == \"admin\" or role == \"owner\"'\n\n# Null checks\nja select 'email != null'\n</code></pre>"},{"location":"cli/overview/#nested-field-access","title":"Nested Field Access","text":"<pre><code># Dot notation\nja select 'user.profile.age &gt; 25'\nja project user.name,user.email\n</code></pre>"},{"location":"cli/overview/#value-types","title":"Value Types","text":"<pre><code># Strings (quoted)\n'name == \"Alice\"'\n\n# Numbers (unquoted)\n'age &gt; 30'\n\n# Booleans\n'is_active == true'\n'verified == false'\n\n# Null\n'value == null'\n'field != null'\n</code></pre>"},{"location":"cli/overview/#working-with-nested-data","title":"Working with Nested Data","text":"<p>jsonl-algebra excels at nested JSON structures:</p>"},{"location":"cli/overview/#accessing-nested-fields","title":"Accessing Nested Fields","text":"<pre><code>{\"user\": {\"profile\": {\"email\": \"alice@example.com\"}}}\n</code></pre> <pre><code># Select nested field\nja project user.profile.email data.jsonl\n\n# Filter on nested field\nja select 'user.profile.age &gt; 25' data.jsonl\n\n# Join on nested field\nja join users.jsonl orders.jsonl --on user.id=customer.id\n</code></pre>"},{"location":"cli/overview/#flattening-arrays","title":"Flattening Arrays","text":"<pre><code>{\"id\": 1, \"tags\": [\"admin\", \"premium\"]}\n</code></pre> <pre><code># Explode creates one row per tag\nja explode tags data.jsonl\n# Output:\n# {\"id\": 1, \"tags\": \"admin\"}\n# {\"id\": 1, \"tags\": \"premium\"}\n</code></pre>"},{"location":"cli/overview/#performance-considerations","title":"Performance Considerations","text":""},{"location":"cli/overview/#streaming-operations","title":"Streaming Operations","text":"<p>These commands stream data (constant memory):</p> <ul> <li><code>select</code></li> <li><code>project</code></li> <li><code>rename</code></li> <li><code>explode</code></li> </ul> <pre><code># Efficient even for huge files\ncat huge.jsonl | ja select 'x &gt; 0' | head -10\n</code></pre>"},{"location":"cli/overview/#buffering-operations","title":"Buffering Operations","text":"<p>These commands buffer data (memory grows with input):</p> <ul> <li><code>sort</code></li> <li><code>distinct</code></li> <li><code>groupby</code></li> <li><code>join</code> (right side)</li> </ul> <pre><code># May use significant memory\nja sort name huge.jsonl\n</code></pre> <p>Optimization Strategy</p> <p>Filter data early in the pipeline to reduce memory usage: <pre><code># Good: Filter first\nja select 'status == \"active\"' huge.jsonl | ja sort name\n\n# Bad: Sort everything first\nja sort name huge.jsonl | ja select 'status == \"active\"'\n</code></pre></p>"},{"location":"cli/overview/#error-handling","title":"Error Handling","text":""},{"location":"cli/overview/#common-error-messages","title":"Common Error Messages","text":"<p>File Not Found <pre><code>$ ja select 'x &gt; 0' missing.jsonl\nError: File not found: missing.jsonl\n</code></pre></p> <p>Invalid Expression <pre><code>$ ja select 'invalid syntax' data.jsonl\nError: Invalid expression: invalid syntax\n</code></pre></p> <p>Missing Required Argument <pre><code>$ ja join users.jsonl orders.jsonl\nError: --on flag required for join operation\n</code></pre></p>"},{"location":"cli/overview/#error-output","title":"Error Output","text":"<p>Errors go to stderr, allowing proper piping:</p> <pre><code># Errors visible, output can be piped\nja select 'age &gt; 30' users.jsonl 2&gt; errors.log | ja project name\n</code></pre>"},{"location":"cli/overview/#exit-codes","title":"Exit Codes","text":"<p>ja uses standard exit codes:</p> Code Meaning <code>0</code> Success <code>1</code> General error <code>2</code> Command line syntax error <code>3</code> File I/O error <code>4</code> Invalid data/expression <p>Use in scripts:</p> <pre><code>if ja select 'status == \"active\"' users.jsonl &gt; active.jsonl; then\n    echo \"Filtering successful\"\nelse\n    echo \"Filtering failed\" &gt;&amp;2\n    exit 1\nfi\n</code></pre>"},{"location":"cli/overview/#environment-variables","title":"Environment Variables","text":"<p>Customize behavior with environment variables:</p> Variable Effect Example <code>JA_JSON_ERRORS</code> Output errors as JSON <code>export JA_JSON_ERRORS=1</code> <code>JA_COLOR</code> Enable/disable colors <code>export JA_COLOR=never</code> <code>JA_CACHE_SIZE</code> REPL cache size <code>export JA_CACHE_SIZE=1000</code>"},{"location":"cli/overview/#combining-with-unix-tools","title":"Combining with Unix Tools","text":"<p>ja plays well with standard Unix utilities:</p>"},{"location":"cli/overview/#with-grep","title":"With grep","text":"<pre><code># Find records containing \"error\"\nja project message logs.jsonl | grep -i error\n</code></pre>"},{"location":"cli/overview/#with-wc","title":"With wc","text":"<pre><code># Count filtered records\nja select 'status == \"active\"' users.jsonl | wc -l\n</code></pre>"},{"location":"cli/overview/#with-headtail","title":"With head/tail","text":"<pre><code># First 10 results\nja sort score --desc scores.jsonl | head -10\n\n# Last 5 results\nja sort timestamp scores.jsonl | tail -5\n</code></pre>"},{"location":"cli/overview/#with-parallel","title":"With parallel","text":"<pre><code># Process multiple files in parallel\nls *.jsonl | parallel 'ja select \"status == \\\"active\\\"\" {} &gt; {.}_active.jsonl'\n</code></pre>"},{"location":"cli/overview/#shell-completion","title":"Shell Completion","text":"<p>Enable tab completion for ja commands:</p> BashZshFish <pre><code># Add to ~/.bashrc\neval \"$(ja --completion bash)\"\n</code></pre> <pre><code># Add to ~/.zshrc\neval \"$(ja --completion zsh)\"\n</code></pre> <pre><code># Add to ~/.config/fish/config.fish\nja --completion fish | source\n</code></pre>"},{"location":"cli/overview/#getting-help","title":"Getting Help","text":""},{"location":"cli/overview/#built-in-help","title":"Built-in Help","text":"<pre><code># General help\nja --help\n\n# Command-specific help\nja select --help\nja join --help\nja groupby --help\n</code></pre>"},{"location":"cli/overview/#online-resources","title":"Online Resources","text":"<ul> <li>Command Reference - Detailed command documentation</li> <li>Examples - Real-world usage patterns</li> <li>Tutorials - Step-by-step guides</li> <li>FAQ - Common questions</li> </ul>"},{"location":"cli/overview/#best-practices","title":"Best Practices","text":"<ol> <li>Filter Early - Reduce data size before expensive operations</li> <li>Use Pipes - Build complex transformations incrementally</li> <li>Test Incrementally - Run each stage separately first</li> <li>Save Intermediate Results - For complex pipelines</li> <li>Validate Input - Use schema validation for critical data</li> <li>Handle Errors - Check exit codes in scripts</li> </ol>"},{"location":"cli/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Commands Reference - Learn each command in detail</li> <li>Examples &amp; Patterns - See real-world usage</li> <li>Quick Start Tutorial - Hands-on learning</li> <li>REPL Mode - Interactive exploration</li> </ul>"},{"location":"concepts/all-i-kept/","title":"All I Kept Was a <code>.jsonl</code> File","text":"<p>I Spent Weeks Designing a \u201cLightweight Database.\u201d  All I Kept Was a <code>.jsonl</code> File.</p>"},{"location":"concepts/all-i-kept/#1-the-premise","title":"1. The Premise","text":"<p>I wanted a tiny, version\u2011control\u2011friendly database format\u2014simpler than SQLite, richer than CSV. \u201cEasy,\u201d I thought. \u201cCSV plus a JSON schema sidecar, maybe a CLI, relational joins, views\u2026\u201d</p> <p>Spoiler: every new layer solved a problem the previous layer created.</p>"},{"location":"concepts/all-i-kept/#2-the-detour-adding-layers","title":"2. The Detour\u202f\u2014\u202fAdding Layers","text":"Layer Why I Added It What Went Wrong CSV + per\u2011table JSON schema Types, keys, validation Duplication; header drift; quoting hell Relation objects with streaming iterators Lazy memory use Exhausted iterators, subtle bugs View files &amp; materialization logic \u201cSQL\u2011like\u201d power IO noise, unclear semantics Full CLI w/ persist commands Nice UX Just wrappers for wrappers <p>Each addition felt clever\u2014until it didn\u2019t.</p>"},{"location":"concepts/all-i-kept/#3-the-unbuilding-phase","title":"3. The Un\u2011building Phase","text":"<p>I asked, \u201cWhat irreducible need remains if I delete this layer?\u201d Piece by piece I removed:</p> <ul> <li>per\u2011table schemas</li> <li>reset logic</li> <li>auto\u2011persist tricks</li> <li>even the catalog for foreign keys</li> </ul> <p>\u2026and nothing essential broke.</p>"},{"location":"concepts/all-i-kept/#4-what-survived","title":"4. What Survived","text":"<p>A single convention:</p> <p>One JSON object per line, in a file named <code>*.jsonl</code>.</p> <p>That\u2019s it. Need really advanced filtering? Pipe through <code>jq</code> or run a five\u2011line Python script.</p>"},{"location":"concepts/all-i-kept/#5-why-simpler-won","title":"5. Why Simpler Won","text":"Perks of <code>.jsonl</code> Hidden Cost Avoided Human\u2011diffable text No binary dumps Streamable GBs No exhausted generators Nested structures free No quoting gymnastics Zero tooling lock\u2011in No API promises to maintain"},{"location":"concepts/all-i-kept/#6-the-real-lesson-social-coordination","title":"6. The Real Lesson: Social Coordination","text":"<p>Most \u201cbig wins\u201d in data tooling aren\u2019t technical genius; they\u2019re social:</p> <ul> <li>CSV won because everyone agreed to tolerate its warts.</li> <li>Markdown won because \u201cgood enough\u201d beats rich\u2011text battles.</li> <li>Git won because a single mental model (\u201ccommit\u201d) spread like a meme.</li> </ul> <p>If a convention is:</p> <ol> <li>Plaintext</li> <li>Easy to explain in one sentence</li> <li>Good\u2011enough interop</li> </ol> <p>\u2026then the coordination win dwarfs any feature checklist.</p> <p><code>.jsonl</code> clears that bar. Anything I\u2019d add would mostly be me having fun\u2014not solving a mass pain\u2011point.</p>"},{"location":"concepts/all-i-kept/#7-what-i-actually-shipped","title":"7. What I Actually Shipped","text":"<p>Nothing\u2014except this insight:</p> <p>\u201cPut each record on its own JSON line, commit it, and move on.\u201d</p> <p>I closed my repo, published this post, and kept the loader script (\\~30\u202fLOC) in a gist.</p>"},{"location":"concepts/all-i-kept/#8-when-not-to-use-jsonl","title":"8. When Not to Use <code>.jsonl</code>","text":"<ul> <li>You need ACID transactions \u2192 SQLite/DuckDB</li> <li>You need strict typing &amp; joins at scale \u2192 Postgres / BigQuery</li> <li>You need columnar analytics \u2192 Parquet + DuckDB</li> </ul> <p>But for configs, logs, small/medium datasets, and exploratory hacks: <code>.jsonl</code> + <code>jq</code> + Git is unbeatable in simplicity\u2011per\u2011byte.</p>"},{"location":"concepts/all-i-kept/#9-takeaways","title":"9. Takeaways","text":"<ol> <li>Architect by deletion. Start adding; keep deleting until pain appears.</li> <li>Ship conventions, not frameworks. Naming the pattern is often enough.</li> <li>Judge by coordination cost. The simplest format lots of people accept beats a genius format nobody standardizes on.</li> </ol> <p>I didn\u2019t deliver a shiny package. (Well, I did deliver a shiny JSONL. I'm not a monster.)</p>"},{"location":"concepts/chained-groups/","title":"Chained Grouping: Deep Dive","text":"<p>Chained groupby is one of <code>ja</code>'s most innovative features. It allows you to build multi-level aggregations while maintaining the JSONL format throughout the pipeline.</p>"},{"location":"concepts/chained-groups/#the-problem-with-traditional-grouping","title":"The Problem with Traditional Grouping","text":"<p>Most data tools force you to specify all grouping levels upfront:</p> <pre><code>-- SQL requires specifying all levels at once\nSELECT region, product, SUM(amount)\nFROM sales\nGROUP BY region, product\n</code></pre> <p>This approach has limitations:</p> <ul> <li>Can't filter between grouping levels</li> <li>Can't inspect intermediate groupings</li> <li>Hard to build complex hierarchies progressively</li> <li>Doesn't compose well with other operations</li> </ul>"},{"location":"concepts/chained-groups/#the-ja-solution-metadata-preserving-grouping","title":"The ja Solution: Metadata-Preserving Grouping","text":"<p>Instead of immediately aggregating, <code>ja groupby</code> adds metadata to preserve grouping information:</p> <pre><code># First level: group by region\nja groupby region sales.jsonl\n</code></pre> <p>This adds metadata to each row:</p> <pre><code>{\n  \"sale_id\": 1,\n  \"region\": \"North\",\n  \"product\": \"Widget\",\n  \"amount\": 100,\n  \"_groups\": [{\"field\": \"region\", \"value\": \"North\"}],\n  \"_group_size\": 3,\n  \"_group_index\": 0\n}\n</code></pre>"},{"location":"concepts/chained-groups/#key-metadata-fields","title":"Key Metadata Fields","text":"<ul> <li><code>_groups</code>: Array of grouping levels with field names and values</li> <li><code>_group_size</code>: Number of rows in this group</li> <li><code>_group_index</code>: This row's position within its group</li> </ul>"},{"location":"concepts/chained-groups/#building-multi-level-hierarchies","title":"Building Multi-Level Hierarchies","text":""},{"location":"concepts/chained-groups/#two-level-grouping","title":"Two-Level Grouping","text":"<pre><code>ja groupby region sales.jsonl | ja groupby product\n</code></pre> <p>The second groupby extends the metadata:</p> <pre><code>{\n  \"sale_id\": 1,\n  \"region\": \"North\", \n  \"product\": \"Widget\",\n  \"amount\": 100,\n  \"_groups\": [\n    {\"field\": \"region\", \"value\": \"North\"},\n    {\"field\": \"product\", \"value\": \"Widget\"}\n  ],\n  \"_group_size\": 2,\n  \"_group_index\": 0\n}\n</code></pre>"},{"location":"concepts/chained-groups/#three-level-and-beyond","title":"Three-Level and Beyond","text":"<pre><code>ja groupby year sales.jsonl \\\n  | ja groupby region \\\n  | ja groupby product \\\n  | ja groupby month\n</code></pre> <p>Each level adds to the <code>_groups</code> array, creating a complete hierarchy.</p>"},{"location":"concepts/chained-groups/#the-power-of-composition","title":"The Power of Composition","text":""},{"location":"concepts/chained-groups/#filter-between-levels","title":"Filter Between Levels","text":"<pre><code># Group by user, filter active groups, then group by product\nja groupby user_id transactions.jsonl \\\n  | ja select '_group_size &gt; 5' \\\n  | ja groupby product_id \\\n  | ja agg total=sum(amount)\n</code></pre> <p>This finds users with more than 5 transactions, then analyzes their product preferences.</p>"},{"location":"concepts/chained-groups/#transform-between-levels","title":"Transform Between Levels","text":"<pre><code># Add computed fields between groupings\nja groupby customer orders.jsonl \\\n  | ja project customer,order_id,amount,is_large=amount&gt;100 \\\n  | ja groupby is_large \\\n  | ja agg count,avg_amount=avg(amount)\n</code></pre>"},{"location":"concepts/chained-groups/#inspect-intermediate-results","title":"Inspect Intermediate Results","text":"<pre><code># See the grouping structure\nja groupby region sales.jsonl | ja groupby product | head -3\n</code></pre> <p>You can examine the data at any stage to understand the grouping.</p>"},{"location":"concepts/chained-groups/#aggregation-the-final-step","title":"Aggregation: The Final Step","text":"<p>When you're ready to aggregate, <code>ja agg</code> uses the metadata to produce clean results:</p> <pre><code>ja groupby region sales.jsonl \\\n  | ja groupby product \\\n  | ja agg total=sum(amount),count,avg=avg(amount)\n</code></pre> <p>Output:</p> <pre><code>{\"region\": \"North\", \"product\": \"Widget\", \"total\": 500, \"count\": 3, \"avg\": 166.67}\n{\"region\": \"North\", \"product\": \"Gadget\", \"total\": 300, \"count\": 2, \"avg\": 150.00}\n{\"region\": \"South\", \"product\": \"Widget\", \"total\": 400, \"count\": 2, \"avg\": 200.00}\n</code></pre> <p>Notice how all grouping fields are preserved in the output.</p>"},{"location":"concepts/chained-groups/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"concepts/chained-groups/#conditional-aggregation-within-groups","title":"Conditional Aggregation Within Groups","text":"<pre><code>ja groupby department employees.jsonl \\\n  | ja agg \\\n      total_salary=sum(salary), \\\n      senior_count=count_if(level==\"senior\"), \\\n      avg_senior_salary=avg_if(salary,level==\"senior\")\n</code></pre>"},{"location":"concepts/chained-groups/#nested-field-grouping","title":"Nested Field Grouping","text":"<pre><code>ja groupby user.region sales.jsonl \\\n  | ja groupby product.category \\\n  | ja agg revenue=sum(amount)\n</code></pre>"},{"location":"concepts/chained-groups/#time-series-grouping","title":"Time-Series Grouping","text":"<pre><code>ja groupby date sales.jsonl \\\n  | ja project date,customer,amount,month=date[0:7] \\\n  | ja groupby month \\\n  | ja agg daily_avg=avg(amount)\n</code></pre>"},{"location":"concepts/chained-groups/#implementation-details","title":"Implementation Details","text":""},{"location":"concepts/chained-groups/#metadata-structure","title":"Metadata Structure","text":"<p>The <code>_groups</code> array maintains the complete grouping hierarchy:</p> <pre><code>\"_groups\": [\n  {\"field\": \"region\", \"value\": \"North\"},\n  {\"field\": \"product\", \"value\": \"Widget\"},\n  {\"field\": \"size\", \"value\": \"Large\"}\n]\n</code></pre>"},{"location":"concepts/chained-groups/#efficient-grouping","title":"Efficient Grouping","text":"<p>Internally, <code>ja</code> uses Python's <code>defaultdict</code> and tuple keys for efficient grouping:</p> <pre><code># Conceptual implementation\ngroup_key = tuple((g[\"field\"], g[\"value\"]) for g in row[\"_groups\"])\ngroups[group_key].append(clean_row)\n</code></pre>"},{"location":"concepts/chained-groups/#memory-efficiency","title":"Memory Efficiency","text":"<p>Because <code>ja</code> processes data streaming, even complex multi-level groupings don't require loading entire datasets into memory.</p>"},{"location":"concepts/chained-groups/#comparison-with-direct-aggregation","title":"Comparison with Direct Aggregation","text":""},{"location":"concepts/chained-groups/#when-to-use-chained-grouping","title":"When to Use Chained Grouping","text":"<p>Use chained grouping when you need:</p> <ul> <li>Multi-level hierarchies: More than one grouping dimension</li> <li>Intermediate filtering: Filtering between grouping levels  </li> <li>Progressive building: Building up complex queries step by step</li> <li>Inspection: Examining intermediate grouping states</li> <li>Composition: Integrating with other operations</li> </ul> <pre><code># Complex pipeline with chained grouping\ncat transactions.jsonl \\\n  | ja select 'amount &gt; 10' \\\n  | ja join customers.jsonl --on customer_id=id \\\n  | ja groupby tier \\\n  | ja select '_group_size &gt; 100' \\\n  | ja groupby month \\\n  | ja agg revenue=sum(amount),customers=count_distinct(customer_id)\n</code></pre>"},{"location":"concepts/chained-groups/#when-to-use-direct-aggregation","title":"When to Use Direct Aggregation","text":"<p>Use the <code>--agg</code> flag for simple, single-level aggregations:</p> <pre><code># Simple aggregation - more efficient\nja groupby category --agg 'total=sum(amount),count' sales.jsonl\n</code></pre>"},{"location":"concepts/chained-groups/#real-world-examples","title":"Real-World Examples","text":""},{"location":"concepts/chained-groups/#e-commerce-analysis","title":"E-commerce Analysis","text":"<pre><code># Multi-dimensional sales analysis\ncat orders.jsonl \\\n  | ja select 'status == \"completed\"' \\\n  | ja join products.jsonl --on product_id=id \\\n  | ja groupby category \\\n  | ja groupby price_tier \\\n  | ja groupby month \\\n  | ja agg \\\n      revenue=sum(total), \\\n      orders=count, \\\n      unique_customers=count_distinct(customer_id), \\\n      avg_order=avg(total)\n</code></pre>"},{"location":"concepts/chained-groups/#log-analysis","title":"Log Analysis","text":"<pre><code># Server log analysis by endpoint and status\ncat access.log.jsonl \\\n  | ja select 'timestamp &gt; \"2024-01-01\"' \\\n  | ja groupby endpoint \\\n  | ja select '_group_size &gt; 1000' \\\n  | ja groupby status_code \\\n  | ja agg \\\n      requests=count, \\\n      avg_response_time=avg(response_time), \\\n      error_rate=count_if(status_code&gt;=400)/count\n</code></pre>"},{"location":"concepts/chained-groups/#user-behavior-analysis","title":"User Behavior Analysis","text":"<pre><code># User engagement analysis\ncat events.jsonl \\\n  | ja groupby user_id \\\n  | ja select '_group_size &gt;= 10' \\\n  | ja groupby event_type \\\n  | ja groupby date \\\n  | ja agg \\\n      daily_events=count, \\\n      unique_users=count_distinct(user_id)\n</code></pre>"},{"location":"concepts/chained-groups/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with single-level grouping, then add levels</li> <li>Filter Early: Use <code>select</code> before grouping to reduce data size  </li> <li>Inspect Intermediate Results: Use <code>head</code> or <code>--lines</code> to check grouping structure</li> <li>Use Meaningful Names: Choose descriptive names for aggregated fields</li> <li>Leverage Metadata: Use <code>_group_size</code> for filtering and analysis</li> </ol>"},{"location":"concepts/chained-groups/#troubleshooting","title":"Troubleshooting","text":""},{"location":"concepts/chained-groups/#common-issues","title":"Common Issues","text":"<p>Empty Results After Chaining:</p> <pre><code># Check each step\nja groupby region data.jsonl | ja agg count\nja groupby region data.jsonl | ja groupby product | ja agg count\n</code></pre> <p>Unexpected Grouping Values:</p> <pre><code># Inspect the grouping metadata\nja groupby region data.jsonl | ja project region,_groups | head -5\n</code></pre> <p>Performance Issues:</p> <pre><code># Consider filtering early\nja select 'relevant_condition' data.jsonl | ja groupby region | ja groupby product\n</code></pre>"},{"location":"concepts/chained-groups/#whats-next","title":"What's Next?","text":"<ul> <li>Expression Language - Learn advanced filtering</li> <li>Performance Guide - Optimize complex pipelines</li> <li>Cookbook Examples - See real-world usage</li> </ul>"},{"location":"concepts/jsonl-algebra/","title":"The Algebra Behind ja","text":""},{"location":"concepts/jsonl-algebra/#what-makes-it-an-algebra","title":"What Makes it an Algebra?","text":"<p>An algebra is a mathematical structure with:</p> <ol> <li>A set of elements (relations/tables)</li> <li>Operations on those elements</li> <li>Properties that those operations satisfy</li> </ol> <p>In <code>ja</code>, our algebra consists of:</p> <ul> <li>Elements: Relations (collections of JSON objects)</li> <li>Operations: select, project, join, union, etc.</li> <li>Properties: Closure, associativity, commutativity (where applicable)</li> </ul>"},{"location":"concepts/jsonl-algebra/#the-relational-model","title":"The Relational Model","text":""},{"location":"concepts/jsonl-algebra/#relations-as-sets","title":"Relations as Sets","text":"<p>In <code>ja</code>, a JSONL file represents a relation - an unordered set of tuples (JSON objects):</p> <pre><code>{\"id\": 1, \"name\": \"Alice\", \"age\": 30}\n{\"id\": 2, \"name\": \"Bob\", \"age\": 25}\n{\"id\": 3, \"name\": \"Charlie\", \"age\": 35}\n</code></pre> <p>This is a relation with schema <code>(id: number, name: string, age: number)</code>.</p>"},{"location":"concepts/jsonl-algebra/#operations-as-functions","title":"Operations as Functions","text":"<p>Each operation is a function that transforms relations:</p> <pre><code>\u03c3[age &gt; 30](R) \u2192 R'\n</code></pre> <p>This reads as: \"select (\u03c3) where age &gt; 30 from relation R produces relation R'\"</p>"},{"location":"concepts/jsonl-algebra/#core-operations","title":"Core Operations","text":""},{"location":"concepts/jsonl-algebra/#1-selection-filter","title":"1. Selection (\u03c3) - Filter","text":"<p>Selection filters rows based on a predicate:</p> <pre><code>ja select 'age &gt; 30' people.jsonl\n</code></pre> <p>Algebraic notation: \u03c3age &gt; 30</p> <p>Properties:</p> <ul> <li>Commutative: \u03c3p1 = \u03c3p2</li> <li>Can be combined: \u03c3p1 = \u03c3p1 \u2227 p2</li> </ul>"},{"location":"concepts/jsonl-algebra/#2-projection-transform","title":"2. Projection (\u03c0) - Transform","text":"<p>Projection selects and computes columns:</p> <pre><code>ja project name,income=salary*12 employees.jsonl\n</code></pre> <p>Algebraic notation: \u03c0name, income=salary\u00d712</p> <p>Properties:</p> <ul> <li>Not commutative in general</li> <li>Idempotent for simple projections: \u03c0a = \u03c0a</li> </ul>"},{"location":"concepts/jsonl-algebra/#3-join-combine","title":"3. Join (\u22c8) - Combine","text":"<p>Join combines relations based on a condition:</p> <pre><code>ja join users.jsonl orders.jsonl --on id=user_id\n</code></pre> <p>Algebraic notation: Users \u22c8[id=user_id] Orders</p> <p>Properties:</p> <ul> <li>Commutative: R \u22c8 S = S \u22c8 R</li> <li>Associative: (R \u22c8 S) \u22c8 T = R \u22c8 (S \u22c8 T)</li> </ul>"},{"location":"concepts/jsonl-algebra/#4-union-combine-all","title":"4. Union (\u222a) - Combine All","text":"<p>Union combines all rows from two relations:</p> <pre><code>ja union employees.jsonl contractors.jsonl\n</code></pre> <p>Properties:</p> <ul> <li>Commutative: R \u222a S = S \u222a R</li> <li>Associative: (R \u222a S) \u222a T = R \u222a (S \u222a T)</li> <li>Identity: R \u222a \u2205 = R</li> </ul>"},{"location":"concepts/jsonl-algebra/#advanced-concepts","title":"Advanced Concepts","text":""},{"location":"concepts/jsonl-algebra/#grouping-and-aggregation","title":"Grouping and Aggregation","text":"<p>Grouping extends relational algebra with aggregation:</p> <pre><code>ja groupby department employees.jsonl | ja agg avg_salary=avg(salary)\n</code></pre> <p>Algebraic notation: \u03b3department, avg_salary=AVG(salary)</p>"},{"location":"concepts/jsonl-algebra/#chained-grouping","title":"Chained Grouping","text":"<p>Our innovation: grouping that preserves composability:</p> <pre><code>cat sales.jsonl \\\n  | ja groupby region \\      # First level grouping\n  | ja groupby product \\     # Second level grouping  \n  | ja agg total=sum(amount) # Final aggregation\n</code></pre> <p>Each groupby adds metadata rather than aggregating, maintaining the relation structure.</p> <p>The key insight is using JSON-native metadata to preserve grouping hierarchy:</p> <pre><code>{\n  \"order_id\": 101,\n  \"user_id\": 1,\n  \"amount\": 250,\n  \"_groups\": [\n    {\"field\": \"user_id\", \"value\": 1},\n    {\"field\": \"amount\", \"value\": 250}\n  ],\n  \"_group_size\": 1,\n  \"_group_index\": 0\n}\n</code></pre>"},{"location":"concepts/jsonl-algebra/#theoretical-guarantees","title":"Theoretical Guarantees","text":""},{"location":"concepts/jsonl-algebra/#1-closure-property","title":"1. Closure Property","text":"<p>Every operation produces a valid relation, ensuring composability:</p> <pre><code>Relation \u2192 Operation \u2192 Relation\n</code></pre>"},{"location":"concepts/jsonl-algebra/#2-optimization-opportunities","title":"2. Optimization Opportunities","text":"<p>The algebraic properties enable optimizations:</p> <pre><code># These are equivalent (push selection down)\nja join huge.jsonl small.jsonl --on id=id | ja select 'active == true'\nja select 'active == true' huge.jsonl | ja join - small.jsonl --on id=id\n</code></pre>"},{"location":"concepts/jsonl-algebra/#3-declarative-nature","title":"3. Declarative Nature","text":"<p>You specify what you want, not how to compute it:</p> <pre><code># Declarative\nja groupby user_id orders.jsonl | ja agg total=sum(amount)\n\n# vs Imperative (pseudocode)\nfor order in orders:\n    totals[order.user_id] += order.amount\n</code></pre>"},{"location":"concepts/jsonl-algebra/#why-this-matters","title":"Why This Matters","text":"<ol> <li>Predictability: Mathematical foundations mean predictable behavior</li> <li>Composability: Operations can be combined in any order (where valid)</li> <li>Optimization: Algebraic laws enable automatic optimization</li> <li>Reasoning: You can reason about transformations algebraically</li> </ol>"},{"location":"concepts/jsonl-algebra/#design-insights","title":"Design Insights","text":""},{"location":"concepts/jsonl-algebra/#json-native-metadata","title":"JSON-Native Metadata","text":"<p>Rather than encoding grouping information in compound strings like \"1.250\", we use structured JSON:</p> <pre><code>\"_groups\": [\n  {\"field\": \"user_id\", \"value\": 1},\n  {\"field\": \"amount\", \"value\": 250}\n]\n</code></pre> <p>This approach:</p> <ul> <li>Preserves data types (no string parsing needed)</li> <li>Is self-documenting</li> <li>Enables complex querying of grouping structure</li> <li>Maintains the principle that data stays sensible throughout pipelines</li> </ul>"},{"location":"concepts/jsonl-algebra/#streaming-by-design","title":"Streaming by Design","text":"<p>Each operation processes data incrementally, enabling:</p> <ul> <li>Processing of arbitrarily large datasets</li> <li>Real-time data processing</li> <li>Low memory footprint</li> <li>Natural integration with Unix pipes</li> </ul>"},{"location":"concepts/jsonl-algebra/#further-reading","title":"Further Reading","text":"<ul> <li>Composability in Practice</li> <li>Chained Grouping Deep Dive</li> <li>Expression Language</li> </ul>"},{"location":"cookbook/log-analysis/","title":"Log Analysis with ja","text":"<p>This cookbook shows how to analyze server logs using <code>ja</code>. We'll work with common log formats and build progressively more complex analyses.</p>"},{"location":"cookbook/log-analysis/#sample-data","title":"Sample Data","text":"<p>Let's start with web server access logs in JSONL format:</p> <p><code>access.jsonl</code>:</p> <pre><code>{\"timestamp\": \"2024-01-15T10:30:45Z\", \"method\": \"GET\", \"path\": \"/api/users\", \"status\": 200, \"response_time\": 45, \"ip\": \"192.168.1.100\", \"user_agent\": \"Mozilla/5.0\"}\n{\"timestamp\": \"2024-01-15T10:31:12Z\", \"method\": \"POST\", \"path\": \"/api/login\", \"status\": 401, \"response_time\": 120, \"ip\": \"192.168.1.105\", \"user_agent\": \"curl/7.68.0\"}\n{\"timestamp\": \"2024-01-15T10:31:45Z\", \"method\": \"GET\", \"path\": \"/api/users/123\", \"status\": 200, \"response_time\": 67, \"ip\": \"192.168.1.100\", \"user_agent\": \"Mozilla/5.0\"}\n{\"timestamp\": \"2024-01-15T10:32:01Z\", \"method\": \"DELETE\", \"path\": \"/api/users/456\", \"status\": 403, \"response_time\": 23, \"ip\": \"192.168.1.107\", \"user_agent\": \"PostmanRuntime/7.28.4\"}\n{\"timestamp\": \"2024-01-15T10:32:15Z\", \"method\": \"GET\", \"path\": \"/health\", \"status\": 200, \"response_time\": 5, \"ip\": \"10.0.0.1\", \"user_agent\": \"health-check\"}\n</code></pre>"},{"location":"cookbook/log-analysis/#basic-analysis","title":"Basic Analysis","text":""},{"location":"cookbook/log-analysis/#1-response-status-distribution","title":"1. Response Status Distribution","text":"<pre><code>ja groupby status access.jsonl | ja agg count\n</code></pre> <p>Output:</p> <pre><code>{\"status\": 200, \"count\": 3}\n{\"status\": 401, \"count\": 1}\n{\"status\": 403, \"count\": 1}\n</code></pre>"},{"location":"cookbook/log-analysis/#2-average-response-time-by-status","title":"2. Average Response Time by Status","text":"<pre><code>ja groupby status access.jsonl | ja agg avg_response_time=avg(response_time),count\n</code></pre> <p>Output:</p> <pre><code>{\"status\": 200, \"avg_response_time\": 39.0, \"count\": 3}\n{\"status\": 401, \"avg_response_time\": 120.0, \"count\": 1}\n{\"status\": 403, \"avg_response_time\": 23.0, \"count\": 1}\n</code></pre>"},{"location":"cookbook/log-analysis/#3-error-rate","title":"3. Error Rate","text":"<pre><code>ja agg \\\n  total_requests=count, \\\n  error_requests=count_if(status&gt;=400), \\\n  error_rate=count_if(status&gt;=400)/count \\\n  access.jsonl\n</code></pre> <p>Output:</p> <pre><code>{\"total_requests\": 5, \"error_requests\": 2, \"error_rate\": 0.4}\n</code></pre>"},{"location":"cookbook/log-analysis/#time-based-analysis","title":"Time-Based Analysis","text":""},{"location":"cookbook/log-analysis/#4-extract-time-components","title":"4. Extract Time Components","text":"<pre><code>ja project \\\n  timestamp, \\\n  method, \\\n  path, \\\n  status, \\\n  response_time, \\\n  hour=timestamp[11:13], \\\n  minute=timestamp[14:16] \\\n  access.jsonl\n</code></pre>"},{"location":"cookbook/log-analysis/#5-requests-per-hour","title":"5. Requests per Hour","text":"<pre><code>ja project timestamp,hour=timestamp[11:13],method,path,status access.jsonl \\\n  | ja groupby hour \\\n  | ja agg requests=count,avg_response_time=avg(response_time)\n</code></pre>"},{"location":"cookbook/log-analysis/#6-peak-traffic-analysis","title":"6. Peak Traffic Analysis","text":"<pre><code>ja project timestamp,minute=timestamp[11:16],status,response_time access.jsonl \\\n  | ja groupby minute \\\n  | ja agg requests=count,errors=count_if(status&gt;=400) \\\n  | ja sort requests --desc \\\n  | head -10\n</code></pre>"},{"location":"cookbook/log-analysis/#endpoint-analysis","title":"Endpoint Analysis","text":""},{"location":"cookbook/log-analysis/#7-most-popular-endpoints","title":"7. Most Popular Endpoints","text":"<pre><code>ja groupby path access.jsonl \\\n  | ja agg requests=count \\\n  | ja sort requests --desc\n</code></pre> <p>Output:</p> <pre><code>{\"path\": \"/api/users\", \"requests\": 1}\n{\"path\": \"/api/users/123\", \"requests\": 1}\n{\"path\": \"/api/login\", \"requests\": 1}\n{\"path\": \"/api/users/456\", \"requests\": 1}\n{\"path\": \"/health\", \"requests\": 1}\n</code></pre>"},{"location":"cookbook/log-analysis/#8-endpoint-performance","title":"8. Endpoint Performance","text":"<pre><code>ja groupby path access.jsonl \\\n  | ja agg \\\n    requests=count, \\\n    avg_response_time=avg(response_time), \\\n    max_response_time=max(response_time), \\\n    error_rate=count_if(status&gt;=400)/count \\\n  | ja sort avg_response_time --desc\n</code></pre>"},{"location":"cookbook/log-analysis/#9-api-vs-health-checks","title":"9. API vs Health Checks","text":"<pre><code>ja project path,status,response_time,is_api=path.startswith(\"/api\") access.jsonl \\\n  | ja groupby is_api \\\n  | ja agg \\\n    requests=count, \\\n    avg_response_time=avg(response_time), \\\n    error_rate=count_if(status&gt;=400)/count\n</code></pre>"},{"location":"cookbook/log-analysis/#multi-dimensional-analysis","title":"Multi-Dimensional Analysis","text":""},{"location":"cookbook/log-analysis/#10-method-and-status-cross-tabulation","title":"10. Method and Status Cross-Tabulation","text":"<pre><code>ja groupby method access.jsonl \\\n  | ja groupby status \\\n  | ja agg count \\\n  | ja sort method,status\n</code></pre> <p>Output:</p> <pre><code>{\"method\": \"DELETE\", \"status\": 403, \"count\": 1}\n{\"method\": \"GET\", \"status\": 200, \"count\": 3}\n{\"method\": \"POST\", \"status\": 401, \"count\": 1}\n</code></pre>"},{"location":"cookbook/log-analysis/#11-hourly-error-analysis","title":"11. Hourly Error Analysis","text":"<pre><code>ja project \\\n  timestamp, \\\n  hour=timestamp[11:13], \\\n  status, \\\n  path, \\\n  response_time \\\n  access.jsonl \\\n  | ja groupby hour \\\n  | ja groupby 'status&gt;=400' \\\n  | ja agg count,paths=list(path) \\\n  | ja select 'status&gt;=400 == true'\n</code></pre>"},{"location":"cookbook/log-analysis/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"cookbook/log-analysis/#12-slow-requests-analysis","title":"12. Slow Requests Analysis","text":"<pre><code># Define slow requests as &gt; 50ms\nja select 'response_time &gt; 50' access.jsonl \\\n  | ja groupby path \\\n  | ja agg \\\n    slow_requests=count, \\\n    avg_slow_time=avg(response_time), \\\n    max_time=max(response_time)\n</code></pre>"},{"location":"cookbook/log-analysis/#13-user-agent-analysis","title":"13. User Agent Analysis","text":"<pre><code>ja project user_agent,status,path access.jsonl \\\n  | ja groupby user_agent \\\n  | ja agg \\\n    requests=count, \\\n    unique_paths=count_distinct(path), \\\n    error_rate=count_if(status&gt;=400)/count \\\n  | ja sort requests --desc\n</code></pre>"},{"location":"cookbook/log-analysis/#14-ip-address-security-analysis","title":"14. IP Address Security Analysis","text":"<pre><code># Find IPs with high error rates\nja groupby ip access.jsonl \\\n  | ja agg \\\n    requests=count, \\\n    errors=count_if(status&gt;=400), \\\n    error_rate=count_if(status&gt;=400)/count \\\n  | ja select 'error_rate &gt; 0.5 and requests &gt; 1' \\\n  | ja sort error_rate --desc\n</code></pre>"},{"location":"cookbook/log-analysis/#real-world-scenarios","title":"Real-World Scenarios","text":""},{"location":"cookbook/log-analysis/#15-performance-monitoring-dashboard","title":"15. Performance Monitoring Dashboard","text":"<pre><code># Generate performance summary\nja project \\\n  timestamp, \\\n  hour=timestamp[11:13], \\\n  status, \\\n  response_time, \\\n  is_error=status&gt;=400, \\\n  is_slow=response_time&gt;100 \\\n  access.jsonl \\\n  | ja agg \\\n    total_requests=count, \\\n    avg_response_time=avg(response_time), \\\n    p95_response_time=percentile(response_time,0.95), \\\n    error_rate=sum(is_error)/count, \\\n    slow_rate=sum(is_slow)/count\n</code></pre>"},{"location":"cookbook/log-analysis/#16-security-alert-detection","title":"16. Security Alert Detection","text":"<pre><code># Find suspicious patterns\nja select 'status == 401 or status == 403' access.jsonl \\\n  | ja groupby ip \\\n  | ja agg \\\n    failed_attempts=count, \\\n    unique_paths=count_distinct(path), \\\n    time_span=max(timestamp)-min(timestamp) \\\n  | ja select 'failed_attempts &gt;= 3' \\\n  | ja sort failed_attempts --desc\n</code></pre>"},{"location":"cookbook/log-analysis/#17-api-rate-limiting-analysis","title":"17. API Rate Limiting Analysis","text":"<pre><code># Analyze request patterns per IP\nja project \\\n  ip, \\\n  timestamp, \\\n  minute=timestamp[0:16], \\\n  path \\\n  access.jsonl \\\n  | ja groupby ip \\\n  | ja groupby minute \\\n  | ja agg requests_per_minute=count \\\n  | ja select 'requests_per_minute &gt; 10' \\\n  | ja groupby ip \\\n  | ja agg \\\n    peak_minutes=count, \\\n    max_rpm=max(requests_per_minute)\n</code></pre>"},{"location":"cookbook/log-analysis/#combining-multiple-log-sources","title":"Combining Multiple Log Sources","text":""},{"location":"cookbook/log-analysis/#18-join-with-application-logs","title":"18. Join with Application Logs","text":"<p><code>app.jsonl</code>:</p> <pre><code>{\"timestamp\": \"2024-01-15T10:30:45Z\", \"level\": \"INFO\", \"message\": \"User authenticated\", \"user_id\": 123}\n{\"timestamp\": \"2024-01-15T10:31:12Z\", \"level\": \"WARN\", \"message\": \"Invalid credentials\", \"user_id\": null}\n{\"timestamp\": \"2024-01-15T10:31:45Z\", \"level\": \"INFO\", \"message\": \"User data retrieved\", \"user_id\": 123}\n</code></pre> <pre><code># Correlate access logs with application logs\nja join app.jsonl access.jsonl --on timestamp=timestamp \\\n  | ja project timestamp,method,path,status,level,message,user_id \\\n  | ja groupby level \\\n  | ja agg count,avg_response_time=avg(response_time)\n</code></pre>"},{"location":"cookbook/log-analysis/#19-error-correlation-analysis","title":"19. Error Correlation Analysis","text":"<pre><code># Find patterns between HTTP errors and application errors\nja join app.jsonl access.jsonl --on timestamp=timestamp \\\n  | ja select 'status &gt;= 400 or level == \"ERROR\"' \\\n  | ja groupby path \\\n  | ja agg \\\n    http_errors=count_if(status&gt;=400), \\\n    app_errors=count_if(level==\"ERROR\"), \\\n    total_issues=count\n</code></pre>"},{"location":"cookbook/log-analysis/#time-series-analysis","title":"Time Series Analysis","text":""},{"location":"cookbook/log-analysis/#20-request-volume-trends","title":"20. Request Volume Trends","text":"<pre><code># Analyze request patterns over time\nja project \\\n  timestamp, \\\n  minute_bucket=timestamp[0:16], \\\n  status, \\\n  response_time \\\n  access.jsonl \\\n  | ja groupby minute_bucket \\\n  | ja agg \\\n    requests=count, \\\n    errors=count_if(status&gt;=400), \\\n    avg_response_time=avg(response_time) \\\n  | ja sort minute_bucket\n</code></pre>"},{"location":"cookbook/log-analysis/#21-anomaly-detection","title":"21. Anomaly Detection","text":"<pre><code># Find time periods with unusual patterns\nja project timestamp,minute=timestamp[0:16],status,response_time access.jsonl \\\n  | ja groupby minute \\\n  | ja agg \\\n    requests=count, \\\n    avg_response_time=avg(response_time), \\\n    error_rate=count_if(status&gt;=400)/count \\\n  | ja project \\\n    minute, \\\n    requests, \\\n    avg_response_time, \\\n    error_rate, \\\n    is_anomaly='requests &gt; 100 or avg_response_time &gt; 200 or error_rate &gt; 0.1' \\\n  | ja select 'is_anomaly == true'\n</code></pre>"},{"location":"cookbook/log-analysis/#export-for-visualization","title":"Export for Visualization","text":""},{"location":"cookbook/log-analysis/#22-prepare-data-for-grafanacharts","title":"22. Prepare Data for Grafana/Charts","text":"<pre><code># Export time series data\nja project \\\n  timestamp, \\\n  hour=timestamp[11:13], \\\n  status, \\\n  response_time \\\n  access.jsonl \\\n  | ja groupby hour \\\n  | ja agg \\\n    requests=count, \\\n    avg_response_time=avg(response_time), \\\n    error_count=count_if(status&gt;=400) \\\n  | ja export csv &gt; hourly_metrics.csv\n</code></pre>"},{"location":"cookbook/log-analysis/#23-create-status-code-distribution","title":"23. Create Status Code Distribution","text":"<pre><code># Format for pie chart\nja groupby status access.jsonl \\\n  | ja agg count \\\n  | ja project label=status,value=count \\\n  | ja export json\n</code></pre>"},{"location":"cookbook/log-analysis/#tips-for-production-use","title":"Tips for Production Use","text":""},{"location":"cookbook/log-analysis/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Filter Early: Apply time range filters first</li> <li>Sample Large Datasets: Use <code>head</code> for exploratory analysis</li> <li>Index Common Fields: Consider pre-processing for frequently queried fields</li> </ol> <pre><code># Efficient large log analysis\ncat large_access.log.jsonl \\\n  | ja select 'timestamp &gt; \"2024-01-15T00:00:00Z\"' \\\n  | ja select 'status &gt;= 400' \\\n  | ja groupby path \\\n  | ja agg error_count=count\n</code></pre>"},{"location":"cookbook/log-analysis/#automation-scripts","title":"Automation Scripts","text":"<p>Create reusable analysis scripts:</p> <pre><code>#!/bin/bash\n# error_summary.sh\nja select 'status &gt;= 400' $1 \\\n  | ja groupby status \\\n  | ja groupby path \\\n  | ja agg count \\\n  | ja sort count --desc\n</code></pre>"},{"location":"cookbook/log-analysis/#integration-with-monitoring","title":"Integration with Monitoring","text":"<pre><code># Real-time monitoring pipeline\ntail -f /var/log/access.log \\\n  | ja select 'status &gt;= 500' \\\n  | ja project timestamp,path,status,ip \\\n  | while read line; do\n      echo \"CRITICAL ERROR: $line\" | send_alert\n    done\n</code></pre>"},{"location":"cookbook/log-analysis/#next-steps","title":"Next Steps","text":"<ul> <li>Performance Optimization - Handle large log files efficiently</li> <li>Format Conversion - Work with different log formats</li> <li>Real-time Processing - Build live monitoring systems</li> </ul>"},{"location":"getting-started/concepts/","title":"Core Concepts","text":"<p>Understanding the fundamental concepts behind jsonl-algebra will help you use it more effectively and build powerful data pipelines. This page explains the \"why\" and \"how\" behind the tool.</p>"},{"location":"getting-started/concepts/#what-is-jsonl","title":"What is JSONL?","text":"<p>JSONL (JSON Lines) is a simple format where each line is a valid JSON object:</p> <pre><code>{\"id\": 1, \"name\": \"Alice\"}\n{\"id\": 2, \"name\": \"Bob\"}\n{\"id\": 3, \"name\": \"Charlie\"}\n</code></pre>"},{"location":"getting-started/concepts/#why-jsonl","title":"Why JSONL?","text":"Feature JSONL JSON Array Streaming Can process line-by-line Must load entire file Append-friendly Just add new lines Must modify structure Error recovery One bad line won't break others One error = broken file Memory usage Constant (per line) Grows with file size Processing Start immediately Wait for complete parse <p>Best Use Cases for JSONL</p> <ul> <li>Log files (each log entry is a JSON object)</li> <li>Event streams (continuous data)</li> <li>Database exports (each row as JSON)</li> <li>API responses (paginated results)</li> <li>Large datasets (millions of records)</li> </ul>"},{"location":"getting-started/concepts/#relational-algebra-basics","title":"Relational Algebra Basics","text":"<p>jsonl-algebra is built on relational algebra - the mathematical foundation of databases. Understanding these concepts helps you compose operations effectively.</p>"},{"location":"getting-started/concepts/#relations-as-tables","title":"Relations as Tables","text":"<p>Think of a JSONL file as a relation (table):</p> <pre><code>users.jsonl \u2192 Users Relation\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user_id \u2502 name   \u2502 age \u2502 city \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502 Alice  \u2502 30  \u2502 NYC  \u2502\n\u2502 2       \u2502 Bob    \u2502 25  \u2502 SF   \u2502\n\u2502 3       \u2502 Charlie\u2502 35  \u2502 NYC  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Each JSON object is a row, and each field is a column.</p>"},{"location":"getting-started/concepts/#closure-property","title":"Closure Property","text":"<p>The most important concept: Every operation takes relations and produces relations.</p> <pre><code>graph LR\n    A[Relation In] --&gt; B[Operation]\n    B --&gt; C[Relation Out]\n    C --&gt; D[Another Operation]\n    D --&gt; E[Relation Out]</code></pre> <p>This means you can chain operations infinitely:</p> <pre><code>cat data.jsonl \\\n  | ja select ... \\    # Relation \u2192 Relation\n  | ja project ... \\   # Relation \u2192 Relation\n  | ja groupby ... \\   # Relation \u2192 Relation\n  | ja sort ...        # Relation \u2192 Relation\n</code></pre>"},{"location":"getting-started/concepts/#core-operations","title":"Core Operations","text":""},{"location":"getting-started/concepts/#selection-filter-rows","title":"Selection (\u03c3) - Filter Rows","text":"<p>Mathematical notation: \u03c3<sub>condition</sub>(R)</p> <p>Purpose: Keep rows that meet a condition</p> <pre><code>ja select 'age &gt; 30' users.jsonl\n</code></pre> <pre><code>Input:                    Output:\n\u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id \u2502 name   \u2502 age \u2502    \u2502 id \u2502 name   \u2502 age \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2524    \u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1  \u2502 Alice  \u2502 30  \u2502    \u2502 3  \u2502Charlie \u2502 35  \u2502\n\u2502 2  \u2502 Bob    \u2502 25  \u2502    \u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 3  \u2502Charlie \u2502 35  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/concepts/#projection-choose-columns","title":"Projection (\u03c0) - Choose Columns","text":"<p>Mathematical notation: \u03c0<sub>fields</sub>(R)</p> <p>Purpose: Keep only specified fields</p> <pre><code>ja project name,age users.jsonl\n</code></pre> <pre><code>Input:                      Output:\n\u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id \u2502 name   \u2502 age \u2502...\u2502  \u2502 name   \u2502 age \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1  \u2502 Alice  \u2502 30  \u2502...\u2502  \u2502 Alice  \u2502 30  \u2502\n\u2502 2  \u2502 Bob    \u2502 25  \u2502...\u2502  \u2502 Bob    \u2502 25  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/concepts/#join-combine-relations","title":"Join (\u22c8) - Combine Relations","text":"<p>Mathematical notation: R \u22c8<sub>condition</sub> S</p> <p>Purpose: Combine rows from two relations where a condition matches</p> <pre><code>ja join users.jsonl orders.jsonl --on user_id=user_id\n</code></pre> <pre><code>Users:                  Orders:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user_id \u2502 name \u2502     \u2502 order_id \u2502 user_id \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502Alice \u2502     \u2502 101      \u2502 1       \u2502\n\u2502 2       \u2502 Bob  \u2502     \u2502 102      \u2502 2       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nResult:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user_id \u2502 name \u2502 order_id \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1       \u2502Alice \u2502 101      \u2502\n\u2502 2       \u2502 Bob  \u2502 102      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/concepts/#union-combine-all-rows","title":"Union (\u222a) - Combine All Rows","text":"<p>Mathematical notation: R \u222a S</p> <p>Purpose: Merge two relations with the same schema</p> <pre><code>ja union file1.jsonl file2.jsonl\n</code></pre>"},{"location":"getting-started/concepts/#distinct-remove-duplicates","title":"Distinct (\u03b4) - Remove Duplicates","text":"<p>Mathematical notation: \u03b4(R)</p> <p>Purpose: Keep only unique rows</p> <pre><code>ja distinct users.jsonl\n</code></pre>"},{"location":"getting-started/concepts/#dot-notation-for-nested-data","title":"Dot Notation for Nested Data","text":"<p>Real-world JSON is often nested. jsonl-algebra uses dot notation to access nested fields naturally.</p>"},{"location":"getting-started/concepts/#simple-nesting","title":"Simple Nesting","text":"<pre><code>{\n  \"user\": {\n    \"name\": \"Alice\",\n    \"age\": 30\n  }\n}\n</code></pre> <p>Access with dots:</p> <pre><code>ja project user.name,user.age data.jsonl\n</code></pre>"},{"location":"getting-started/concepts/#deep-nesting","title":"Deep Nesting","text":"<pre><code>{\n  \"user\": {\n    \"profile\": {\n      \"contact\": {\n        \"email\": \"alice@example.com\"\n      }\n    }\n  }\n}\n</code></pre> <p>Access deeply nested fields:</p> <pre><code>ja project user.profile.contact.email data.jsonl\n</code></pre>"},{"location":"getting-started/concepts/#arrays-in-nested-data","title":"Arrays in Nested Data","text":"<pre><code>{\n  \"user\": {\n    \"name\": \"Alice\",\n    \"tags\": [\"admin\", \"premium\"]\n  }\n}\n</code></pre> <p>Work with nested arrays:</p> <pre><code># Access the tags field (returns the whole array)\nja project user.tags data.jsonl\n</code></pre> <p>Learn More</p> <p>See the Dot Notation Guide for advanced patterns.</p>"},{"location":"getting-started/concepts/#streaming-architecture","title":"Streaming Architecture","text":"<p>jsonl-algebra is designed for streaming - processing data without loading it all into memory.</p>"},{"location":"getting-started/concepts/#how-streaming-works","title":"How Streaming Works","text":"<pre><code>graph LR\n    A[File] --&gt; B[Read Line]\n    B --&gt; C[Parse JSON]\n    C --&gt; D[Apply Operation]\n    D --&gt; E[Output Line]\n    E --&gt; F[Next Line]\n    F --&gt; B</code></pre>"},{"location":"getting-started/concepts/#benefits","title":"Benefits","text":"<ol> <li>Constant Memory Usage - Process gigabyte files with megabytes of RAM</li> <li>Immediate Results - See output as soon as first line is processed</li> <li>Composable - Pipe operations together naturally</li> <li>Interruptible - Can stop processing early (e.g., with <code>head</code>)</li> </ol>"},{"location":"getting-started/concepts/#example-processing-large-files","title":"Example: Processing Large Files","text":"<pre><code># This works even for 100GB files\ncat huge_logs.jsonl \\\n  | ja select 'level == \"ERROR\"' \\\n  | ja project timestamp,message \\\n  | head -10\n</code></pre> <p>The pipeline: - Reads one line at a time - Filters immediately - Projects fields - Stops after 10 results</p> <p>Memory used: ~constant (few MB), regardless of file size!</p>"},{"location":"getting-started/concepts/#expression-language","title":"Expression Language","text":"<p>jsonl-algebra uses a simple, safe expression language for filtering and calculations.</p>"},{"location":"getting-started/concepts/#supported-operators","title":"Supported Operators","text":"Operator Meaning Example <code>==</code> Equal <code>status == \"active\"</code> <code>!=</code> Not equal <code>role != \"admin\"</code> <code>&gt;</code> Greater than <code>age &gt; 30</code> <code>&lt;</code> Less than <code>score &lt; 100</code> <code>&gt;=</code> Greater or equal <code>price &gt;= 50</code> <code>&lt;=</code> Less or equal <code>count &lt;= 10</code> <code>and</code> Logical AND <code>age &gt; 18 and status == \"active\"</code> <code>or</code> Logical OR <code>role == \"admin\" or role == \"owner\"</code>"},{"location":"getting-started/concepts/#value-types","title":"Value Types","text":"<pre><code># Strings (use quotes)\nja select 'name == \"Alice\"'\n\n# Numbers (no quotes)\nja select 'age &gt; 30'\n\n# Booleans\nja select 'is_active == true'\n\n# Null checks\nja select 'email != null'\n</code></pre>"},{"location":"getting-started/concepts/#nested-field-access","title":"Nested Field Access","text":"<pre><code>ja select 'user.profile.age &gt; 25 and user.status == \"active\"'\n</code></pre> <p>Safety First</p> <p>The expression language is safe - it can't execute arbitrary code or access the filesystem.</p>"},{"location":"getting-started/concepts/#pipeline-composition","title":"Pipeline Composition","text":"<p>The Unix philosophy: build complex solutions by composing simple tools.</p>"},{"location":"getting-started/concepts/#pipeline-patterns","title":"Pipeline Patterns","text":""},{"location":"getting-started/concepts/#pattern-1-filter-transform-output","title":"Pattern 1: Filter \u2192 Transform \u2192 Output","text":"<pre><code>cat data.jsonl \\\n  | ja select 'active == true' \\      # Filter\n  | ja project id,name \\               # Transform\n  | ja sort name                       # Order\n</code></pre>"},{"location":"getting-started/concepts/#pattern-2-join-aggregate-report","title":"Pattern 2: Join \u2192 Aggregate \u2192 Report","text":"<pre><code>ja join users.jsonl orders.jsonl --on id=user_id \\\n  | ja groupby user.name --agg total=sum:amount \\\n  | ja sort total --desc \\\n  | head -10\n</code></pre>"},{"location":"getting-started/concepts/#pattern-3-multi-stage-filtering","title":"Pattern 3: Multi-stage Filtering","text":"<pre><code>cat logs.jsonl \\\n  | ja select 'level == \"ERROR\"' \\\n  | ja select 'timestamp &gt; \"2025-01-01\"' \\\n  | ja select 'component == \"auth\"'\n</code></pre>"},{"location":"getting-started/concepts/#when-to-use-pipelines-vs-single-operations","title":"When to Use Pipelines vs Single Operations","text":"<p>Use pipelines when: - Building complex transformations step-by-step - Each step is conceptually distinct - Debugging intermediate results</p> <p>Use combined conditions when: - Multiple filters on same data - Performance is critical (fewer passes) - Simpler to read</p> <pre><code># Pipeline (3 passes over data)\nja select 'a &gt; 10' | ja select 'b &lt; 20' | ja select 'c == 30'\n\n# Combined (1 pass)\nja select 'a &gt; 10 and b &lt; 20 and c == 30'\n</code></pre>"},{"location":"getting-started/concepts/#data-flow-model","title":"Data Flow Model","text":"<p>Understanding how data flows helps you build efficient pipelines.</p>"},{"location":"getting-started/concepts/#lazy-evaluation","title":"Lazy Evaluation","text":"<p>Operations are lazy - they only process data as needed:</p> <pre><code>cat huge.jsonl | ja select 'x &gt; 100' | head -1\n</code></pre> <p>This pipeline: 1. Opens file (doesn't read it all) 2. Processes lines one-by-one 3. Stops after finding first match 4. Never reads the entire file</p>"},{"location":"getting-started/concepts/#buffering","title":"Buffering","text":"<p>Most operations are streaming, but some require buffering:</p> Operation Streaming Why <code>select</code> Yes Can decide per-line <code>project</code> Yes Can transform per-line <code>sort</code> No Must see all data to order <code>distinct</code> No Must track seen items <code>groupby</code> No Must collect groups <code>join</code> Partial Right file buffered, left streamed <p>Memory Considerations</p> <p>Non-streaming operations will load data into memory. For huge datasets, filter first!</p>"},{"location":"getting-started/concepts/#type-system","title":"Type System","text":"<p>JSONL/JSON supports these types, all handled by jsonl-algebra:</p> <pre><code>{\n  \"string\": \"text value\",\n  \"number\": 42,\n  \"float\": 3.14,\n  \"boolean\": true,\n  \"null\": null,\n  \"array\": [1, 2, 3],\n  \"object\": {\"nested\": \"value\"}\n}\n</code></pre>"},{"location":"getting-started/concepts/#type-handling-in-operations","title":"Type Handling in Operations","text":"<p>Comparisons are type-aware: <pre><code># Number comparison\nja select 'age &gt; 30'      # Numeric\n\n# String comparison\nja select 'name == \"Alice\"'  # Lexicographic\n</code></pre></p> <p>Aggregations respect types: <pre><code># Sum works on numbers\nja groupby category --agg total=sum:amount\n\n# Count works on anything\nja groupby status --agg count\n</code></pre></p>"},{"location":"getting-started/concepts/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>JSONL = Stream-friendly JSON - One object per line</li> <li>Relations = Tables - JSONL files are relations</li> <li>Operations preserve relations - Enables composition</li> <li>Dot notation accesses nesting - <code>user.profile.email</code></li> <li>Streaming = Efficient - Constant memory, immediate results</li> <li>Pipes compose tools - Build complex solutions simply</li> </ol>"},{"location":"getting-started/concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the concepts, dive deeper:</p> <ul> <li>Relational Algebra Details - Mathematical foundations</li> <li>Dot Notation Guide - Master nested data</li> <li>Streaming &amp; Piping - Optimize for large data</li> <li>CLI Commands - Learn all available operations</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Welcome! This guide will help you get jsonl-algebra installed and ready to use on your system.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing jsonl-algebra, ensure you have:</p> <ul> <li>Python 3.8 or higher - Check with <code>python --version</code> or <code>python3 --version</code></li> <li>pip - Python's package installer (usually comes with Python)</li> <li>Terminal access - Command-line interface</li> </ul> <p>Python Version Check</p> <pre><code>python3 --version\n# Should show: Python 3.8.x or higher\n</code></pre>"},{"location":"getting-started/installation/#quick-install-recommended","title":"Quick Install (Recommended)","text":"<p>The easiest way to install jsonl-algebra is from PyPI using pip:</p> Using pipUsing pip3With User Install <pre><code>pip install jsonl-algebra\n</code></pre> <pre><code>pip3 install jsonl-algebra\n</code></pre> <pre><code>pip install --user jsonl-algebra\n</code></pre> <p>This single command installs:</p> <ul> <li>The <code>ja</code> CLI tool</li> <li>The <code>ja-shell</code> interactive navigator</li> <li>The Python library for programmatic use</li> <li>All required dependencies</li> </ul>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify everything works:</p> <pre><code># Check that ja is available\nja --version\n\n# Should output something like: ja version 1.01\n\n# Test basic functionality\necho '{\"name\": \"Alice\", \"age\": 30}' | ja project name\n# Output: {\"name\": \"Alice\"}\n</code></pre> <p>Installation Complete!</p> <p>If you see the version number and the test command works, you're all set! Head to the Quick Start guide.</p>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting-started/installation/#method-1-install-from-pypi-stable-release","title":"Method 1: Install from PyPI (Stable Release)","text":"<p>This is the recommended method for most users. It installs the latest stable version:</p> <pre><code>pip install jsonl-algebra\n</code></pre> <p>What gets installed:</p> <ul> <li>Core library (<code>ja</code> package)</li> <li>CLI tool (<code>ja</code> command)</li> <li>Interactive shell (<code>ja-shell</code> command)</li> <li>Dataset generator (<code>ja-generate-dataset</code> command)</li> <li>All dependencies (jmespath, jsonschema, prompt-toolkit, rich)</li> </ul>"},{"location":"getting-started/installation/#method-2-install-from-source-latest-development-version","title":"Method 2: Install from Source (Latest Development Version)","text":"<p>For developers or users who want the latest features:</p> Clone and InstallInstall with Development Tools <pre><code># Clone the repository\ngit clone https://github.com/queelius/jsonl-algebra.git\ncd jsonl-algebra\n\n# Install in editable mode\npip install -e .\n</code></pre> <pre><code># Clone the repository\ngit clone https://github.com/queelius/jsonl-algebra.git\ncd jsonl-algebra\n\n# Install with dev dependencies\npip install -e \".[dev]\"\n</code></pre> <p>Editable mode (<code>-e</code>) means changes to the source code take effect immediately without reinstalling.</p>"},{"location":"getting-started/installation/#method-3-install-in-a-virtual-environment-recommended-for-development","title":"Method 3: Install in a Virtual Environment (Recommended for Development)","text":"<p>Using a virtual environment keeps your project dependencies isolated:</p> Using venvUsing conda <pre><code># Create virtual environment\npython3 -m venv ja-env\n\n# Activate it\nsource ja-env/bin/activate  # On Linux/Mac\n# or\nja-env\\Scripts\\activate     # On Windows\n\n# Install jsonl-algebra\npip install jsonl-algebra\n</code></pre> <pre><code># Create conda environment\nconda create -n ja-env python=3.10\n\n# Activate it\nconda activate ja-env\n\n# Install jsonl-algebra\npip install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>jsonl-algebra comes with these dependencies (automatically installed):</p> Package Purpose Required jmespath Advanced query expressions Yes jsonschema Schema validation Yes prompt-toolkit Rich terminal input (for ja-shell) Yes rich Beautiful terminal output (for ja-shell) Yes"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For development or special features:</p> <pre><code># Development tools (testing, linting, docs)\npip install jsonl-algebra[dev]\n\n# Dataset generation\npip install jsonl-algebra[dataset]\n</code></pre>"},{"location":"getting-started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"getting-started/installation/#linux","title":"Linux","text":"<p>Most distributions work out of the box:</p> <pre><code># Ubuntu/Debian\nsudo apt install python3 python3-pip\npip3 install jsonl-algebra\n\n# Fedora/RHEL\nsudo dnf install python3 python3-pip\npip3 install jsonl-algebra\n\n# Arch Linux\nsudo pacman -S python python-pip\npip install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#macos","title":"macOS","text":"<p>Using Homebrew:</p> <pre><code># Install Python if needed\nbrew install python3\n\n# Install jsonl-algebra\npip3 install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#windows","title":"Windows","text":"Using Python InstallerUsing WSL2 (Recommended) <ol> <li>Download Python from python.org</li> <li>Run installer (make sure \"Add Python to PATH\" is checked)</li> <li>Open Command Prompt or PowerShell</li> <li>Run: <code>pip install jsonl-algebra</code></li> </ol> <pre><code># In WSL2 Ubuntu terminal\nsudo apt update\nsudo apt install python3 python3-pip\npip3 install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#upgrading","title":"Upgrading","text":"<p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade jsonl-algebra\n</code></pre> <p>To upgrade to a specific version:</p> <pre><code>pip install jsonl-algebra==1.01\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<p>If you need to remove jsonl-algebra:</p> <pre><code>pip uninstall jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#command-not-found","title":"Command Not Found","text":"<p>If <code>ja</code> command is not found after installation:</p> Check PATHAdd to PATHUse Full Path <pre><code># On Linux/Mac\necho $PATH\n\n# The directory containing 'ja' should be in PATH\n# Usually: ~/.local/bin or /usr/local/bin\n</code></pre> <pre><code># Add to ~/.bashrc or ~/.zshrc\nexport PATH=\"$HOME/.local/bin:$PATH\"\n\n# Then reload\nsource ~/.bashrc\n</code></pre> <pre><code># Find where ja was installed\npip show -f jsonl-algebra | grep bin/ja\n\n# Use the full path\n/path/to/ja --version\n</code></pre>"},{"location":"getting-started/installation/#permission-denied","title":"Permission Denied","text":"<p>If you get permission errors:</p> <pre><code># Use --user flag\npip install --user jsonl-algebra\n\n# Or use a virtual environment (recommended)\npython3 -m venv myenv\nsource myenv/bin/activate\npip install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#ssl-certificate-errors","title":"SSL Certificate Errors","text":"<p>If pip has SSL issues:</p> <pre><code>pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#python-version-issues","title":"Python Version Issues","text":"<p>If Python 3.8+ is not your default:</p> <pre><code># Use python3 explicitly\npython3 -m pip install jsonl-algebra\n\n# Or specify the version\npython3.10 -m pip install jsonl-algebra\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>Run these commands to verify everything is working:</p> <pre><code># 1. Check version\nja --version\n\n# 2. List available commands\nja --help\n\n# 3. Test basic operation\necho '{\"x\": 1}' | ja select 'x &gt; 0'\n\n# 4. Test ja-shell\nja-shell --version\n\n# 5. Test Python import\npython3 -c \"from ja.core import select; print('Import successful')\"\n</code></pre> <p>Ready to Go!</p> <p>If all commands work, you're ready to start using jsonl-algebra! Continue to the Quick Start Guide for a hands-on tutorial.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Tutorial - Learn the basics in 5 minutes</li> <li>Core Concepts - Understand the fundamentals</li> <li>CLI Reference - Explore all available commands</li> <li>Examples - See real-world usage patterns</li> </ul>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the Troubleshooting Guide</li> <li>Search existing issues</li> <li>Open a new issue with:</li> <li>Your OS and Python version</li> <li>Installation method used</li> <li>Complete error message</li> <li>Steps to reproduce</li> </ol>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with jsonl-algebra in just 5 minutes! This hands-on tutorial will teach you the essentials through practical examples.</p>"},{"location":"getting-started/quickstart/#what-youll-learn","title":"What You'll Learn","text":"<p>By the end of this guide, you'll be able to:</p> <ul> <li>Filter JSON data with <code>select</code></li> <li>Choose specific fields with <code>project</code></li> <li>Combine datasets with <code>join</code></li> <li>Calculate aggregates with <code>groupby</code></li> <li>Build powerful data pipelines</li> </ul> <p>Time required: 5-10 minutes</p> <p>Follow Along</p> <p>Copy and paste the commands into your terminal to see them in action!</p>"},{"location":"getting-started/quickstart/#setup-create-sample-data","title":"Setup: Create Sample Data","text":"<p>First, let's create some sample data files to work with:</p> <pre><code># Create a users file\ncat &gt; users.jsonl &lt;&lt; 'EOF'\n{\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\", \"role\": \"engineer\"}\n{\"user_id\": 2, \"name\": \"Bob\", \"age\": 25, \"city\": \"SF\", \"role\": \"designer\"}\n{\"user_id\": 3, \"name\": \"Charlie\", \"age\": 35, \"city\": \"NYC\", \"role\": \"manager\"}\n{\"user_id\": 4, \"name\": \"Diana\", \"age\": 28, \"city\": \"LA\", \"role\": \"engineer\"}\n{\"user_id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"SF\", \"role\": \"engineer\"}\nEOF\n\n# Create an orders file\ncat &gt; orders.jsonl &lt;&lt; 'EOF'\n{\"order_id\": 101, \"user_id\": 1, \"amount\": 250, \"status\": \"shipped\"}\n{\"order_id\": 102, \"user_id\": 1, \"amount\": 175, \"status\": \"shipped\"}\n{\"order_id\": 103, \"user_id\": 2, \"amount\": 420, \"status\": \"pending\"}\n{\"order_id\": 104, \"user_id\": 3, \"amount\": 890, \"status\": \"shipped\"}\n{\"order_id\": 105, \"user_id\": 4, \"amount\": 325, \"status\": \"cancelled\"}\n{\"order_id\": 106, \"user_id\": 5, \"amount\": 560, \"status\": \"shipped\"}\nEOF\n</code></pre> <p>Great! Now you have two JSONL files to practice with.</p>"},{"location":"getting-started/quickstart/#lesson-1-filtering-data-with-select","title":"Lesson 1: Filtering Data with <code>select</code>","text":"<p>The <code>select</code> operation filters rows based on a condition.</p>"},{"location":"getting-started/quickstart/#example-1-find-engineers","title":"Example 1: Find Engineers","text":"<pre><code>ja select 'role == \"engineer\"' users.jsonl\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\", \"role\": \"engineer\"}\n{\"user_id\": 4, \"name\": \"Diana\", \"age\": 28, \"city\": \"LA\", \"role\": \"engineer\"}\n{\"user_id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"SF\", \"role\": \"engineer\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-2-find-users-over-30","title":"Example 2: Find Users Over 30","text":"<pre><code>ja select 'age &gt; 30' users.jsonl\n</code></pre> <p>Output: <pre><code>{\"user_id\": 3, \"name\": \"Charlie\", \"age\": 35, \"city\": \"NYC\", \"role\": \"manager\"}\n{\"user_id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"SF\", \"role\": \"engineer\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-3-combine-conditions","title":"Example 3: Combine Conditions","text":"<pre><code>ja select 'role == \"engineer\" and city == \"NYC\"' users.jsonl\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\", \"role\": \"engineer\"}\n</code></pre></p> <p>Expression Syntax</p> <p>Use <code>==</code> for equality, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> for comparisons, and <code>and</code>/<code>or</code> for logic.</p>"},{"location":"getting-started/quickstart/#lesson-2-choosing-fields-with-project","title":"Lesson 2: Choosing Fields with <code>project</code>","text":"<p>The <code>project</code> operation selects specific fields from each record.</p>"},{"location":"getting-started/quickstart/#example-1-get-names-and-ages","title":"Example 1: Get Names and Ages","text":"<pre><code>ja project name,age users.jsonl\n</code></pre> <p>Output: <pre><code>{\"name\": \"Alice\", \"age\": 30}\n{\"name\": \"Bob\", \"age\": 25}\n{\"name\": \"Charlie\", \"age\": 35}\n{\"name\": \"Diana\", \"age\": 28}\n{\"name\": \"Eve\", \"age\": 32}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-2-single-field","title":"Example 2: Single Field","text":"<pre><code>ja project name users.jsonl\n</code></pre> <p>Output: <pre><code>{\"name\": \"Alice\"}\n{\"name\": \"Bob\"}\n{\"name\": \"Charlie\"}\n{\"name\": \"Diana\"}\n{\"name\": \"Eve\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#lesson-3-building-pipelines","title":"Lesson 3: Building Pipelines","text":"<p>The real power comes from chaining operations together with pipes (<code>|</code>).</p>"},{"location":"getting-started/quickstart/#example-engineers-names-in-nyc","title":"Example: Engineers' Names in NYC","text":"<pre><code>ja select 'city == \"NYC\"' users.jsonl | ja project name,role\n</code></pre> <p>Output: <pre><code>{\"name\": \"Alice\", \"role\": \"engineer\"}\n{\"name\": \"Charlie\", \"role\": \"manager\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-filter-and-count","title":"Example: Filter and Count","text":"<pre><code>ja select 'status == \"shipped\"' orders.jsonl | wc -l\n</code></pre> <p>Output: <code>4</code> (four shipped orders)</p>"},{"location":"getting-started/quickstart/#lesson-4-joining-datasets","title":"Lesson 4: Joining Datasets","text":"<p>Combine data from multiple files with <code>join</code>.</p>"},{"location":"getting-started/quickstart/#example-users-with-their-orders","title":"Example: Users with Their Orders","text":"<pre><code>ja join users.jsonl orders.jsonl --on user_id=user_id\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\", \"role\": \"engineer\", \"order_id\": 101, \"amount\": 250, \"status\": \"shipped\"}\n{\"user_id\": 1, \"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\", \"role\": \"engineer\", \"order_id\": 102, \"amount\": 175, \"status\": \"shipped\"}\n{\"user_id\": 2, \"name\": \"Bob\", \"age\": 25, \"city\": \"SF\", \"role\": \"designer\", \"order_id\": 103, \"amount\": 420, \"status\": \"pending\"}\n...\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-join-and-filter","title":"Example: Join and Filter","text":"<p>Get only shipped orders with user info:</p> <pre><code>ja join users.jsonl orders.jsonl --on user_id=user_id \\\n  | ja select 'status == \"shipped\"' \\\n  | ja project name,amount,city\n</code></pre> <p>Output: <pre><code>{\"name\": \"Alice\", \"amount\": 250, \"city\": \"NYC\"}\n{\"name\": \"Alice\", \"amount\": 175, \"city\": \"NYC\"}\n{\"name\": \"Charlie\", \"amount\": 890, \"city\": \"NYC\"}\n{\"name\": \"Eve\", \"amount\": 560, \"city\": \"SF\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#lesson-5-grouping-and-aggregating","title":"Lesson 5: Grouping and Aggregating","text":"<p>Calculate statistics by grouping data.</p>"},{"location":"getting-started/quickstart/#example-1-count-by-city","title":"Example 1: Count by City","text":"<pre><code>ja groupby city --agg count users.jsonl\n</code></pre> <p>Output: <pre><code>{\"city\": \"NYC\", \"count\": 2}\n{\"city\": \"SF\", \"count\": 2}\n{\"city\": \"LA\", \"count\": 1}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-2-sum-order-amounts-by-user","title":"Example 2: Sum Order Amounts by User","text":"<pre><code>ja groupby user_id --agg total=sum:amount orders.jsonl\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1, \"total\": 425}\n{\"user_id\": 2, \"total\": 420}\n{\"user_id\": 3, \"total\": 890}\n{\"user_id\": 4, \"total\": 325}\n{\"user_id\": 5, \"total\": 560}\n</code></pre></p>"},{"location":"getting-started/quickstart/#example-3-multiple-aggregates","title":"Example 3: Multiple Aggregates","text":"<pre><code>ja groupby city --agg count,avg_age=avg:age users.jsonl\n</code></pre> <p>Output: <pre><code>{\"city\": \"NYC\", \"count\": 2, \"avg_age\": 32.5}\n{\"city\": \"SF\", \"count\": 2, \"avg_age\": 28.5}\n{\"city\": \"LA\", \"count\": 1, \"avg_age\": 28.0}\n</code></pre></p>"},{"location":"getting-started/quickstart/#putting-it-all-together","title":"Putting It All Together","text":"<p>Let's solve a real-world problem: Find the total revenue per city from shipped orders.</p>"},{"location":"getting-started/quickstart/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Join users and orders</li> <li>Filter for shipped orders only</li> <li>Group by city</li> <li>Sum the amounts</li> </ol> <pre><code>ja join users.jsonl orders.jsonl --on user_id=user_id \\\n  | ja select 'status == \"shipped\"' \\\n  | ja groupby city --agg revenue=sum:amount\n</code></pre> <p>Output: <pre><code>{\"city\": \"NYC\", \"revenue\": 1315}\n{\"city\": \"SF\", \"revenue\": 560}\n</code></pre></p> <p>You Did It!</p> <p>You just performed a multi-step analysis combining filtering, joining, and aggregation!</p>"},{"location":"getting-started/quickstart/#working-with-nested-data","title":"Working with Nested Data","text":"<p>jsonl-algebra excels at handling nested JSON structures using dot notation.</p>"},{"location":"getting-started/quickstart/#create-nested-data","title":"Create Nested Data","text":"<pre><code>cat &gt; nested.jsonl &lt;&lt; 'EOF'\n{\"id\": 1, \"user\": {\"name\": \"Alice\", \"profile\": {\"age\": 30, \"city\": \"NYC\"}}}\n{\"id\": 2, \"user\": {\"name\": \"Bob\", \"profile\": {\"age\": 25, \"city\": \"SF\"}}}\n{\"id\": 3, \"user\": {\"name\": \"Charlie\", \"profile\": {\"age\": 35, \"city\": \"NYC\"}}}\nEOF\n</code></pre>"},{"location":"getting-started/quickstart/#access-nested-fields","title":"Access Nested Fields","text":"<pre><code># Project nested fields\nja project user.name,user.profile.city nested.jsonl\n</code></pre> <p>Output: <pre><code>{\"user.name\": \"Alice\", \"user.profile.city\": \"NYC\"}\n{\"user.name\": \"Bob\", \"user.profile.city\": \"SF\"}\n{\"user.name\": \"Charlie\", \"user.profile.city\": \"NYC\"}\n</code></pre></p> <pre><code># Filter on nested fields\nja select 'user.profile.age &gt; 28' nested.jsonl\n</code></pre> <p>Output: <pre><code>{\"id\": 1, \"user\": {\"name\": \"Alice\", \"profile\": {\"age\": 30, \"city\": \"NYC\"}}}\n{\"id\": 3, \"user\": {\"name\": \"Charlie\", \"profile\": {\"age\": 35, \"city\": \"NYC\"}}}\n</code></pre></p>"},{"location":"getting-started/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quickstart/#pattern-1-top-n-results","title":"Pattern 1: Top N Results","text":"<pre><code># Top 3 highest amounts\nja select 'status == \"shipped\"' orders.jsonl \\\n  | ja sort amount --desc \\\n  | head -3\n</code></pre>"},{"location":"getting-started/quickstart/#pattern-2-unique-values","title":"Pattern 2: Unique Values","text":"<pre><code># List all cities (unique)\nja project city users.jsonl | ja distinct\n</code></pre> <p>Output: <pre><code>{\"city\": \"NYC\"}\n{\"city\": \"SF\"}\n{\"city\": \"LA\"}\n</code></pre></p>"},{"location":"getting-started/quickstart/#pattern-3-data-validation","title":"Pattern 3: Data Validation","text":"<pre><code># Find users without required fields\nja select 'name == null or age == null' users.jsonl\n</code></pre>"},{"location":"getting-started/quickstart/#pattern-4-converting-formats","title":"Pattern 4: Converting Formats","text":"<pre><code># Convert to CSV\nja project name,age,city users.jsonl | ja export csv &gt; users.csv\n</code></pre>"},{"location":"getting-started/quickstart/#command-cheat-sheet","title":"Command Cheat Sheet","text":"Task Command Filter rows <code>ja select 'condition' file.jsonl</code> Select fields <code>ja project field1,field2 file.jsonl</code> Join files <code>ja join left.jsonl right.jsonl --on key1=key2</code> Group &amp; count <code>ja groupby field --agg count file.jsonl</code> Sort <code>ja sort field [--desc] file.jsonl</code> Remove dupes <code>ja distinct file.jsonl</code> Combine files <code>ja union file1.jsonl file2.jsonl</code> Get first N <code>ja ... | head -N</code> Count lines <code>ja ... | wc -l</code>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've mastered the basics, explore more:</p>"},{"location":"getting-started/quickstart/#learn-core-concepts","title":"Learn Core Concepts","text":"<ul> <li>Relational Algebra - Mathematical foundation</li> <li>Dot Notation - Working with nested data</li> <li>Streaming &amp; Piping - Processing large files</li> </ul>"},{"location":"getting-started/quickstart/#explore-advanced-features","title":"Explore Advanced Features","text":"<ul> <li>All CLI Commands - Complete command reference</li> <li>ja-shell - Interactive data exploration</li> <li>Integrations - MCP server, log analyzer, etc.</li> </ul>"},{"location":"getting-started/quickstart/#try-real-world-tutorials","title":"Try Real-World Tutorials","text":"<ul> <li>Analyzing Log Files</li> <li>Building ETL Pipelines</li> <li>Data Quality Checks</li> </ul>"},{"location":"getting-started/quickstart/#use-the-repl","title":"Use the REPL","text":"<p>For interactive exploration:</p> <pre><code>ja repl users.jsonl\n</code></pre> <p>Then try commands like: <pre><code>ja&gt; select 'age &gt; 28' filtered\nja&gt; info filtered\nja&gt; ls filtered --limit 3\n</code></pre></p>"},{"location":"getting-started/quickstart/#practice-exercises","title":"Practice Exercises","text":"<p>Try these challenges on your own:</p> <ol> <li>Find all engineers in NYC over age 28</li> <li>Calculate average order amount by status</li> <li>List users who have never placed an order</li> <li>Find the city with the highest total revenue</li> </ol> Solutions <pre><code># 1. Engineers in NYC over 28\nja select 'role == \"engineer\" and city == \"NYC\" and age &gt; 28' users.jsonl\n\n# 2. Average order amount by status\nja groupby status --agg avg_amount=avg:amount orders.jsonl\n\n# 3. Users with no orders (left join, filter nulls)\nja join users.jsonl orders.jsonl --on user_id=user_id --left \\\n  | ja select 'order_id == null'\n\n# 4. City with highest revenue\nja join users.jsonl orders.jsonl --on user_id=user_id \\\n  | ja select 'status == \"shipped\"' \\\n  | ja groupby city --agg revenue=sum:amount \\\n  | ja sort revenue --desc \\\n  | head -1\n</code></pre>"},{"location":"getting-started/quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>Run <code>ja --help</code> for command overview</li> <li>Run <code>ja &lt;command&gt; --help</code> for specific command help</li> <li>Check the FAQ for common questions</li> <li>Visit the Troubleshooting Guide if stuck</li> </ul> <p>You're Ready!</p> <p>You now know the essential operations of jsonl-algebra. Start using it on your own data!</p>"},{"location":"guide/repl/datasets/","title":"Dataset Management","text":"<p>The REPL provides comprehensive dataset management commands to load, organize, and inspect your data.</p>"},{"location":"guide/repl/datasets/#loading-datasets","title":"Loading Datasets","text":""},{"location":"guide/repl/datasets/#load-file-name","title":"<code>load &lt;file&gt; [name]</code>","text":"<p>Load a JSONL file into the workspace:</p> <pre><code># Load with default name (filename without extension)\nja&gt; load users.jsonl\nLoaded: users (current)\n  Path: /home/user/users.jsonl\n\n# Load with custom name\nja&gt; load /data/customers.jsonl clients\nLoaded: clients (current)\n  Path: /data/customers.jsonl\n</code></pre> <p>Behavior: - The dataset becomes the current dataset - Default name is the filename stem (without <code>.jsonl</code>) - Names must be unique (loading fails if name already exists) - File paths are stored, not data (streaming model preserved)</p>"},{"location":"guide/repl/datasets/#switching-between-datasets","title":"Switching Between Datasets","text":""},{"location":"guide/repl/datasets/#cd-name","title":"<code>cd &lt;name&gt;</code>","text":"<p>Change the current dataset:</p> <pre><code>ja&gt; load users.jsonl\nja&gt; load orders.jsonl\nja&gt; cd users\nCurrent dataset: users\n</code></pre>"},{"location":"guide/repl/datasets/#pwd-current","title":"<code>pwd</code> / <code>current</code>","text":"<p>Show the current dataset:</p> <pre><code>ja&gt; pwd\nCurrent dataset: users\n  Path: /home/user/users.jsonl\n</code></pre>"},{"location":"guide/repl/datasets/#listing-datasets","title":"Listing Datasets","text":""},{"location":"guide/repl/datasets/#datasets","title":"<code>datasets</code>","text":"<p>List all registered datasets:</p> <pre><code>ja&gt; datasets\nRegistered datasets:\n  orders\n    /home/user/orders.jsonl\n  users (current)\n    /home/user/users.jsonl\n  filtered\n    /tmp/ja_repl_abc123/filtered_1.jsonl\n</code></pre> <p>Output shows: - Dataset names (alphabetically sorted) - Current dataset marked with <code>(current)</code> - File paths (temp files for derived datasets)</p>"},{"location":"guide/repl/datasets/#inspecting-datasets","title":"Inspecting Datasets","text":""},{"location":"guide/repl/datasets/#info-name","title":"<code>info [name]</code>","text":"<p>Show detailed statistics about a dataset:</p> <pre><code># Show info for current dataset\nja&gt; info\n\nDataset: users\nPath: /home/user/users.jsonl\nRows: 1,234\nSize: 456.7 KB\nFields: id, name, age, email, location.city, location.state\n\nSample (first row):\n  {\n    \"id\": 1,\n    \"name\": \"Alice\",\n    \"age\": 30,\n    ...\n  }\n\n# Show info for specific dataset\nja&gt; info filtered\n\nDataset: filtered\nPath: /tmp/ja_repl_abc123/filtered_1.jsonl\nRows: 523\nSize: 198.4 KB\n...\n</code></pre> <p>Information displayed: - Dataset name - File path - Row count (with comma formatting) - File size (in B, KB, or MB) - Field names (with dot notation for nested fields) - Sample of first row</p>"},{"location":"guide/repl/datasets/#ls-name-limit-n","title":"<code>ls [name] [--limit N]</code>","text":"<p>Preview dataset contents:</p> <pre><code># Preview current dataset (default: window-size lines)\nja&gt; ls\n{\"id\": 1, \"name\": \"Alice\", ...}\n{\"id\": 2, \"name\": \"Bob\", ...}\n...\n\n# Preview with custom limit\nja&gt; ls --limit 3\n{\"id\": 1, \"name\": \"Alice\", ...}\n{\"id\": 2, \"name\": \"Bob\", ...}\n{\"id\": 3, \"name\": \"Charlie\", ...}\n\n# Preview specific dataset\nja&gt; ls users --limit 5\n...\n</code></pre>"},{"location":"guide/repl/datasets/#saving-datasets","title":"Saving Datasets","text":""},{"location":"guide/repl/datasets/#save-file","title":"<code>save &lt;file&gt;</code>","text":"<p>Persist the current dataset to a file:</p> <pre><code>ja&gt; save output.jsonl\nSaved users to: output.jsonl\n\n# Save to a different location\nja&gt; save /tmp/backup.jsonl\nSaved users to: /tmp/backup.jsonl\n</code></pre> <p>Notes: - Only saves the current dataset - Does NOT register the saved file as a new dataset - Overwrites existing files without warning</p>"},{"location":"guide/repl/datasets/#dataset-lifecycle","title":"Dataset Lifecycle","text":""},{"location":"guide/repl/datasets/#original-files-vs-derived-datasets","title":"Original Files vs. Derived Datasets","text":"<ul> <li>Original files: Loaded with <code>load</code>, stored at their original paths</li> <li>Derived datasets: Created by operations, stored in temp directory</li> </ul> <pre><code>ja&gt; load users.jsonl\n# users -&gt; /home/user/users.jsonl (original)\n\nja&gt; select 'age &gt; 30' adults\n# adults -&gt; /tmp/ja_repl_xyz/adults_1.jsonl (derived)\n</code></pre>"},{"location":"guide/repl/datasets/#temporary-files","title":"Temporary Files","text":"<p>Derived datasets are automatically stored in a temporary directory:</p> <pre><code>/tmp/ja_repl_&lt;session_id&gt;/\n  \u251c\u2500\u2500 adults_1.jsonl\n  \u251c\u2500\u2500 filtered_2.jsonl\n  \u2514\u2500\u2500 joined_3.jsonl\n</code></pre> <p>Cleanup: - Temp files persist for the session duration - Automatically cleaned up when REPL exits - Use <code>save</code> to persist important results</p>"},{"location":"guide/repl/datasets/#name-conflict-prevention","title":"Name Conflict Prevention","text":"<p>Dataset names must be unique:</p> <pre><code>ja&gt; load users.jsonl\nLoaded: users (current)\n\nja&gt; load users.jsonl\nError: Dataset 'users' already exists. Use a different name.\n\n# Solution: Use custom name\nja&gt; load users.jsonl users2\nLoaded: users2 (current)\n</code></pre> <p>This applies to both loading and operations:</p> <pre><code>ja&gt; select 'age &gt; 30' filtered\nCreated: filtered (current)\n\nja&gt; select 'city == \"NYC\"' filtered\nError: Dataset 'filtered' already exists. Use a different name.\n</code></pre>"},{"location":"guide/repl/datasets/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use descriptive names for derived datasets:    <pre><code>ja&gt; select 'status == \"active\"' active_users\nja&gt; select 'age &gt; 65' seniors\n</code></pre></p> </li> <li> <p>Check <code>info</code> before operations to understand your data:    <pre><code>ja&gt; load data.jsonl\nja&gt; info  # Check structure first\nja&gt; select '...' filtered\n</code></pre></p> </li> <li> <p>Use <code>datasets</code> to track your workspace:    <pre><code>ja&gt; datasets  # See what's loaded\nja&gt; info users\nja&gt; info processed\n</code></pre></p> </li> <li> <p>Save important results before continuing:    <pre><code>ja&gt; select ... important\nja&gt; save important_data.jsonl  # Persist it\nja&gt; select ... more_work\n</code></pre></p> </li> </ol>"},{"location":"guide/repl/datasets/#examples","title":"Examples","text":""},{"location":"guide/repl/datasets/#loading-multiple-files","title":"Loading Multiple Files","text":"<pre><code>ja&gt; load users.jsonl\nLoaded: users (current)\n\nja&gt; load orders.jsonl\nLoaded: orders (current)\n\nja&gt; load products.jsonl\nLoaded: products (current)\n\nja&gt; datasets\nRegistered datasets:\n  orders\n  products (current)\n  users\n</code></pre>"},{"location":"guide/repl/datasets/#working-with-custom-names","title":"Working with Custom Names","text":"<pre><code>ja&gt; load jan_sales.jsonl sales_jan\nLoaded: sales_jan (current)\n\nja&gt; load feb_sales.jsonl sales_feb\nLoaded: sales_feb (current)\n\nja&gt; cd sales_jan\nCurrent dataset: sales_jan\n\nja&gt; union sales_feb q1_sales\nCreated: q1_sales (current)\n\nja&gt; info q1_sales\nDataset: q1_sales\nRows: 2,456\n...\n</code></pre>"},{"location":"guide/repl/datasets/#exploring-unknown-data","title":"Exploring Unknown Data","text":"<pre><code>ja&gt; load mystery.jsonl\nLoaded: mystery (current)\n\nja&gt; info\nDataset: mystery\nRows: 10,234\nSize: 2.3 MB\nFields (15 total): id, timestamp, user.name, user.email, ...\n\nja&gt; ls --limit 2\n{\"id\": 1, \"timestamp\": \"2024-01-01\", ...}\n{\"id\": 2, \"timestamp\": \"2024-01-02\", ...}\n</code></pre>"},{"location":"guide/repl/introduction/","title":"Interactive REPL","text":"<p>The JSONL Algebra REPL (Read-Eval-Print Loop) provides a powerful interactive environment for exploring and transforming JSONL data.</p>"},{"location":"guide/repl/introduction/#overview","title":"Overview","text":"<p>The REPL allows you to:</p> <ul> <li>Load and manage multiple datasets by name</li> <li>Execute operations immediately and see results</li> <li>Chain transformations interactively</li> <li>Explore data with preview and statistics commands</li> <li>Save results when you're satisfied with the transformation</li> </ul> <p>Unlike traditional pipeline-based tools, the REPL maintains a workspace of named datasets that you can switch between, combine, and transform without leaving your session.</p>"},{"location":"guide/repl/introduction/#starting-the-repl","title":"Starting the REPL","text":"<pre><code># Start an empty REPL session\nja repl\n\n# Start with a file already loaded\nja repl mydata.jsonl\n</code></pre>"},{"location":"guide/repl/introduction/#key-design-principles","title":"Key Design Principles","text":""},{"location":"guide/repl/introduction/#named-datasets","title":"Named Datasets","text":"<p>Every dataset in the REPL has a unique name:</p> <ul> <li>Original files keep their filename (without extension) as the default name</li> <li>Operations create new named datasets</li> <li>You can have multiple datasets loaded simultaneously</li> </ul>"},{"location":"guide/repl/introduction/#non-destructive-operations","title":"Non-Destructive Operations","text":"<p>All operations create new datasets rather than modifying existing ones:</p> <pre><code>ja&gt; load users.jsonl\nLoaded: users (current)\n\nja&gt; select 'age &gt; 30' adults\nCreated: adults (current)\n\n# 'users' still exists unchanged!\nja&gt; datasets\n  users\n  adults (current)\n</code></pre>"},{"location":"guide/repl/introduction/#immediate-execution","title":"Immediate Execution","text":"<p>Operations execute immediately and show results:</p> <pre><code>ja&gt; select 'age &gt; 30' filtered\nCreated: filtered (current)\n\nja&gt; ls --limit 3\n{\"id\": 1, \"name\": \"Alice\", \"age\": 35}\n{\"id\": 2, \"name\": \"Bob\", \"age\": 42}\n{\"id\": 3, \"name\": \"Charlie\", \"age\": 38}\n</code></pre>"},{"location":"guide/repl/introduction/#current-dataset-context","title":"Current Dataset Context","text":"<p>The REPL tracks a \"current\" dataset that operations use by default:</p> <pre><code>ja&gt; load users.jsonl\nLoaded: users (current)\n\nja&gt; pwd\nCurrent dataset: users\n  Path: /home/user/users.jsonl\n</code></pre>"},{"location":"guide/repl/introduction/#basic-workflow","title":"Basic Workflow","text":"<p>Here's a typical REPL workflow:</p> <pre><code># 1. Load data\nja&gt; load users.jsonl\nLoaded: users (current)\n\n# 2. Explore the data\nja&gt; info\nDataset: users\nRows: 100\nSize: 15.2 KB\nFields: id, name, age, email, city\n\n# 3. Preview some rows\nja&gt; ls --limit 5\n...\n\n# 4. Transform the data\nja&gt; select 'age &gt; 25' adults\nCreated: adults (current)\n\n# 5. Check the results\nja&gt; info\nDataset: adults\nRows: 75\nSize: 11.4 KB\n\n# 6. Save when satisfied\nja&gt; save output.jsonl\nSaved adults to: output.jsonl\n</code></pre>"},{"location":"guide/repl/introduction/#command-categories","title":"Command Categories","text":"<p>The REPL commands fall into several categories:</p>"},{"location":"guide/repl/introduction/#dataset-management","title":"Dataset Management","text":"<ul> <li><code>load</code>, <code>cd</code>, <code>pwd</code>, <code>datasets</code>, <code>info</code>, <code>save</code></li> </ul>"},{"location":"guide/repl/introduction/#data-operations","title":"Data Operations","text":"<ul> <li>Unary: <code>select</code>, <code>project</code>, <code>rename</code>, <code>distinct</code>, <code>sort</code>, <code>groupby</code></li> <li>Binary: <code>join</code>, <code>union</code>, <code>intersection</code>, <code>difference</code>, <code>product</code></li> </ul>"},{"location":"guide/repl/introduction/#exploration","title":"Exploration","text":"<ul> <li><code>ls</code>, <code>info</code></li> </ul>"},{"location":"guide/repl/introduction/#utilities","title":"Utilities","text":"<ul> <li><code>!&lt;command&gt;</code> - Shell commands</li> <li><code>window-size</code> - Settings</li> <li><code>help</code> - Show help</li> <li><code>exit</code> - Quit</li> </ul>"},{"location":"guide/repl/introduction/#next-steps","title":"Next Steps","text":"<ul> <li>Dataset Management - Learn about loading, switching, and managing datasets</li> <li>Operations - Explore all available data transformations</li> <li>Tips &amp; Tricks - Advanced REPL usage patterns</li> </ul>"},{"location":"guide/repl/operations/","title":"REPL Operations","text":"<p>All data transformation operations in the REPL require an output name and create a new dataset.</p>"},{"location":"guide/repl/operations/#unary-operations","title":"Unary Operations","text":"<p>Unary operations transform the current dataset.</p>"},{"location":"guide/repl/operations/#select-expression-output_name","title":"<code>select '&lt;expression&gt;' &lt;output_name&gt;</code>","text":"<p>Filter rows based on a condition:</p> <pre><code>ja&gt; select 'age &gt; 30' adults\nCreated: adults (current)\n\nja&gt; select 'status == `\"active\"` &amp;&amp; score &gt; 80' high_performers\nCreated: high_performers (current)\n</code></pre> <p>Expression Syntax: - JMESPath expressions - Use backticks for string literals: <code>\\</code>\"value\"`<code>- Supports nested fields with dot notation:</code>user.age &gt; 25`</p>"},{"location":"guide/repl/operations/#project-fields-output_name","title":"<code>project &lt;fields&gt; &lt;output_name&gt;</code>","text":"<p>Select specific fields:</p> <pre><code>ja&gt; project id,name,email user_contact\nCreated: user_contact (current)\n\nja&gt; project user.name,user.location.city user_info\nCreated: user_info (current)\n</code></pre> <p>Field Syntax: - Comma-separated field names - Supports dot notation for nested fields - No spaces around commas</p>"},{"location":"guide/repl/operations/#rename-oldnew-output_name","title":"<code>rename &lt;old=new,...&gt; &lt;output_name&gt;</code>","text":"<p>Rename fields:</p> <pre><code>ja&gt; rename id=user_id,name=full_name renamed\nCreated: renamed (current)\n\nja&gt; rename user.loc=user.location updated\nCreated: updated (current)\n</code></pre>"},{"location":"guide/repl/operations/#distinct-output_name","title":"<code>distinct &lt;output_name&gt;</code>","text":"<p>Remove duplicate rows:</p> <pre><code>ja&gt; distinct unique\nCreated: unique (current)\n</code></pre>"},{"location":"guide/repl/operations/#sort-keys-desc-output_name","title":"<code>sort &lt;keys&gt; [--desc] &lt;output_name&gt;</code>","text":"<p>Sort by one or more keys:</p> <pre><code># Ascending order\nja&gt; sort age sorted_by_age\nCreated: sorted_by_age (current)\n\n# Descending order\nja&gt; sort amount --desc top_amounts\nCreated: top_amounts (current)\n\n# Multiple keys\nja&gt; sort city,age sorted_multi\nCreated: sorted_multi (current)\n</code></pre>"},{"location":"guide/repl/operations/#groupby-key-agg-spec-output_name","title":"<code>groupby &lt;key&gt; [--agg &lt;spec&gt;] &lt;output_name&gt;</code>","text":"<p>Group rows by a key:</p> <pre><code># Group without aggregation (adds metadata)\nja&gt; groupby category grouped\nCreated: grouped (current)\n\n# Group with aggregation\nja&gt; groupby region --agg count,sum(amount) summary\nCreated: summary (current)\n\n# Multiple aggregations\nja&gt; groupby product --agg count,avg(price),max(price) stats\nCreated: stats (current)\n</code></pre> <p>Aggregation Functions: - <code>count</code> - Count rows - <code>sum(field)</code> - Sum values - <code>avg(field)</code> - Average - <code>min(field)</code> - Minimum - <code>max(field)</code> - Maximum - <code>list(field)</code> - Collect all values - <code>first(field)</code> - First value - <code>last(field)</code> - Last value</p>"},{"location":"guide/repl/operations/#binary-operations","title":"Binary Operations","text":"<p>Binary operations combine the current dataset with another named dataset.</p>"},{"location":"guide/repl/operations/#join-dataset-on-mapping-output_name","title":"<code>join &lt;dataset&gt; --on &lt;mapping&gt; &lt;output_name&gt;</code>","text":"<p>Join two datasets:</p> <pre><code>ja&gt; cd users\nCurrent dataset: users\n\nja&gt; join orders --on id=user_id user_orders\nCreated: user_orders (current)\n\n# Join on nested fields\nja&gt; join companies --on user.company_id=id user_companies\nCreated: user_companies (current)\n</code></pre> <p>Notes: - Current dataset is the left side - Specified dataset is the right side - Mapping format: <code>left_field=right_field</code> - Supports dot notation in field names</p>"},{"location":"guide/repl/operations/#union-dataset-output_name","title":"<code>union &lt;dataset&gt; &lt;output_name&gt;</code>","text":"<p>Combine rows from two datasets (deduplicated):</p> <pre><code>ja&gt; cd jan_sales\nja&gt; union feb_sales q1_sales\nCreated: q1_sales (current)\n</code></pre>"},{"location":"guide/repl/operations/#intersection-dataset-output_name","title":"<code>intersection &lt;dataset&gt; &lt;output_name&gt;</code>","text":"<p>Keep only rows present in both datasets:</p> <pre><code>ja&gt; cd active_users\nja&gt; intersection premium_users premium_active\nCreated: premium_active (current)\n</code></pre>"},{"location":"guide/repl/operations/#difference-dataset-output_name","title":"<code>difference &lt;dataset&gt; &lt;output_name&gt;</code>","text":"<p>Remove rows present in another dataset:</p> <pre><code>ja&gt; cd all_users\nja&gt; difference inactive_users active_only\nCreated: active_only (current)\n</code></pre>"},{"location":"guide/repl/operations/#product-dataset-output_name","title":"<code>product &lt;dataset&gt; &lt;output_name&gt;</code>","text":"<p>Cartesian product of two datasets:</p> <pre><code>ja&gt; cd colors\nja&gt; product sizes combinations\nCreated: combinations (current)\n</code></pre>"},{"location":"guide/repl/operations/#operation-chaining","title":"Operation Chaining","text":"<p>Operations automatically switch to the newly created dataset, enabling natural chaining:</p> <pre><code>ja&gt; load users.jsonl\nLoaded: users (current)\n\nja&gt; select 'age &gt; 25' adults\nCreated: adults (current)\n\nja&gt; project name,email,city contact_info\nCreated: contact_info (current)\n\nja&gt; sort name sorted\nCreated: sorted (current)\n\nja&gt; ls --limit 3\n{\"name\": \"Alice\", \"email\": \"alice@example.com\", \"city\": \"NYC\"}\n...\n</code></pre>"},{"location":"guide/repl/operations/#working-with-multiple-datasets","title":"Working with Multiple Datasets","text":"<p>You can work with multiple datasets by switching between them:</p> <pre><code>ja&gt; load users.jsonl\nja&gt; load orders.jsonl\n\n# Work with users\nja&gt; cd users\nja&gt; select 'status == `\"active\"`' active_users\nCreated: active_users (current)\n\n# Work with orders\nja&gt; cd orders\nja&gt; select 'amount &gt; 100' large_orders\nCreated: large_orders (current)\n\n# Join them\nja&gt; cd active_users\nja&gt; join large_orders --on id=user_id result\nCreated: result (current)\n</code></pre>"},{"location":"guide/repl/operations/#examples","title":"Examples","text":""},{"location":"guide/repl/operations/#data-cleaning-pipeline","title":"Data Cleaning Pipeline","text":"<pre><code>ja&gt; load raw_data.jsonl\nLoaded: raw_data (current)\n\n# Remove nulls\nja&gt; select 'name != `null`' has_name\nCreated: has_name (current)\n\n# Remove duplicates\nja&gt; distinct unique\nCreated: unique (current)\n\n# Select specific fields\nja&gt; project id,name,email,created_at clean\nCreated: clean (current)\n\n# Sort by creation date\nja&gt; sort created_at sorted\nCreated: sorted (current)\n\nja&gt; save cleaned_data.jsonl\nSaved sorted to: cleaned_data.jsonl\n</code></pre>"},{"location":"guide/repl/operations/#aggregation-workflow","title":"Aggregation Workflow","text":"<pre><code>ja&gt; load sales.jsonl\nLoaded: sales (current)\n\n# Filter to this year\nja&gt; select 'year == `2024`' sales_2024\nCreated: sales_2024 (current)\n\n# Group by region and calculate totals\nja&gt; groupby region --agg count,sum(amount),avg(amount) regional_summary\nCreated: regional_summary (current)\n\n# Sort by total amount\nja&gt; sort sum_amount --desc top_regions\nCreated: top_regions (current)\n\nja&gt; ls\n{\"region\": \"West\", \"count\": 1234, \"sum_amount\": 456789, \"avg_amount\": 370}\n{\"region\": \"East\", \"count\": 1100, \"sum_amount\": 398000, \"avg_amount\": 362}\n...\n</code></pre>"},{"location":"guide/repl/operations/#multi-dataset-join","title":"Multi-Dataset Join","text":"<pre><code>ja&gt; load users.jsonl\nja&gt; load orders.jsonl\nja&gt; load products.jsonl\n\n# Join users with orders\nja&gt; cd users\nja&gt; join orders --on id=user_id user_orders\nCreated: user_orders (current)\n\n# Join with products\nja&gt; join products --on product_id=id full_data\nCreated: full_data (current)\n\n# Aggregate by user\nja&gt; groupby name --agg count,sum(price) user_spending\nCreated: user_spending (current)\n\n# Get top spenders\nja&gt; sort sum_price --desc top_spenders\nCreated: top_spenders (current)\n\nja&gt; ls --limit 10\n...\n</code></pre>"},{"location":"guide/repl/operations/#filtering-and-comparison","title":"Filtering and Comparison","text":"<pre><code>ja&gt; load all_transactions.jsonl\nLoaded: all_transactions (current)\n\n# Get high-value transactions\nja&gt; select 'amount &gt; 1000' high_value\nCreated: high_value (current)\n\n# Get fraud flags\nja&gt; cd all_transactions\nja&gt; select 'flagged == `true`' flagged\nCreated: flagged (current)\n\n# Find intersection (high-value AND flagged)\nja&gt; cd high_value\nja&gt; intersection flagged investigate\nCreated: investigate (current)\n\nja&gt; info\nDataset: investigate\nRows: 23\nSize: 5.6 KB\n...\n</code></pre>"},{"location":"guide/repl/operations/#tips","title":"Tips","text":"<ol> <li> <p>Name your outputs descriptively to track transformations:    <pre><code>ja&gt; select 'age &gt; 65' seniors\nja&gt; select 'income &lt; 30000' low_income\nja&gt; intersection low_income seniors low_income_seniors\n</code></pre></p> </li> <li> <p>Use <code>info</code> after operations to verify results:    <pre><code>ja&gt; select 'status == `\"active\"`' active\nCreated: active (current)\n\nja&gt; info\nDataset: active\nRows: 523  # Down from 1000, looks right!\n</code></pre></p> </li> <li> <p>Preview before saving:    <pre><code>ja&gt; ls --limit 10  # Check it looks good\nja&gt; save final_output.jsonl\n</code></pre></p> </li> <li> <p>Keep intermediate results for debugging:    <pre><code>ja&gt; select ... step1\nja&gt; project ... step2\nja&gt; join ... step3\n# Now you can go back and check each step!\n</code></pre></p> </li> </ol>"},{"location":"integrations/overview/","title":"Integrations Overview","text":"<p>jsonl-algebra comes with powerful integrations that extend its capabilities beyond the core CLI and library. These integrations demonstrate real-world applications and provide ready-to-use tools for common data processing tasks.</p>"},{"location":"integrations/overview/#available-integrations","title":"Available Integrations","text":""},{"location":"integrations/overview/#1-mcp-server-ai-assistant-integration","title":"1. MCP Server - AI Assistant Integration","text":"<p>Model Context Protocol server for AI assistants and agentic coders</p> <p>The MCP server exposes jsonl-algebra operations as structured tools that AI assistants (like Claude, ChatGPT, etc.) can use to manipulate JSONL files through natural language.</p> <pre><code># Setup\npip install mcp\npython -m integrations.mcp_server\n</code></pre> <p>Features:</p> <ul> <li>9 specialized tools for JSONL manipulation</li> <li>Natural language query interface</li> <li>Automatic file discovery as resources</li> <li>Multiple output formats (JSONL, JSON, table, summary)</li> <li>Complex transformation pipelines</li> <li>JMESPath expression support</li> </ul> <p>Use Cases:</p> <ul> <li>\"Show me all users older than 25 from users.jsonl\"</li> <li>\"Calculate average salary by department\"</li> <li>\"Join orders and customers files on customer_id\"</li> <li>\"Get statistics about the sales data\"</li> </ul> <p>Learn More \u2192</p>"},{"location":"integrations/overview/#2-log-analyzer-real-time-monitoring","title":"2. Log Analyzer - Real-time Monitoring","text":"<p>Streaming log analysis with alerts and dashboards</p> <p>Analyze log files in real-time with sliding windows, alert systems, and terminal visualization.</p> <pre><code>python integrations/log_analyzer.py /var/log/app.log --window 60 --threshold 10\n</code></pre> <p>Features:</p> <ul> <li>Streaming log processing</li> <li>Sliding window analysis</li> <li>Error rate monitoring</li> <li>Performance anomaly detection</li> <li>Terminal dashboard</li> <li>Customizable alert system</li> <li>Pattern detection</li> </ul> <p>Use Cases:</p> <ul> <li>Monitor application error rates</li> <li>Detect performance degradation</li> <li>Real-time log filtering</li> <li>Alert on specific patterns</li> <li>Track request rates</li> </ul> <p>Learn More \u2192</p>"},{"location":"integrations/overview/#3-data-explorer-interactive-repl","title":"3. Data Explorer - Interactive REPL","text":"<p>SQL-like interactive exploration for JSONL files</p> <p>Explore JSONL files interactively with SQL-like syntax, tab completion, and data profiling.</p> <pre><code>python integrations/data_explorer.py data.jsonl\n</code></pre> <p>Features:</p> <ul> <li>SQL-like query syntax</li> <li>Tab completion for commands and fields</li> <li>Data profiling and statistics</li> <li>Export to multiple formats</li> <li>Command history and recall</li> <li>Visual result formatting</li> <li>Schema inference</li> </ul> <p>Example Session:</p> <pre><code>&gt; SELECT name, age WHERE age &gt; 25\n&gt; GROUP BY city AGGREGATE count, avg(age)\n&gt; PROFILE\n&gt; EXPORT results.csv\n</code></pre> <p>Use Cases:</p> <ul> <li>Ad-hoc data exploration</li> <li>Quick data quality checks</li> <li>Interactive analysis</li> <li>Export filtered datasets</li> <li>Schema discovery</li> </ul> <p>Learn More \u2192</p>"},{"location":"integrations/overview/#4-ml-pipeline-machine-learning-integration","title":"4. ML Pipeline - Machine Learning Integration","text":"<p>Feature engineering with scikit-learn integration</p> <p>Use jsonl-algebra for ML data preprocessing and feature engineering.</p> <pre><code>from integrations.ml_pipeline import JSONLFeatureEngine\n\nengine = JSONLFeatureEngine(\"training.jsonl\")\nengine.add_feature(\"age_squared\", lambda r: r[\"age\"] ** 2)\nX, y = engine.prepare_features([\"age\", \"age_squared\"], \"target\")\n</code></pre> <p>Features:</p> <ul> <li>Feature engineering with ja transformations</li> <li>scikit-learn pipeline integration</li> <li>Automated preprocessing</li> <li>Model evaluation utilities</li> <li>Cross-validation support</li> <li>Feature selection helpers</li> </ul> <p>Use Cases:</p> <ul> <li>Clean training data</li> <li>Engineer features from JSONL</li> <li>Build ML pipelines</li> <li>Preprocess for scikit-learn</li> <li>Feature transformation</li> </ul> <p>Learn More \u2192</p>"},{"location":"integrations/overview/#5-composability-module-functional-pipelines","title":"5. Composability Module - Functional Pipelines","text":"<p>Built into core library - functional programming patterns</p> <p>The composability module provides Pipeline classes and functional operators for elegant data transformations.</p> <pre><code>from ja.compose import Pipeline, Select, Project, Sort\n\npipeline = (\n    Pipeline()\n    | Select(\"age &gt; 25\")\n    | Project([\"name\", \"email\"])\n    | Sort(\"name\")\n)\n\nresults = pipeline.run(\"data.jsonl\")\n</code></pre> <p>Features:</p> <ul> <li>Pipeline class for composition</li> <li>Unix pipe operator support (<code>|</code>)</li> <li>Lazy evaluation for large datasets</li> <li>Functional helpers (<code>compose</code>, <code>pipe</code>)</li> <li>Operation classes (Select, Project, Sort, etc.)</li> <li>Chainable transformations</li> </ul> <p>Use Cases:</p> <ul> <li>Build reusable pipelines</li> <li>Functional data processing</li> <li>Lazy evaluation for big data</li> <li>Elegant API usage</li> <li>Complex transformations</li> </ul> <p>Learn More \u2192</p>"},{"location":"integrations/overview/#comparison-matrix","title":"Comparison Matrix","text":"Integration Use Case Language Interactive AI-Ready MCP Server AI assistant integration Python No \u2705 Yes Log Analyzer Real-time monitoring Python Yes (Dashboard) No Data Explorer Ad-hoc exploration Python Yes (REPL) No ML Pipeline Machine learning Python No No Composability Library usage Python No No"},{"location":"integrations/overview/#installation","title":"Installation","text":""},{"location":"integrations/overview/#all-integrations","title":"All Integrations","text":"<p>Install jsonl-algebra with all optional dependencies:</p> <pre><code>pip install jsonl-algebra[integrations]\n</code></pre>"},{"location":"integrations/overview/#individual-integrations","title":"Individual Integrations","text":"MCP ServerLog AnalyzerData ExplorerML PipelineComposability <pre><code>pip install mcp\n./integrations/setup_mcp.sh\n</code></pre> <pre><code>pip install rich  # For terminal UI\npython integrations/log_analyzer.py\n</code></pre> <pre><code>pip install prompt-toolkit rich\npython integrations/data_explorer.py\n</code></pre> <pre><code>pip install scikit-learn pandas\npython -c \"from integrations.ml_pipeline import JSONLFeatureEngine\"\n</code></pre> <pre><code># Built-in - no extra install needed\npip install jsonl-algebra\npython -c \"from ja.compose import Pipeline\"\n</code></pre>"},{"location":"integrations/overview/#common-workflows","title":"Common Workflows","text":""},{"location":"integrations/overview/#workflow-1-ai-powered-data-analysis","title":"Workflow 1: AI-Powered Data Analysis","text":"<p>Use the MCP server with an AI assistant:</p> <pre><code>User: \"Analyze the sales data and find top products by revenue\"\n\nAI: *Uses MCP server*\n    1. jsonl_query: \"SELECT * FROM sales.jsonl\"\n    2. jsonl_aggregate: group_by=['product'], agg={'revenue': 'sum'}\n    3. jsonl_sort: by='revenue', reverse=true\n\nResult: Top products with revenue displayed\n</code></pre>"},{"location":"integrations/overview/#workflow-2-real-time-monitoring-alert-analysis","title":"Workflow 2: Real-time Monitoring \u2192 Alert \u2192 Analysis","text":"<pre><code># 1. Monitor logs in real-time\npython integrations/log_analyzer.py /var/log/app.log --alert-threshold 10\n\n# 2. When alert triggers, explore interactively\npython integrations/data_explorer.py /var/log/app.log\n\n# 3. Export filtered data for deeper analysis\n&gt; SELECT * WHERE level = 'ERROR' AND timestamp &gt; '2025-10-27'\n&gt; EXPORT error_logs.jsonl\n</code></pre>"},{"location":"integrations/overview/#workflow-3-etl-with-ml-training","title":"Workflow 3: ETL with ML Training","text":"<pre><code>from ja.compose import Pipeline, Select, Project\nfrom integrations.ml_pipeline import JSONLFeatureEngine\n\n# 1. ETL pipeline\npipeline = (\n    Pipeline()\n    | Select(\"status == 'complete'\")\n    | Project([\"user_id\", \"score\", \"timestamp\"])\n)\n\ncleaned = pipeline.run(\"raw_data.jsonl\")\n\n# 2. Feature engineering\nengine = JSONLFeatureEngine(cleaned)\nengine.add_feature(\"score_squared\", lambda r: r[\"score\"] ** 2)\nengine.add_feature(\"hour\", lambda r: extract_hour(r[\"timestamp\"]))\n\n# 3. Prepare for ML\nX, y = engine.prepare_features([\"score\", \"score_squared\", \"hour\"], \"target\")\n\n# 4. Train model\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X, y)\n</code></pre>"},{"location":"integrations/overview/#design-philosophy","title":"Design Philosophy","text":"<p>All integrations follow these principles:</p>"},{"location":"integrations/overview/#1-unix-philosophy","title":"1. Unix Philosophy","text":"<p>Do one thing well, compose easily:</p> <pre><code># Each tool focuses on one aspect\nja select ... | python integrations/log_analyzer.py -\n</code></pre>"},{"location":"integrations/overview/#2-pythonic-patterns","title":"2. Pythonic Patterns","text":"<p>Explicit, simple, readable:</p> <pre><code># Clear, idiomatic Python\npipeline = Pipeline() | Select(\"x &gt; 0\") | Project([\"name\"])\n</code></pre>"},{"location":"integrations/overview/#3-streaming-first","title":"3. Streaming First","text":"<p>Handle massive datasets efficiently:</p> <pre><code># Processes data line-by-line\nfor record in pipeline.run_lazy(\"huge.jsonl\"):\n    process(record)\n</code></pre>"},{"location":"integrations/overview/#4-real-world-utility","title":"4. Real-World Utility","text":"<p>Solve actual problems elegantly:</p> <pre><code># Real monitoring use case\npython integrations/log_analyzer.py production.log --alert-email admin@example.com\n</code></pre>"},{"location":"integrations/overview/#5-comprehensive-documentation","title":"5. Comprehensive Documentation","text":"<p>Examples and guides for everything:</p> <ul> <li>Detailed README for each integration</li> <li>Usage examples</li> <li>API documentation</li> <li>Tutorial walkthroughs</li> </ul>"},{"location":"integrations/overview/#creating-your-own-integration","title":"Creating Your Own Integration","text":"<p>Want to build a custom integration? Here's the pattern:</p> <pre><code># integrations/my_custom_tool.py\n\nfrom ja.core import read_jsonl, select, project\nfrom typing import Iterator, Dict\n\nclass MyCustomTool:\n    \"\"\"\n    My custom integration for jsonl-algebra.\n\n    Does something specific and useful.\n    \"\"\"\n\n    def __init__(self, input_file: str):\n        self.input_file = input_file\n\n    def process(self) -&gt; Iterator[Dict]:\n        \"\"\"Process data using ja operations.\"\"\"\n        data = read_jsonl(self.input_file)\n\n        # Use core operations\n        filtered = select(data, \"status == 'active'\")\n        projected = project(filtered, [\"id\", \"name\"])\n\n        return projected\n\n    def run(self):\n        \"\"\"Main entry point.\"\"\"\n        for record in self.process():\n            # Do something with record\n            print(record)\n\nif __name__ == \"__main__\":\n    import sys\n    tool = MyCustomTool(sys.argv[1])\n    tool.run()\n</code></pre>"},{"location":"integrations/overview/#integration-checklist","title":"Integration Checklist","text":"<ul> <li> Clear, focused purpose</li> <li> Uses ja core operations</li> <li> Handles streaming data</li> <li> Comprehensive docstrings</li> <li> Usage examples</li> <li> Error handling</li> <li> Tests</li> <li> README documentation</li> </ul>"},{"location":"integrations/overview/#testing-integrations","title":"Testing Integrations","text":"<p>Each integration has tests:</p> <pre><code># Run all integration tests\npytest integrations/\n\n# Run specific integration tests\npytest integrations/test_mcp_minimal.py\npytest integrations/test_log_analyzer.py\n</code></pre>"},{"location":"integrations/overview/#test-coverage","title":"Test Coverage","text":"<pre><code>pytest --cov=integrations integrations/\n</code></pre>"},{"location":"integrations/overview/#dependencies","title":"Dependencies","text":""},{"location":"integrations/overview/#core-dependencies","title":"Core Dependencies","text":"<p>All integrations require:</p> <ul> <li>Python 3.8+</li> <li>jsonl-algebra</li> </ul>"},{"location":"integrations/overview/#optional-dependencies","title":"Optional Dependencies","text":"Integration Requires MCP Server <code>mcp</code> Log Analyzer <code>rich</code> Data Explorer <code>prompt-toolkit</code>, <code>rich</code>, <code>pandas</code> (optional) ML Pipeline <code>scikit-learn</code>, <code>pandas</code>"},{"location":"integrations/overview/#installing-all","title":"Installing All","text":"<pre><code># Everything in one command\npip install jsonl-algebra[integrations]\n</code></pre>"},{"location":"integrations/overview/#performance-considerations","title":"Performance Considerations","text":""},{"location":"integrations/overview/#memory-usage","title":"Memory Usage","text":"Integration Memory Pattern Best For MCP Server Per-request Small to medium datasets Log Analyzer Sliding window Streaming data Data Explorer Buffered Interactive exploration ML Pipeline Dataset-sized Training data preparation Composability Configurable (lazy/eager) Any size"},{"location":"integrations/overview/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Use lazy pipelines for large datasets</li> <li>Filter early to reduce data size</li> <li>Adjust cache sizes for your workload</li> <li>Monitor memory with large aggregations</li> <li>Stream when possible instead of buffering</li> </ol>"},{"location":"integrations/overview/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/overview/#common-issues","title":"Common Issues","text":"<p>Import Error <pre><code>ModuleNotFoundError: No module named 'mcp'\n</code></pre> Solution: <code>pip install mcp</code></p> <p>Memory Error with Large Files <pre><code>MemoryError: Unable to allocate array\n</code></pre> Solution: Use lazy evaluation or streaming mode</p> <p>MCP Server Not Starting <pre><code>Error: Cannot start MCP server\n</code></pre> Solution: Check MCP SDK installation and configuration</p>"},{"location":"integrations/overview/#community-integrations","title":"Community Integrations","text":"<p>Have you built an integration? Share it!</p> <ol> <li>Create a PR to add it to <code>integrations/</code></li> <li>Follow the integration checklist</li> <li>Add documentation</li> <li>Include tests</li> </ol>"},{"location":"integrations/overview/#next-steps","title":"Next Steps","text":"<p>Explore each integration in detail:</p> <ul> <li>MCP Server Guide - AI assistant integration</li> <li>Log Analyzer Guide - Real-time monitoring</li> <li>Data Explorer Guide - Interactive REPL</li> <li>ML Pipeline Guide - Machine learning</li> <li>Composability API - Functional patterns</li> </ul> <p>Or try a tutorial:</p> <ul> <li>Real-time Monitoring Tutorial</li> <li>ETL Pipeline Tutorial</li> <li>Data Analysis Tutorial</li> </ul>"},{"location":"operations/overview/","title":"Operations Overview","text":"<p><code>ja</code> provides a complete set of relational algebra operations designed for JSON data. Each operation follows the principle of taking relations (JSONL data) and producing relations, enabling infinite composability.</p>"},{"location":"operations/overview/#core-operations","title":"Core Operations","text":""},{"location":"operations/overview/#selection-and-filtering","title":"Selection and Filtering","text":"Operation Symbol Purpose Example select \u03c3 Filter rows based on conditions <code>ja select 'age &gt; 30'</code> distinct \u03b4 Remove duplicate rows <code>ja distinct</code>"},{"location":"operations/overview/#projection-and-transformation","title":"Projection and Transformation","text":"Operation Symbol Purpose Example project \u03c0 Select/compute columns <code>ja project name,total=price*qty</code> rename \u03c1 Rename fields <code>ja rename old_name=new_name</code>"},{"location":"operations/overview/#set-operations","title":"Set Operations","text":"Operation Symbol Purpose Example union \u222a Combine all rows from relations <code>ja union file1.jsonl file2.jsonl</code> intersection \u2229 Keep only rows in both relations <code>ja intersection file1.jsonl file2.jsonl</code> difference - Keep rows in left but not right <code>ja difference file1.jsonl file2.jsonl</code>"},{"location":"operations/overview/#join-operations","title":"Join Operations","text":"Operation Symbol Purpose Example join \u22c8 Inner join on condition <code>ja join users.jsonl orders.jsonl --on id=user_id</code> product \u00d7 Cartesian product <code>ja product features.jsonl options.jsonl</code>"},{"location":"operations/overview/#grouping-and-aggregation","title":"Grouping and Aggregation","text":"Operation Symbol Purpose Example groupby \u03b3 Group rows (chainable) <code>ja groupby department</code> agg \u03b3 Aggregate data <code>ja agg count,total=sum(amount)</code>"},{"location":"operations/overview/#ordering","title":"Ordering","text":"Operation Symbol Purpose Example sort \u03c4 Sort rows <code>ja sort name,age --desc</code>"},{"location":"operations/overview/#quick-reference","title":"Quick Reference","text":""},{"location":"operations/overview/#selection-filter-rows","title":"Selection (Filter Rows)","text":"<pre><code># Basic filtering\nja select 'age &gt; 30' people.jsonl\n\n# Complex conditions\nja select 'status == \"active\" and score &gt;= 80' users.jsonl\n\n# Nested field filtering\nja select 'user.location.country == \"US\"' data.jsonl\n\n# Using group metadata\nja groupby department data.jsonl | ja select '_group_size &gt; 10'\n</code></pre>"},{"location":"operations/overview/#projection-selecttransform-columns","title":"Projection (Select/Transform Columns)","text":"<pre><code># Select specific fields\nja project name,email people.jsonl\n\n# Compute new fields\nja project name,total=price*quantity orders.jsonl\n\n# Nested field selection\nja project user.name,user.email,order.total data.jsonl\n\n# Flatten nested structures\nja project user.name,user.email --flatten data.jsonl\n</code></pre>"},{"location":"operations/overview/#aggregation","title":"Aggregation","text":"<pre><code># Simple aggregation\nja agg count,total=sum(amount) orders.jsonl\n\n# After grouping\nja groupby department employees.jsonl | ja agg avg_salary=avg(salary)\n\n# Chained grouping\nja groupby region sales.jsonl | ja groupby product | ja agg revenue=sum(amount)\n\n# Conditional aggregation\nja agg shipped=count_if(status==\"shipped\"),total=sum(amount) orders.jsonl\n</code></pre>"},{"location":"operations/overview/#joins","title":"Joins","text":"<pre><code># Inner join\nja join users.jsonl orders.jsonl --on id=user_id\n\n# Join with nested fields\nja join customers.jsonl orders.jsonl --on customer.id=customer_id\n\n# Multiple files in pipeline\ncat orders.jsonl | ja join customers.jsonl --on customer_id=id\n</code></pre>"},{"location":"operations/overview/#set-operations_1","title":"Set Operations","text":"<pre><code># Combine files\nja union current.jsonl historical.jsonl\n\n# Find common records\nja intersection whitelist.jsonl data.jsonl\n\n# Find differences\nja difference all_users.jsonl inactive_users.jsonl\n</code></pre>"},{"location":"operations/overview/#advanced-features","title":"Advanced Features","text":""},{"location":"operations/overview/#nested-data-support","title":"Nested Data Support","text":"<p>All operations support dot notation for nested fields:</p> <pre><code># Works with any level of nesting\nja select 'user.profile.preferences.notifications == true'\nja project user.profile.name,user.profile.email\nja groupby user.location.country\nja join file1.jsonl file2.jsonl --on user.id=customer.id\n</code></pre>"},{"location":"operations/overview/#expression-language","title":"Expression Language","text":"<p>Rich expression support in <code>select</code> and <code>project</code>:</p> <pre><code># Arithmetic\nja project name,annual_salary=monthly_salary*12\n\n# String operations  \nja select 'name.startswith(\"A\")'\n\n# Comparisons\nja select 'created_date &gt; \"2024-01-01\"'\n\n# Logical operations\nja select 'age &gt;= 18 and status == \"active\"'\n</code></pre>"},{"location":"operations/overview/#aggregation-functions","title":"Aggregation Functions","text":"Function Purpose Example <code>count</code> Count rows <code>count</code> <code>sum(field)</code> Sum numeric values <code>sum(amount)</code> <code>avg(field)</code> Average of values <code>avg(score)</code> <code>min(field)</code> Minimum value <code>min(date)</code> <code>max(field)</code> Maximum value <code>max(price)</code> <code>list(field)</code> Collect values in list <code>list(tag)</code> <code>first(field)</code> First value <code>first(name)</code> <code>last(field)</code> Last value <code>last(status)</code>"},{"location":"operations/overview/#conditional-aggregations","title":"Conditional Aggregations","text":"Function Purpose Example <code>count_if(condition)</code> Count matching rows <code>count_if(status==\"paid\")</code> <code>sum_if(field, condition)</code> Sum matching values <code>sum_if(amount, region==\"North\")</code> <code>avg_if(field, condition)</code> Average matching values <code>avg_if(score, active==true)</code>"},{"location":"operations/overview/#composition-examples","title":"Composition Examples","text":""},{"location":"operations/overview/#building-complex-pipelines","title":"Building Complex Pipelines","text":"<pre><code># E-commerce analysis pipeline\ncat orders.jsonl \\\n  | ja select 'status == \"completed\"' \\\n  | ja join products.jsonl --on product_id=id \\\n  | ja join customers.jsonl --on customer_id=id \\\n  | ja project \\\n      customer.name, \\\n      product.category, \\\n      total=quantity*price, \\\n      month=date[0:7] \\\n  | ja groupby customer.tier \\\n  | ja groupby product.category \\\n  | ja agg \\\n      revenue=sum(total), \\\n      orders=count, \\\n      avg_order=avg(total)\n</code></pre>"},{"location":"operations/overview/#data-quality-pipeline","title":"Data Quality Pipeline","text":"<pre><code># Clean and validate data\ncat raw_data.jsonl \\\n  | ja select 'email != null and age &gt; 0' \\\n  | ja project \\\n      name, \\\n      email=email.lower(), \\\n      age, \\\n      valid=email.contains(\"@\") \\\n  | ja select 'valid == true' \\\n  | ja distinct \\\n  | ja sort name\n</code></pre>"},{"location":"operations/overview/#time-series-analysis","title":"Time Series Analysis","text":"<pre><code># Analyze user engagement over time\ncat events.jsonl \\\n  | ja project \\\n      user_id, \\\n      event_type, \\\n      date=timestamp[0:10] \\\n  | ja groupby date \\\n  | ja groupby event_type \\\n  | ja agg \\\n      events=count, \\\n      unique_users=count_distinct(user_id) \\\n  | ja sort date\n</code></pre>"},{"location":"operations/overview/#performance-considerations","title":"Performance Considerations","text":""},{"location":"operations/overview/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Filter Early: Use <code>select</code> before expensive operations</li> <li>Project Only Needed Fields: Reduce data size with <code>project</code></li> <li>Use Direct Aggregation: Use <code>--agg</code> for simple grouping</li> <li>Order Operations: Put most selective filters first</li> </ol> <pre><code># Optimized pipeline\ncat large_file.jsonl \\\n  | ja select 'timestamp &gt; \"2024-01-01\"' \\\n  | ja project user_id,amount,category \\\n  | ja groupby category \\\n  | ja agg total=sum(amount)\n</code></pre>"},{"location":"operations/overview/#memory-efficiency","title":"Memory Efficiency","text":"<p>All operations are streaming by design:</p> <ul> <li>Process arbitrarily large files</li> <li>Constant memory usage (except for operations requiring sorting/grouping)</li> <li>Natural integration with Unix pipes</li> </ul>"},{"location":"operations/overview/#error-handling","title":"Error Handling","text":""},{"location":"operations/overview/#common-issues","title":"Common Issues","text":"<p>Invalid Expressions:</p> <pre><code># Check expression syntax\nja select 'age &gt; thirty'  # Error: 'thirty' not defined\nja select 'age &gt; 30'      # Correct\n</code></pre> <p>Missing Fields:</p> <pre><code># Handle missing fields gracefully\nja select 'field != null'  # Only rows where field exists\n</code></pre> <p>Type Mismatches:</p> <pre><code># Ensure consistent types\nja select 'amount &gt; 0'     # Assumes amount is numeric\n</code></pre>"},{"location":"operations/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Deep Dive: Selection - Advanced filtering techniques</li> <li>Deep Dive: Grouping - Master chained groupby</li> <li>Deep Dive: Joins - Complex join patterns</li> <li>Cookbook - Real-world examples</li> </ul>"},{"location":"shell/introduction/","title":"ja-shell: Interactive JSON Navigator","text":"<p>ja-shell is a revolutionary way to explore JSON and JSONL files - navigate them like a filesystem! Think <code>cd</code>, <code>ls</code>, and <code>cat</code> for your data.</p>"},{"location":"shell/introduction/#what-is-ja-shell","title":"What is ja-shell?","text":"<p>ja-shell creates a virtual filesystem from your JSON data:</p> <ul> <li>JSONL files become directories of records</li> <li>JSON objects become directories of fields</li> <li>Arrays become directories of indexed elements</li> <li>Atomic values (strings, numbers) become files</li> </ul> <p>You can <code>cd</code> into your data, <code>ls</code> to see what's there, and <code>cat</code> to view values - just like navigating directories!</p>"},{"location":"shell/introduction/#why-use-ja-shell","title":"Why Use ja-shell?","text":""},{"location":"shell/introduction/#traditional-approach-jq","title":"Traditional Approach: jq","text":"<pre><code># With jq - requires learning query syntax\ncat users.jsonl | jq '.[0].address.city'\ncat users.jsonl | jq 'map(select(.age &gt; 30))'\n</code></pre>"},{"location":"shell/introduction/#the-ja-shell-way","title":"The ja-shell Way","text":"<pre><code>$ ja-shell\n\nja:/$ cd users.jsonl\nja:/users.jsonl$ cd [0]\nja:/users.jsonl/[0]$ cd address\nja:/users.jsonl/[0]/address$ cat city\nNYC\n\nja:/users.jsonl/[0]/address$ cd /users.jsonl\nja:/users.jsonl$ ls @[age&gt;30]  # Coming soon!\n</code></pre> <p>Result: Natural, filesystem-like navigation with tab completion!</p>"},{"location":"shell/introduction/#key-features","title":"Key Features","text":""},{"location":"shell/introduction/#1-filesystem-abstraction","title":"1. Filesystem Abstraction","text":"<p>Navigate JSON structures intuitively:</p> <pre><code>users.jsonl               \u2192  Directory of records\n  [0]/                    \u2192  First record (directory)\n    name                  \u2192  Field (file): \"Alice\"\n    age                   \u2192  Field (file): 30\n    address/              \u2192  Nested object (directory)\n      city                \u2192  Field (file): \"NYC\"\n      zip                 \u2192  Field (file): \"10001\"\n    tags[]                \u2192  Array (directory)\n      [0]                 \u2192  Element (file): \"admin\"\n      [1]                 \u2192  Element (file): \"premium\"\n</code></pre>"},{"location":"shell/introduction/#2-rich-terminal-ui","title":"2. Rich Terminal UI","text":"<p>Beautiful, color-coded output:</p> <ul> <li>Syntax-highlighted JSON</li> <li>Pretty-printed tables</li> <li>Tree views for structure</li> <li>Icons for file types</li> <li>Progress indicators</li> </ul>"},{"location":"shell/introduction/#3-powerful-shell-features","title":"3. Powerful Shell Features","text":"<p>Everything you expect from a modern shell:</p> <ul> <li>Tab completion - Auto-complete paths and commands</li> <li>Command history - Use arrow keys to recall commands</li> <li>Auto-suggestions - See suggestions as you type</li> <li>Multi-line editing - Edit complex commands easily</li> <li>Vi/Emacs bindings - Use your preferred keybindings</li> </ul>"},{"location":"shell/introduction/#4-performance-optimized","title":"4. Performance Optimized","text":"<ul> <li>Lazy loading - JSONL records loaded on-demand</li> <li>Caching - Recently accessed data stays in memory</li> <li>Streaming - Handle gigabyte files efficiently</li> <li>Incremental parsing - Start exploring immediately</li> </ul>"},{"location":"shell/introduction/#quick-start","title":"Quick Start","text":""},{"location":"shell/introduction/#installation","title":"Installation","text":"<p>ja-shell is included when you install jsonl-algebra:</p> <pre><code>pip install jsonl-algebra\n</code></pre>"},{"location":"shell/introduction/#launch-the-shell","title":"Launch the Shell","text":"<pre><code># Start in current directory\nja-shell\n\n# Start in specific directory\nja-shell ~/data\n\n# Start with a file\nja-shell users.jsonl\n</code></pre>"},{"location":"shell/introduction/#your-first-session","title":"Your First Session","text":"<pre><code>$ ja-shell data/\n\nWelcome to ja-shell!\nNavigate JSON/JSONL files like a filesystem.\nType 'help' for available commands.\n\nja:/$ ls\n\ud83d\udcc1 users.jsonl\n\ud83d\udcc1 orders.jsonl\n\ud83d\udcc1 config.json\n\nja:/$ cd users.jsonl\nja:/users.jsonl$ ls\n\ud83d\udcc1 [0]        {\"id\": 1, \"name\": \"Alice\", ...}\n\ud83d\udcc1 [1]        {\"id\": 2, \"name\": \"Bob\", ...}\n\ud83d\udcc1 [2]        {\"id\": 3, \"name\": \"Charlie\", ...}\n\nja:/users.jsonl$ cd [0]\nja:/users.jsonl/[0]$ ls\n\ud83d\udcc4 id         1\n\ud83d\udcc4 name       Alice\n\ud83d\udcc4 age        30\n\ud83d\udcc4 email      alice@example.com\n\ud83d\udcc1 address/   {\"city\": \"NYC\", \"zip\": \"10001\"}\n\ud83d\udcc1 tags[]     [\"admin\", \"premium\"]\n\nja:/users.jsonl/[0]$ cat name\nAlice\n\nja:/users.jsonl/[0]$ cd address\nja:/users.jsonl/[0]/address$ pwd\n/users.jsonl/[0]/address\n\nja:/users.jsonl/[0]/address$ cat city\nNYC\n\nja:/users.jsonl/[0]/address$ cd ../tags\nja:/users.jsonl/[0]/tags$ ls\n\ud83d\udcc4 [0]        admin\n\ud83d\udcc4 [1]        premium\n\nja:/users.jsonl/[0]/tags$ cd /\nja:/$ tree users.jsonl 2\n\ud83d\udcc1 /users.jsonl\n\u251c\u2500\u2500 \ud83d\udcc1 [0]\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 id\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 name\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 age\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 email\n\u2502   \u251c\u2500\u2500 \ud83d\udcc1 address\n\u2502   \u2514\u2500\u2500 \ud83d\udcc1 tags\n\u251c\u2500\u2500 \ud83d\udcc1 [1]\n\u2502   \u2514\u2500\u2500 ...\n\nja:/$ exit\nGoodbye!\n</code></pre>"},{"location":"shell/introduction/#common-use-cases","title":"Common Use Cases","text":""},{"location":"shell/introduction/#1-exploring-unfamiliar-data","title":"1. Exploring Unfamiliar Data","text":"<p>When you receive JSON data you've never seen before:</p> <pre><code>ja:/$ cd api_response.json\nja:/api_response.json$ tree 2\n# See structure at a glance\n\nja:/api_response.json$ cd data/users/[0]\nja:/api_response.json/data/users/[0]$ ls\n# Discover what fields exist\n</code></pre>"},{"location":"shell/introduction/#2-debugging-api-responses","title":"2. Debugging API Responses","text":"<p>Quickly navigate complex API responses:</p> <pre><code>ja:/$ cd response.json/data/users/[0]/profile\nja:/response.json/data/users/[0]/profile$ cat email\nuser@example.com\n\nja:/response.json/data/users/[0]/profile$ cd ../permissions\nja:/response.json/data/users/[0]/permissions$ ls\n</code></pre>"},{"location":"shell/introduction/#3-configuration-file-inspection","title":"3. Configuration File Inspection","text":"<p>Navigate nested configuration:</p> <pre><code>ja:/$ cd config.json/database/credentials\nja:/config.json/database/credentials$ cat host\nlocalhost\n\nja:/config.json/database/credentials$ cat port\n5432\n</code></pre>"},{"location":"shell/introduction/#4-log-file-analysis","title":"4. Log File Analysis","text":"<p>Explore log entries interactively:</p> <pre><code>ja:/$ cd logs.jsonl\nja:/logs.jsonl$ cd [0]\nja:/logs.jsonl/[0]$ cat level\nERROR\n\nja:/logs.jsonl/[0]$ cat message\nConnection timeout\n\nja:/logs.jsonl/[0]$ cat timestamp\n2025-10-27T10:30:00Z\n</code></pre>"},{"location":"shell/introduction/#available-commands","title":"Available Commands","text":""},{"location":"shell/introduction/#navigation","title":"Navigation","text":"Command Description Example <code>ls [path]</code> List contents <code>ls</code>, <code>ls users.jsonl</code> <code>cd &lt;path&gt;</code> Change directory <code>cd users.jsonl/[0]</code> <code>pwd</code> Show current path <code>pwd</code>"},{"location":"shell/introduction/#viewing-data","title":"Viewing Data","text":"Command Description Example <code>cat &lt;path&gt;</code> Display content <code>cat name</code>, <code>cat [0]</code> <code>tree [path] [depth]</code> Show tree structure <code>tree users.jsonl 2</code> <code>stat &lt;path&gt;</code> Show metadata <code>stat users.jsonl</code>"},{"location":"shell/introduction/#utility","title":"Utility","text":"Command Description Example <code>help</code> Show help <code>help</code> <code>exit</code> / <code>quit</code> Exit shell <code>exit</code>"},{"location":"shell/introduction/#path-syntax","title":"Path Syntax","text":""},{"location":"shell/introduction/#absolute-paths","title":"Absolute Paths","text":"<p>Start with <code>/</code> to navigate from root:</p> <pre><code>/users.jsonl/[0]/address/city\n</code></pre>"},{"location":"shell/introduction/#relative-paths","title":"Relative Paths","text":"<p>Navigate from current location:</p> <pre><code>address/city        # Go into address, then city\n../orders           # Go up one level, then into orders\n</code></pre>"},{"location":"shell/introduction/#special-paths","title":"Special Paths","text":"<ul> <li><code>.</code> - Current directory</li> <li><code>..</code> - Parent directory</li> <li><code>/</code> - Root (physical filesystem root)</li> </ul>"},{"location":"shell/introduction/#jsonl-records","title":"JSONL Records","text":"<p>Access by index in square brackets:</p> <pre><code>[0]     # First record\n[1]     # Second record\n[42]    # 43rd record\n</code></pre>"},{"location":"shell/introduction/#object-keys","title":"Object Keys","text":"<p>Just use the key name:</p> <pre><code>name\naddress\nuser_id\n</code></pre>"},{"location":"shell/introduction/#nested-navigation","title":"Nested Navigation","text":"<p>Use <code>/</code> to go deeper:</p> <pre><code>address/city\nuser/profile/email\ndata/results/[0]/score\n</code></pre>"},{"location":"shell/introduction/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"shell/introduction/#1-tab-completion-is-your-friend","title":"1. Tab Completion is Your Friend","text":"<p>Press Tab to auto-complete:</p> <pre><code>ja:/$ cd us&lt;TAB&gt;\n# Completes to: cd users.jsonl\n\nja:/users.jsonl$ cd [0]/ad&lt;TAB&gt;\n# Completes to: cd [0]/address\n</code></pre>"},{"location":"shell/introduction/#2-use-tree-for-quick-overview","title":"2. Use Tree for Quick Overview","text":"<pre><code>ja:/$ tree users.jsonl 2\n# See structure at a glance without cd-ing around\n</code></pre>"},{"location":"shell/introduction/#3-jump-with-absolute-paths","title":"3. Jump with Absolute Paths","text":"<pre><code>ja:/users.jsonl/[5]/address$ cd /config.json\n# Jump directly instead of cd ../../..\n</code></pre>"},{"location":"shell/introduction/#4-cat-works-on-directories-too","title":"4. Cat Works on Directories Too","text":"<pre><code>ja:/users.jsonl$ cat [0]\n# Shows entire record as pretty JSON\n</code></pre>"},{"location":"shell/introduction/#5-command-history","title":"5. Command History","text":"<ul> <li>Press Up / Down to recall previous commands</li> <li>Press Ctrl+R to search history</li> </ul>"},{"location":"shell/introduction/#comparison-with-other-tools","title":"Comparison with Other Tools","text":"Feature ja-shell jq GUI Viewers Interactive \u2705 \u274c \u2705 Navigation \u2705 Filesystem-like \u274c Query-based \u26a0\ufe0f GUI-only Large JSONL \u2705 Streaming \u26a0\ufe0f Loads all \u274c Memory-bound Learning Curve \ud83d\udfe2 Low (like cd/ls) \ud83d\udd34 High (query syntax) \ud83d\udfe1 Medium Terminal UI \u2705 Rich colors/tables \u26a0\ufe0f Plain text \u2705 GUI Tab Completion \u2705 \u274c N/A Scriptable \u26a0\ufe0f Future feature \u2705 \u274c"},{"location":"shell/introduction/#architecture","title":"Architecture","text":"<p>How ja-shell works under the hood:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  JAShell (UI Layer)             \u2502\n\u2502  - prompt_toolkit input         \u2502\n\u2502  - rich output                  \u2502\n\u2502  - Command handlers             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  JSONPath (VFS Layer)           \u2502\n\u2502  - Path parsing &amp; resolution    \u2502\n\u2502  - Navigation (cd, ls)          \u2502\n\u2502  - Data access (cat, stat)      \u2502\n\u2502  - Lazy JSONL loading           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Storage Layer                  \u2502\n\u2502  - LazyJSONL streaming          \u2502\n\u2502  - File caching                 \u2502\n\u2502  - JSON parsing                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"shell/introduction/#performance","title":"Performance","text":""},{"location":"shell/introduction/#lazy-loading","title":"Lazy Loading","text":"<p>JSONL files are not loaded entirely into memory:</p> <ul> <li>Records loaded on-demand when accessed</li> <li>Recently accessed records cached (LRU cache)</li> <li>Perfect for multi-gigabyte files</li> </ul>"},{"location":"shell/introduction/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Physical files cached after first load</li> <li>JSONL indices built lazily</li> <li>LRU cache for JSONL records (default: 100)</li> </ul>"},{"location":"shell/introduction/#benchmarks","title":"Benchmarks","text":"File Size First Access Cached Access Memory Usage 1 MB ~50ms &lt;1ms ~2 MB 100 MB ~100ms &lt;1ms ~5 MB 1 GB ~200ms &lt;1ms ~10 MB 10 GB ~300ms &lt;1ms ~20 MB <p>Note: Memory usage stays constant regardless of file size!</p>"},{"location":"shell/introduction/#future-features","title":"Future Features","text":""},{"location":"shell/introduction/#query-based-navigation-coming-soon","title":"Query-Based Navigation (Coming Soon)","text":"<p>Filter records as you navigate:</p> <pre><code>ja:/users.jsonl$ cd @[age&gt;30]\nja:/users.jsonl/@[age&gt;30]$ ls\n\ud83d\udcc1 [0]  # Alice (age: 30)\n\ud83d\udcc1 [1]  # Charlie (age: 35)\n</code></pre>"},{"location":"shell/introduction/#write-operations-planned","title":"Write Operations (Planned)","text":"<p>Edit data in-place:</p> <pre><code>ja:/users.jsonl/[0]$ echo \"Bob\" &gt; name\n# Changes Alice's name to Bob\n</code></pre>"},{"location":"shell/introduction/#export-filtered-data-planned","title":"Export Filtered Data (Planned)","text":"<pre><code>ja:/users.jsonl/@[age&gt;30]$ export &gt; filtered.jsonl\n# Save filtered view to file\n</code></pre>"},{"location":"shell/introduction/#fuse-filesystem-future","title":"FUSE Filesystem (Future)","text":"<p>Mount JSON as a real filesystem:</p> <pre><code>ja-mount ~/data /mnt/json\n\n# Now ANY program can access it!\ncd /mnt/json/users.jsonl/[0]/address\ncat city  # Works with standard cat!\nvim name  # Edit with vim!\n</code></pre>"},{"location":"shell/introduction/#limitations","title":"Limitations","text":"<p>Current limitations to be aware of:</p> <ol> <li>Read-only - Can't modify data yet (coming soon)</li> <li>No regex in paths - Can't use wildcards yet</li> <li>Limited filtering - Advanced queries coming soon</li> <li>No scripting - Can't automate commands yet</li> </ol>"},{"location":"shell/introduction/#troubleshooting","title":"Troubleshooting","text":""},{"location":"shell/introduction/#tab-completion-not-working","title":"Tab Completion Not Working","text":"<p>Make sure <code>prompt-toolkit</code> is installed:</p> <pre><code>pip install prompt-toolkit\n</code></pre>"},{"location":"shell/introduction/#colors-look-wrong","title":"Colors Look Wrong","text":"<p>Your terminal may not support true color. Try a modern terminal:</p> <ul> <li>Linux: GNOME Terminal, Konsole, kitty</li> <li>macOS: iTerm2, Alacritty</li> <li>Windows: Windows Terminal, WSL2</li> </ul>"},{"location":"shell/introduction/#cant-navigate-into-jsonl-file","title":"Can't Navigate into .jsonl File","text":"<p>Ensure the file contains valid JSONL (one JSON object per line):</p> <pre><code># Check file format\nhead -1 users.jsonl | python3 -m json.tool\n</code></pre>"},{"location":"shell/introduction/#performance-is-slow","title":"Performance is Slow","text":"<p>For very large files, first access may be slow. Subsequent access is cached and fast.</p>"},{"location":"shell/introduction/#next-steps","title":"Next Steps","text":"<p>Ready to dive in? Continue with:</p> <ul> <li>Tutorial - Step-by-step walkthrough</li> <li>Command Reference - All commands detailed</li> <li>Advanced Features - Power user tips</li> <li>Use Cases - Real-world examples</li> </ul>"},{"location":"shell/introduction/#getting-help","title":"Getting Help","text":"<ul> <li>Type <code>help</code> in the shell</li> <li>Check the FAQ</li> <li>Report issues on GitHub</li> </ul> <p>Try It Now!</p> <p><pre><code>ja-shell\n</code></pre> Start exploring your data immediately!</p>"},{"location":"tools/dataset-generator/","title":"Dataset Generator","text":"<p>The <code>ja-generate-dataset</code> command creates synthetic datasets specifically designed to showcase jsonl-algebra's capabilities. It generates two related JSONL files with realistic nested structures and relationships.</p>"},{"location":"tools/dataset-generator/#quick-start","title":"Quick Start","text":"<pre><code># Install with dataset support\npip install \"jsonl-algebra[dataset]\"\n\n# Generate default dataset (20 companies, 100 people)\nja-generate-dataset\n\n# Generate larger dataset\nja-generate-dataset --num-companies 50 --num-people 1000\n\n# Generate to specific directory\nja-generate-dataset --output-dir examples/\n</code></pre>"},{"location":"tools/dataset-generator/#generated-data-structure","title":"Generated Data Structure","text":""},{"location":"tools/dataset-generator/#companies-companiesjsonl","title":"Companies (<code>companies.jsonl</code>)","text":"<p>Each company record contains:</p> <pre><code>{\n  \"id\": \"uuid-string\",\n  \"name\": \"Company Name Inc\",\n  \"industry\": \"Technology\",\n  \"headquarters\": {\n    \"city\": \"San Francisco\",\n    \"state\": \"CA\", \n    \"country\": \"USA\"\n  },\n  \"size\": 1500,\n  \"founded\": 2010\n}\n</code></pre> <p>Industries: Technology, Healthcare, Finance, Education, Retail, Manufacturing, Consulting, Entertainment, Transportation, Real Estate, Construction, Agriculture, Energy, Media</p>"},{"location":"tools/dataset-generator/#people-peoplejsonl","title":"People (<code>people.jsonl</code>)","text":"<p>Each person record contains:</p> <pre><code>{\n  \"id\": \"uuid-string\",\n  \"created_at\": \"2023-05-15T10:30:00Z\",\n  \"status\": \"active\",\n  \"household_id\": \"shared-uuid-for-family\",\n  \"person\": {\n    \"name\": {\n      \"first\": \"Sarah\",\n      \"last\": \"Johnson\"\n    },\n    \"age\": 32,\n    \"gender\": \"female\",\n    \"email\": \"sarah.johnson@gmail.com\",\n    \"phone\": \"555-123-4567\",\n    \"location\": {\n      \"city\": \"San Francisco\",\n      \"state\": \"CA\",\n      \"country\": \"USA\"\n    },\n    \"interests\": [\"hiking\", \"photography\", \"cooking\"],\n    \"job\": {\n      \"title\": \"Software Engineer\", \n      \"company_name\": \"Tech Solutions Inc\",\n      \"salary\": 95000.0\n    }\n  }\n}\n</code></pre> <p>Key Features:</p> <ul> <li>Household relationships: People sharing <code>household_id</code> have the same last name and location</li> <li>Employment relationships: <code>person.job.company_name</code> links to company <code>name</code> field</li> <li>Nested structures: Rich nested JSON perfect for testing ja's navigation capabilities</li> <li>Realistic distributions: Age, gender, salary, and location follow realistic patterns</li> </ul>"},{"location":"tools/dataset-generator/#command-line-options","title":"Command Line Options","text":"<pre><code>ja-generate-dataset [OPTIONS]\n\nData Generation:\n  --num-companies N        Number of companies (default: 20)\n  --num-people N          Number of people (default: 100)  \n  --max-household-size N  Max people per household (default: 5)\n\nRandomness Control:\n  --deterministic         Use fixed seed for reproducible data (default)\n  --random               Use random seed for varied output\n  --seed N               Custom seed for deterministic mode (default: 42)\n\nOutput Control:\n  --output-dir PATH       Output directory (default: current directory)\n  --companies-file PATH   Custom companies file path\n  --people-file PATH      Custom people file path\n</code></pre>"},{"location":"tools/dataset-generator/#example-workflows","title":"Example Workflows","text":""},{"location":"tools/dataset-generator/#basic-exploration","title":"Basic Exploration","text":"<pre><code># Generate sample data\nja-generate-dataset --num-companies 10 --num-people 50\n\n# Explore the data\nja people.jsonl --head 3 --pretty\nja companies.jsonl --select name,industry,size --head 5\n\n# Count people by company\nja people.jsonl --group-by person.job.company_name --count\n</code></pre>"},{"location":"tools/dataset-generator/#nested-data-operations","title":"Nested Data Operations","text":"<pre><code># Extract names and ages\nja people.jsonl --select person.name,person.age\n\n# Filter by age and location  \nja people.jsonl --where 'person.age &gt; 30' --select person.name,person.location.state\n\n# Group by nested fields\nja people.jsonl --group-by person.location.state,person.gender --count\n</code></pre>"},{"location":"tools/dataset-generator/#relational-operations","title":"Relational Operations","text":"<pre><code># Join people with their companies\nja people.jsonl --join companies.jsonl --on 'person.job.company_name = name' \\\\\n  --select person.name,name,industry,person.job.salary\n\n# Find high earners in tech companies\nja people.jsonl --join companies.jsonl --on 'person.job.company_name = name' \\\\\n  --where 'industry = \"Technology\" and person.job.salary &gt; 100000' \\\\\n  --select person.name,name,person.job.salary\n</code></pre>"},{"location":"tools/dataset-generator/#aggregation-examples","title":"Aggregation Examples","text":"<pre><code># Average salary by industry\nja people.jsonl --join companies.jsonl --on 'person.job.company_name = name' \\\\\n  --group-by industry --agg 'avg(person.job.salary)'\n\n# Company size distribution\nja companies.jsonl --group-by industry --agg 'avg(size),count(*)'\n\n# Household statistics\nja people.jsonl --group-by household_id --agg 'count(*),avg(person.age)' \\\\\n  --select '*,_count as household_size,_avg_person_age as avg_age'\n</code></pre>"},{"location":"tools/dataset-generator/#testing-and-development","title":"Testing and Development","text":"<p>The dataset generator is designed for both documentation examples and unit testing:</p>"},{"location":"tools/dataset-generator/#deterministic-mode-default","title":"Deterministic Mode (Default)","text":"<ul> <li>Always produces the same output for given parameters</li> <li>Perfect for examples, documentation, and reproducible tests</li> <li>Uses seed 42 by default</li> </ul>"},{"location":"tools/dataset-generator/#random-mode","title":"Random Mode","text":"<ul> <li>Generates varied data for stress testing</li> <li>Useful for property-based testing</li> <li>Each run produces different realistic data</li> </ul>"},{"location":"tools/dataset-generator/#usage-in-tests","title":"Usage in Tests","text":"<pre><code># In test files\nimport subprocess\nimport tempfile\nimport os\n\ndef setup_test_data():\n    \\\"\\\"\\\"Generate deterministic test data.\\\"\\\"\\\"\n    with tempfile.TemporaryDirectory() as tmpdir:\n        subprocess.run([\n            \"python\", \"scripts/generate_dataset.py\",\n            \"--deterministic\", \"--seed\", \"123\",\n            \"--num-companies\", \"5\", \"--num-people\", \"25\", \n            \"--output-dir\", tmpdir\n        ])\n        return os.path.join(tmpdir, \"people.jsonl\"), os.path.join(tmpdir, \"companies.jsonl\")\n</code></pre>"},{"location":"tools/dataset-generator/#data-relationships","title":"Data Relationships","text":"<p>The generated datasets are designed to demonstrate common data patterns:</p> <pre><code>Companies (1) \u2192 (N) People\n  company.name = person.job.company_name\n\nHouseholds (1) \u2192 (N) People  \n  household_id groups people with shared:\n  - person.name.last (family name)\n  - person.location (shared address)\n\nGeographic Hierarchy:\n  Country \u2192 State \u2192 City\n  All records use USA with realistic state/city combinations\n</code></pre>"},{"location":"tools/dataset-generator/#dependencies","title":"Dependencies","text":"<ul> <li>Core: Works with Python standard library only</li> <li>Enhanced: Install <code>faker</code> for richer company names and data variety</li> </ul> <pre><code>pip install \"jsonl-algebra[dataset]\"  # Includes faker\n</code></pre> <p>Without faker, the generator uses built-in data pools that still produce realistic, varied output.</p>"},{"location":"tools/dataset-generator/#tips","title":"Tips","text":"<ol> <li>Start small: Use <code>--num-people 20 --num-companies 5</code> for initial exploration</li> <li>Use deterministic mode: For examples and tests where consistency matters  </li> <li>Scale gradually: Large datasets (10K+ records) are great for performance testing</li> <li>Combine with ja: The suggested commands in the output are a great starting point</li> <li>Explore relationships: Use joins to see how nested structures connect across files</li> </ol> <p>The generated data is specifically crafted to showcase ja's strengths in handling real-world nested JSON data patterns.</p>"},{"location":"tutorials/data-analysis/","title":"Tutorial: Analyzing Log Files","text":"<p>Learn how to use jsonl-algebra to analyze log files, extract insights, and identify issues. This tutorial walks through a real-world scenario: analyzing web server access logs.</p> <p>Time required: 15-20 minutes</p> <p>What you'll learn:</p> <ul> <li>Parsing and filtering log data</li> <li>Calculating statistics and trends</li> <li>Identifying errors and anomalies</li> <li>Creating reports from logs</li> <li>Building monitoring dashboards</li> </ul>"},{"location":"tutorials/data-analysis/#scenario","title":"Scenario","text":"<p>You're analyzing access logs from a web application. The logs are in JSONL format with this structure:</p> <pre><code>{\"timestamp\": \"2025-10-27T10:15:30Z\", \"method\": \"GET\", \"path\": \"/api/users\", \"status\": 200, \"duration_ms\": 45, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:15:31Z\", \"method\": \"POST\", \"path\": \"/api/orders\", \"status\": 201, \"duration_ms\": 120, \"user_id\": 1002, \"ip\": \"192.168.1.101\"}\n{\"timestamp\": \"2025-10-27T10:15:32Z\", \"method\": \"GET\", \"path\": \"/api/products\", \"status\": 500, \"duration_ms\": 5000, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n</code></pre>"},{"location":"tutorials/data-analysis/#setup-create-sample-data","title":"Setup: Create Sample Data","text":"<p>First, let's create a realistic sample log file:</p> <pre><code>cat &gt; access_logs.jsonl &lt;&lt; 'EOF'\n{\"timestamp\": \"2025-10-27T10:00:00Z\", \"method\": \"GET\", \"path\": \"/api/users\", \"status\": 200, \"duration_ms\": 45, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:00:05Z\", \"method\": \"POST\", \"path\": \"/api/orders\", \"status\": 201, \"duration_ms\": 120, \"user_id\": 1002, \"ip\": \"192.168.1.101\"}\n{\"timestamp\": \"2025-10-27T10:00:10Z\", \"method\": \"GET\", \"path\": \"/api/products\", \"status\": 500, \"duration_ms\": 5000, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:00:15Z\", \"method\": \"GET\", \"path\": \"/api/users/1001\", \"status\": 200, \"duration_ms\": 30, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:00:20Z\", \"method\": \"DELETE\", \"path\": \"/api/orders/500\", \"status\": 404, \"duration_ms\": 20, \"user_id\": 1003, \"ip\": \"192.168.1.102\"}\n{\"timestamp\": \"2025-10-27T10:00:25Z\", \"method\": \"GET\", \"path\": \"/api/products\", \"status\": 200, \"duration_ms\": 55, \"user_id\": 1002, \"ip\": \"192.168.1.101\"}\n{\"timestamp\": \"2025-10-27T10:00:30Z\", \"method\": \"POST\", \"path\": \"/api/users\", \"status\": 400, \"duration_ms\": 15, \"user_id\": null, \"ip\": \"192.168.1.103\"}\n{\"timestamp\": \"2025-10-27T10:00:35Z\", \"method\": \"GET\", \"path\": \"/api/orders\", \"status\": 200, \"duration_ms\": 80, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:00:40Z\", \"method\": \"PUT\", \"path\": \"/api/users/1002\", \"status\": 500, \"duration_ms\": 3000, \"user_id\": 1002, \"ip\": \"192.168.1.101\"}\n{\"timestamp\": \"2025-10-27T10:00:45Z\", \"method\": \"GET\", \"path\": \"/api/products/search\", \"status\": 200, \"duration_ms\": 150, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:00:50Z\", \"method\": \"POST\", \"path\": \"/api/orders\", \"status\": 201, \"duration_ms\": 95, \"user_id\": 1003, \"ip\": \"192.168.1.102\"}\n{\"timestamp\": \"2025-10-27T10:00:55Z\", \"method\": \"GET\", \"path\": \"/api/users\", \"status\": 200, \"duration_ms\": 40, \"user_id\": 1002, \"ip\": \"192.168.1.101\"}\n{\"timestamp\": \"2025-10-27T10:01:00Z\", \"method\": \"GET\", \"path\": \"/api/products/123\", \"status\": 404, \"duration_ms\": 25, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\n{\"timestamp\": \"2025-10-27T10:01:05Z\", \"method\": \"POST\", \"path\": \"/api/auth/login\", \"status\": 401, \"duration_ms\": 10, \"user_id\": null, \"ip\": \"192.168.1.104\"}\n{\"timestamp\": \"2025-10-27T10:01:10Z\", \"method\": \"GET\", \"path\": \"/api/orders/1001\", \"status\": 200, \"duration_ms\": 60, \"user_id\": 1001, \"ip\": \"192.168.1.100\"}\nEOF\n</code></pre>"},{"location":"tutorials/data-analysis/#task-1-find-all-errors","title":"Task 1: Find All Errors","text":"<p>Let's identify all error responses (status &gt;= 400):</p> <pre><code>ja select 'status &gt;= 400' access_logs.jsonl\n</code></pre> <p>Output: <pre><code>{\"timestamp\": \"2025-10-27T10:00:10Z\", \"method\": \"GET\", \"path\": \"/api/products\", \"status\": 500, ...}\n{\"timestamp\": \"2025-10-27T10:00:20Z\", \"method\": \"DELETE\", \"path\": \"/api/orders/500\", \"status\": 404, ...}\n{\"timestamp\": \"2025-10-27T10:00:30Z\", \"method\": \"POST\", \"path\": \"/api/users\", \"status\": 400, ...}\n{\"timestamp\": \"2025-10-27T10:00:40Z\", \"method\": \"PUT\", \"path\": \"/api/users/1002\", \"status\": 500, ...}\n{\"timestamp\": \"2025-10-27T10:01:00Z\", \"method\": \"GET\", \"path\": \"/api/products/123\", \"status\": 404, ...}\n{\"timestamp\": \"2025-10-27T10:01:05Z\", \"method\": \"POST\", \"path\": \"/api/auth/login\", \"status\": 401, ...}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#save-errors-to-file","title":"Save Errors to File","text":"<pre><code>ja select 'status &gt;= 400' access_logs.jsonl &gt; errors.jsonl\n</code></pre>"},{"location":"tutorials/data-analysis/#count-error-types","title":"Count Error Types","text":"<pre><code>ja select 'status &gt;= 400' access_logs.jsonl \\\n  | ja groupby status --agg count \\\n  | ja sort count --desc\n</code></pre> <p>Output: <pre><code>{\"status\": 404, \"count\": 2}\n{\"status\": 500, \"count\": 2}\n{\"status\": 400, \"count\": 1}\n{\"status\": 401, \"count\": 1}\n</code></pre></p> <p>HTTP Status Categories</p> <ul> <li>400-499: Client errors (bad requests, auth failures)</li> <li>500-599: Server errors (application crashes, timeouts)</li> </ul>"},{"location":"tutorials/data-analysis/#task-2-identify-slow-requests","title":"Task 2: Identify Slow Requests","text":"<p>Find requests that took longer than 1 second (1000ms):</p> <pre><code>ja select 'duration_ms &gt; 1000' access_logs.jsonl \\\n  | ja project timestamp,method,path,duration_ms \\\n  | ja sort duration_ms --desc\n</code></pre> <p>Output: <pre><code>{\"timestamp\": \"2025-10-27T10:00:10Z\", \"method\": \"GET\", \"path\": \"/api/products\", \"duration_ms\": 5000}\n{\"timestamp\": \"2025-10-27T10:00:40Z\", \"method\": \"PUT\", \"path\": \"/api/users/1002\", \"duration_ms\": 3000}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#calculate-performance-statistics","title":"Calculate Performance Statistics","text":"<pre><code>ja groupby path --agg count,avg_ms=avg:duration_ms,max_ms=max:duration_ms access_logs.jsonl \\\n  | ja sort avg_ms --desc\n</code></pre> <p>Output: <pre><code>{\"path\": \"/api/products\", \"count\": 3, \"avg_ms\": 1683.33, \"max_ms\": 5000}\n{\"path\": \"/api/orders\", \"count\": 3, \"avg_ms\": 98.33, \"max_ms\": 120}\n{\"path\": \"/api/products/search\", \"count\": 1, \"avg_ms\": 150.0, \"max_ms\": 150}\n...\n</code></pre></p>"},{"location":"tutorials/data-analysis/#task-3-analyze-request-patterns","title":"Task 3: Analyze Request Patterns","text":""},{"location":"tutorials/data-analysis/#requests-by-http-method","title":"Requests by HTTP Method","text":"<pre><code>ja groupby method --agg count access_logs.jsonl \\\n  | ja sort count --desc\n</code></pre> <p>Output: <pre><code>{\"method\": \"GET\", \"count\": 9}\n{\"method\": \"POST\", \"count\": 4}\n{\"method\": \"PUT\", \"count\": 1}\n{\"method\": \"DELETE\", \"count\": 1}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#requests-by-endpoint","title":"Requests by Endpoint","text":"<pre><code>ja groupby path --agg count access_logs.jsonl \\\n  | ja sort count --desc \\\n  | head -5\n</code></pre> <p>Output: <pre><code>{\"path\": \"/api/products\", \"count\": 2}\n{\"path\": \"/api/users\", \"count\": 2}\n{\"path\": \"/api/orders\", \"count\": 2}\n...\n</code></pre></p>"},{"location":"tutorials/data-analysis/#success-rate-by-endpoint","title":"Success Rate by Endpoint","text":"<pre><code>ja groupby path --agg total=count,errors=\"count:status &gt;= 400\" access_logs.jsonl\n</code></pre>"},{"location":"tutorials/data-analysis/#task-4-user-activity-analysis","title":"Task 4: User Activity Analysis","text":""},{"location":"tutorials/data-analysis/#most-active-users","title":"Most Active Users","text":"<pre><code>ja select 'user_id != null' access_logs.jsonl \\\n  | ja groupby user_id --agg requests=count \\\n  | ja sort requests --desc\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1001, \"requests\": 7}\n{\"user_id\": 1002, \"requests\": 4}\n{\"user_id\": 1003, \"requests\": 2}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#user-error-analysis","title":"User Error Analysis","text":"<p>Find users experiencing the most errors:</p> <pre><code>ja select 'status &gt;= 400 and user_id != null' access_logs.jsonl \\\n  | ja groupby user_id --agg errors=count \\\n  | ja sort errors --desc\n</code></pre> <p>Output: <pre><code>{\"user_id\": 1001, \"errors\": 2}\n{\"user_id\": 1002, \"errors\": 1}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#task-5-create-a-summary-report","title":"Task 5: Create a Summary Report","text":"<p>Combine multiple analyses into a comprehensive report:</p> <pre><code>#!/bin/bash\n# log_report.sh\n\nLOG_FILE=\"access_logs.jsonl\"\n\necho \"=== Log Analysis Report ===\"\necho\n\necho \"Total Requests:\"\nwc -l &lt; \"$LOG_FILE\"\necho\n\necho \"Error Summary:\"\nja select 'status &gt;= 400' \"$LOG_FILE\" \\\n  | ja groupby status --agg count \\\n  | ja sort count --desc\n\necho\necho \"Top 5 Endpoints by Request Count:\"\nja groupby path --agg count \"$LOG_FILE\" \\\n  | ja sort count --desc \\\n  | head -5\n\necho\necho \"Slowest Endpoints (avg response time):\"\nja groupby path --agg avg_ms=avg:duration_ms \"$LOG_FILE\" \\\n  | ja sort avg_ms --desc \\\n  | head -5\n\necho\necho \"Most Active Users:\"\nja select 'user_id != null' \"$LOG_FILE\" \\\n  | ja groupby user_id --agg count \\\n  | ja sort count --desc \\\n  | head -5\n</code></pre> <p>Make it executable and run:</p> <pre><code>chmod +x log_report.sh\n./log_report.sh\n</code></pre>"},{"location":"tutorials/data-analysis/#task-6-time-based-analysis","title":"Task 6: Time-based Analysis","text":""},{"location":"tutorials/data-analysis/#extract-hour-from-timestamp","title":"Extract Hour from Timestamp","text":"<p>To analyze patterns by hour, we'll use a technique with <code>ja</code> expressions:</p> <pre><code># For more complex time parsing, use the data explorer or a preprocessing step\n# For now, let's group by full timestamp prefix\n\nja project timestamp,path,status access_logs.jsonl | head -5\n</code></pre>"},{"location":"tutorials/data-analysis/#peak-usage-times","title":"Peak Usage Times","text":"<p>For a real-world scenario, you'd parse timestamps. Here's a conceptual approach:</p> <pre><code># preprocess.py - Add hour field\nimport json\nfrom datetime import datetime\n\nwith open('access_logs.jsonl') as f:\n    for line in f:\n        record = json.loads(line)\n        dt = datetime.fromisoformat(record['timestamp'].replace('Z', '+00:00'))\n        record['hour'] = dt.hour\n        print(json.dumps(record))\n</code></pre> <p>Then analyze:</p> <pre><code>python preprocess.py | ja groupby hour --agg requests=count \\\n  | ja sort hour\n</code></pre>"},{"location":"tutorials/data-analysis/#task-7-alerting-on-anomalies","title":"Task 7: Alerting on Anomalies","text":""},{"location":"tutorials/data-analysis/#high-error-rate-detection","title":"High Error Rate Detection","text":"<pre><code># Find endpoints with &gt;50% error rate\nja groupby path \\\n  --agg total=count,\"errors=count:status &gt;= 400\" \\\n  access_logs.jsonl \\\n  | ja select 'errors * 2 &gt; total'  # More than 50% errors\n</code></pre>"},{"location":"tutorials/data-analysis/#performance-degradation","title":"Performance Degradation","text":"<pre><code># Endpoints averaging &gt;500ms\nja groupby path --agg avg_ms=avg:duration_ms access_logs.jsonl \\\n  | ja select 'avg_ms &gt; 500'\n</code></pre> <p>Output: <pre><code>{\"path\": \"/api/products\", \"avg_ms\": 1683.33}\n{\"path\": \"/api/users/1002\", \"avg_ms\": 3000.0}\n</code></pre></p>"},{"location":"tutorials/data-analysis/#task-8-multi-file-analysis","title":"Task 8: Multi-File Analysis","text":"<p>If logs are split across multiple files:</p> <pre><code># Combine all log files\nja union logs_morning.jsonl logs_afternoon.jsonl logs_evening.jsonl \\\n  &gt; full_day_logs.jsonl\n\n# Or analyze directly\nja union logs_*.jsonl \\\n  | ja select 'status &gt;= 500' \\\n  | ja groupby path --agg count\n</code></pre>"},{"location":"tutorials/data-analysis/#task-9-export-for-visualization","title":"Task 9: Export for Visualization","text":""},{"location":"tutorials/data-analysis/#create-csv-for-spreadsheet-analysis","title":"Create CSV for Spreadsheet Analysis","text":"<pre><code>ja groupby path --agg count,avg_ms=avg:duration_ms,errors=\"count:status &gt;= 400\" access_logs.jsonl \\\n  | ja export csv &gt; endpoint_stats.csv\n</code></pre> <p>Open <code>endpoint_stats.csv</code> in Excel, Google Sheets, or similar.</p>"},{"location":"tutorials/data-analysis/#create-json-for-dashboard","title":"Create JSON for Dashboard","text":"<pre><code>ja groupby path --agg count,avg_ms=avg:duration_ms access_logs.jsonl \\\n  | ja export json &gt; dashboard_data.json\n</code></pre>"},{"location":"tutorials/data-analysis/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"tutorials/data-analysis/#pattern-1-funnel-analysis","title":"Pattern 1: Funnel Analysis","text":"<p>Track user journey through endpoints:</p> <pre><code># Users who hit products endpoint\nja select 'path == \"/api/products\"' access_logs.jsonl \\\n  | ja project user_id \\\n  | ja distinct &gt; viewed_products.jsonl\n\n# Of those, who placed orders?\nja join viewed_products.jsonl access_logs.jsonl --on user_id=user_id \\\n  | ja select 'path == \"/api/orders\" and method == \"POST\"' \\\n  | ja project user_id \\\n  | ja distinct\n</code></pre>"},{"location":"tutorials/data-analysis/#pattern-2-session-reconstruction","title":"Pattern 2: Session Reconstruction","text":"<p>Group requests by user to reconstruct sessions:</p> <pre><code>ja select 'user_id != null' access_logs.jsonl \\\n  | ja sort user_id,timestamp \\\n  | ja groupby user_id --agg requests=count,paths=list:path\n</code></pre>"},{"location":"tutorials/data-analysis/#pattern-3-correlation-analysis","title":"Pattern 3: Correlation Analysis","text":"<p>Find endpoints often accessed together:</p> <pre><code># First endpoint per user\nja select 'user_id != null' access_logs.jsonl \\\n  | ja sort user_id,timestamp \\\n  | ja groupby user_id \\\n  # Take first path per user (would need custom aggregation)\n</code></pre>"},{"location":"tutorials/data-analysis/#real-world-integration","title":"Real-World Integration","text":""},{"location":"tutorials/data-analysis/#with-monitoring-tools","title":"With Monitoring Tools","text":"<pre><code># Continuous monitoring\ntail -f /var/log/app/access.log \\\n  | ja select 'status &gt;= 500' \\\n  | ja project timestamp,path,status,duration_ms \\\n  &gt; critical_errors.jsonl &amp;\n\n# Alert when threshold reached\nwatch -n 60 'ja select \"status &gt;= 500\" critical_errors.jsonl | wc -l'\n</code></pre>"},{"location":"tutorials/data-analysis/#with-log-aggregation","title":"With Log Aggregation","text":"<pre><code># Process logs from multiple servers\nfor server in web{1..5}; do\n  scp $server:/var/log/app/access.log ${server}_access.jsonl\ndone\n\nja union *_access.jsonl \\\n  | ja groupby server_hostname --agg errors=\"count:status &gt;= 500\"\n</code></pre>"},{"location":"tutorials/data-analysis/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Filter Early - Reduce data size before expensive operations    <pre><code># Good\nja select 'status &gt;= 400' huge.jsonl | ja groupby path\n\n# Bad\nja groupby path huge.jsonl | ja select 'count &gt; 10'\n</code></pre></p> </li> <li> <p>Save Intermediate Results - For complex analyses    <pre><code>ja select 'status &gt;= 400' logs.jsonl &gt; errors.jsonl\nja groupby path --agg count errors.jsonl\nja groupby user_id --agg count errors.jsonl\n</code></pre></p> </li> <li> <p>Use Scripts for Reports - Automate repetitive analysis</p> </li> <li>Timestamp Preprocessing - Add derived time fields early</li> <li>Monitor Performance - Keep an eye on query execution time</li> </ol>"},{"location":"tutorials/data-analysis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/data-analysis/#issue-memory-errors-with-large-logs","title":"Issue: Memory errors with large logs","text":"<p>Solution: Filter or sample first <pre><code>ja select 'status &gt;= 400' huge_logs.jsonl | ja groupby path\n# Or\nhead -100000 huge_logs.jsonl | ja groupby path\n</code></pre></p>"},{"location":"tutorials/data-analysis/#issue-inconsistent-timestamps","title":"Issue: Inconsistent timestamps","text":"<p>Solution: Normalize in preprocessing <pre><code># normalize_timestamps.py\nimport json\nfrom dateutil import parser\n\nfor line in sys.stdin:\n    record = json.loads(line)\n    record['timestamp'] = parser.parse(record['timestamp']).isoformat()\n    print(json.dumps(record))\n</code></pre></p>"},{"location":"tutorials/data-analysis/#summary","title":"Summary","text":"<p>You've learned how to:</p> <ul> <li>\u2705 Filter logs for errors and anomalies</li> <li>\u2705 Calculate performance statistics</li> <li>\u2705 Analyze request patterns</li> <li>\u2705 Track user activity</li> <li>\u2705 Create summary reports</li> <li>\u2705 Detect performance issues</li> <li>\u2705 Export data for visualization</li> </ul>"},{"location":"tutorials/data-analysis/#next-steps","title":"Next Steps","text":"<ul> <li>Real-time Monitoring Tutorial - Set up live monitoring</li> <li>ETL Pipeline Tutorial - Build data pipelines</li> <li>Log Analyzer Integration - Use the built-in tool</li> <li>Data Quality Tutorial - Validate and clean data</li> </ul>"},{"location":"tutorials/data-analysis/#practice-exercises","title":"Practice Exercises","text":"<p>Try these on your own logs:</p> <ol> <li>Find the endpoint with the highest error rate</li> <li>Identify the slowest hour of the day</li> <li>Calculate 95<sup>th</sup> percentile response time per endpoint</li> <li>Find users with the most failed authentication attempts</li> <li>Create an automated daily summary report</li> </ol> <p>Well Done!</p> <p>You can now analyze logs like a pro with jsonl-algebra!</p>"}]}
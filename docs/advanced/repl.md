# Interactive REPL Guide

The `ja` REPL (Read-Eval-Print Loop) provides an interactive environment for building data pipelines step-by-step. It's perfect for data exploration, prototyping complex queries, and learning the tool.

## Getting Started

Launch the REPL:

```bash
ja repl
```

You'll see:

```
Welcome to ja REPL! ðŸš€ Type 'help' for commands, 'exit' to quit.
ja>
```

## Basic Commands

### Setting Data Source

```bash
ja> from orders.jsonl
Input source set to: orders.jsonl

ja> from stdin
Input source set to: stdin
```

### Building a Pipeline

```bash
ja> from orders.jsonl
ja> select status == "shipped"
Added: select status == "shipped"
ja> groupby customer
Added: groupby customer
ja> agg total=sum(amount)
Added: agg total=sum(amount)
```

### Viewing the Pipeline

```bash
ja> pipeline
Current pipeline:
  Input: orders.jsonl
  1. select status == "shipped"
  2. groupby customer
  3. agg total=sum(amount)
```

### Executing the Pipeline

```bash
ja> execute
Executing: ja select 'status == "shipped"' orders.jsonl | ja groupby customer - | ja agg total=sum(amount) -

--- Output ---
{"customer": "Alice", "total": 179.98}
{"customer": "Charlie", "total": 199.99}
--------------
```

## Advanced Features

### No Quotes Required

Unlike the command line, expressions don't need quotes in the REPL:

```bash
# Command line
ja select 'age > 30 and status == "active"' users.jsonl

# REPL
ja> select age > 30 and status == "active"
```

### Limited Output

View just a few lines while building your pipeline:

```bash
ja> execute --lines=5
```

### Generate Scripts

See the equivalent bash script:

```bash
ja> compile

--- Compiled Bash Script ---
#!/bin/bash
# Generated by ja REPL
ja select 'status == "shipped"' orders.jsonl | \
  ja groupby customer - | \
  ja agg 'total=sum(amount)' -
--------------------------
```

### Reset Pipeline

Start over:

```bash
ja> reset
Pipeline reset.
```

## Data Exploration Workflow

### 1. Start with Data Inspection

```bash
ja> from large_dataset.jsonl
ja> execute --lines=3
# See the structure and sample data
```

### 2. Build Filters Incrementally

```bash
ja> select timestamp > "2024-01-01"
ja> execute --lines=5
# Check the filtering is working

ja> select amount > 100
ja> execute --lines=5
# Add another filter and verify
```

### 3. Add Transformations

```bash
ja> project customer,amount,month=timestamp[0:7]
ja> execute --lines=5
# See the transformed data
```

### 4. Group and Aggregate

```bash
ja> groupby month
ja> execute --lines=10
# Inspect the grouping

ja> groupby customer
ja> execute --lines=10
# Add second level grouping

ja> agg revenue=sum(amount),orders=count
ja> execute
# Final aggregation
```

## Complex Query Building

### Multi-Join Analysis

```bash
ja> from orders.jsonl
ja> join customers.jsonl --on customer_id=id
ja> execute --lines=3
# Check the join worked

ja> join products.jsonl --on product_id=id  
ja> execute --lines=3
# Add second join

ja> select order_date > "2024-01-01"
ja> project customer.name,product.category,total=quantity*price
ja> groupby customer.tier
ja> groupby product.category
ja> agg revenue=sum(total),orders=count
ja> execute
```

### Time Series Analysis

```bash
ja> from events.jsonl
ja> project timestamp,user_id,event_type,date=timestamp[0:10]
ja> execute --lines=5

ja> groupby date
ja> execute --lines=10
# Check daily grouping

ja> groupby event_type
ja> agg events=count,unique_users=count_distinct(user_id)
ja> sort date,event_type
ja> execute
```

## Debugging and Troubleshooting

### Check Each Step

```bash
ja> from data.jsonl
ja> select complicated_condition
ja> execute --lines=1
# Is anything matching?

ja> pipeline
# Review the steps so far

ja> reset
# Start over if needed
```

### Inspect Intermediate Results

```bash
ja> groupby category
ja> execute --lines=5
# See the grouping metadata

ja> select _group_size > 10
ja> execute --lines=5
# Filter based on group size
```

### Common Issues

**No Output After Filtering**:

```bash
ja> from data.jsonl
ja> execute --lines=5
# Check source data

ja> select some_condition
ja> execute --lines=5
# See if filter is too restrictive
```

**Unexpected Grouping**:

```bash
ja> groupby field
ja> project field,_groups,_group_size
ja> execute --lines=10
# Inspect the grouping structure
```

## REPL-Specific Features

### Smart Expression Parsing

The REPL intelligently parses expressions:

```bash
# These all work without quotes
ja> select age > 30
ja> select status == "active" and score >= 80
ja> project name,total=price*quantity
ja> agg revenue=sum(amount),count
```

### Command History

Use arrow keys to navigate command history:

- â†‘/â†“: Previous/next command
- Ctrl+C: Interrupt current command (continues REPL)
- Ctrl+D or `exit`: Exit REPL

### Auto-completion

The REPL provides context-aware suggestions for:

- Command names
- Field names (when available)
- Common aggregation functions

## Scripting from REPL

### Save Pipelines

Generate scripts for reuse:

```bash
ja> from orders.jsonl
ja> select status == "shipped"
ja> groupby customer
ja> agg total=sum(amount)
ja> compile > analysis_script.sh
```

### Parameterized Queries

Build templates:

```bash
# In the REPL, build your pipeline
ja> from data.jsonl
ja> select 'date >= "$START_DATE"'
ja> groupby category  
ja> agg total=sum(amount)
ja> compile

# Then edit the generated script to use variables
```

## Best Practices

### 1. Start Small

```bash
ja> from large_file.jsonl
ja> execute --lines=5
# Always check a sample first
```

### 2. Build Incrementally

```bash
# Add operations one at a time
ja> select condition1
ja> execute --lines=5
ja> select condition2  
ja> execute --lines=5
ja> groupby field
ja> execute --lines=10
```

### 3. Use the Pipeline View

```bash
ja> pipeline
# Regular check of what you've built
```

### 4. Save Complex Queries

```bash
ja> compile > my_analysis.sh
# Don't lose complex work
```

### 5. Explore Before Committing

```bash
# Try different approaches
ja> groupby customer
ja> execute --lines=5
ja> reset
ja> groupby product  
ja> execute --lines=5
# Compare different groupings
```

## Integration with External Tools

### Pipe to External Commands

```bash
ja> execute | jq '.[] | select(.revenue > 1000)'
ja> execute | head -20
ja> execute | sort -n
```

### Export Results

```bash
ja> execute > results.jsonl
ja> compile > analysis.sh
```

## Help and Documentation

### In-REPL Help

```bash
ja> help
# Comprehensive help with examples

ja> help select
# Command-specific help (if available)
```

### Examples and Tips

The REPL help includes:

- Command examples
- Expression syntax
- Aggregation functions
- Common patterns
- Troubleshooting tips

## Advanced Workflows

### Data Quality Exploration

```bash
ja> from messy_data.jsonl
ja> project name,email,age
ja> execute --lines=10
# See what fields look like

ja> agg count,nulls=count_if(email==null),invalids=count_if(!email.contains("@"))
ja> execute
# Check data quality

ja> select email != null and email.contains("@") and age > 0
ja> execute --lines=5
# Clean data step by step
```

### Schema Discovery

```bash
ja> from unknown_data.jsonl
ja> execute --lines=1
# See the structure

ja> project _keys=keys(.)
ja> execute --lines=10
# See all field names

ja> groupby typeof(some_field)
ja> agg count
ja> execute
# Check field types
```

### Performance Testing

```bash
ja> from huge_file.jsonl
ja> select simple_condition
ja> execute --lines=1000
# Test filter performance

ja> project field1,field2,field3
ja> execute --lines=1000  
# Test projection performance
```

## Next Steps

- [Performance Optimization](performance.md) - Make your queries faster
- [Complex Expressions](../concepts/expression-language.md) - Advanced filtering
- [Cookbook Examples](../cookbook/log-analysis.md) - Real-world patterns
